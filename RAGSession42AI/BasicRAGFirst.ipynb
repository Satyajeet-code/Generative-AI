{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25c4c744",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/Satyajeet-code/Generative-AI/blob/main/RAGSession42AI/BasicRAGFirst.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96602272",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain langchain-community PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079435c0",
   "metadata": {},
   "source": [
    "### Types of Loaders:\n",
    "   #### There are different loaders provided by langchain to load types of documents. Some of them are:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26691f1e",
   "metadata": {},
   "source": [
    "#### CSVLoader: Loads CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "da9e0a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "\n",
    "loader = CSVLoader(file_path=\"C:/Users/91933/House Price prediction.csv\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b9cf1024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset=pd.read_csv(r\"C:\\Users\\91933\\House Price prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "828df15c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Home</th>\n",
       "      <th>Sqft</th>\n",
       "      <th>LotSize</th>\n",
       "      <th>Baths</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2192</td>\n",
       "      <td>16.4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>505.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3429</td>\n",
       "      <td>24.7</td>\n",
       "      <td>3.5</td>\n",
       "      <td>784.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2842</td>\n",
       "      <td>17.7</td>\n",
       "      <td>3.5</td>\n",
       "      <td>649.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2987</td>\n",
       "      <td>20.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>689.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3029</td>\n",
       "      <td>22.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>709.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Home  Sqft  LotSize  Baths  Price\n",
       "0     1  2192     16.4    2.5  505.5\n",
       "1     2  3429     24.7    3.5  784.1\n",
       "2     3  2842     17.7    3.5  649.0\n",
       "3     4  2987     20.3    3.5  689.8\n",
       "4     5  3029     22.2    3.0  709.8"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9d7601",
   "metadata": {},
   "source": [
    "#### DirectoryLoader: Loads all documents in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "483e3d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "# import exceptions\n",
    "\n",
    "folder_path = r\"D:\\demo folder\"\n",
    "\n",
    "# loader = DirectoryLoader(folder_path,glob=\"**/*.txt\", show_progress=True)\n",
    "loader = DirectoryLoader(folder_path, glob=\"**/*.docx\")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f16eef3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "26ec09b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'D:\\\\demo folder\\\\REPORT_TRW.docx'}, page_content=\"Applications of Artificial Intelligence in Agriculture: A Literature Survey\\n\\nSubmitted by:\\n\\nSimran Gurung (23MCA1005)\\n\\nSatyajeet Narayan (23MCA1047)\\n\\nPriya M (23MCA1019)\\n\\nGuided by:\\n\\nDr. Rashmi Rekha Borah\\n\\nAssistant Professor\\n\\nSSL\\n\\nVIT, Chennai\\n\\nABSTRACT\\n\\nThis paper focuses on the applications of Artificial Intelligence (AI). The pivotal factors influencing the crop production such as  climatic changes, soil health, various crop diseases and efficient weed management are the focal points of our research. We conducted a comprehensive search for pertinent academic articles using prominent databases, including Google Scholar, Scopus, and IEEE Xplore, with a time frame spanning from 2019 to 2023. Our study aims to improve the crop production in agriculture by monitoring the four horsemen in this field- detection of crop diseases,soil health monitoring, predicting the climatic changes and weed detection methods using AI. This paper contributes to the ongoing efforts in the agricultural sector to optimize productivity, foster sustainability, and ensure food security.\\n\\nKeywords: Artificial Intelligence, Agriculture, Farming, crop production, weed management\\n\\nINTRODUCTION\\n\\nAgriculture, among the world's oldest and most vital sectors, faces increasing challenges as global population growth surges, escalating both food demand and employment needs. In response, innovative automated methods are being introduced to augment traditional farming practices. These advances become necessary as the conventional methods prove insufficient in meeting the escalating requirements while also accommodating employment opportunities for the burgeoning global populace [1]. Pressing factors such as labor shortages, stringent regulations, a surging global population, and a diminishing number of farmers compel agriculturists to seek novel solutions. This shift in the agricultural landscape is driven by emerging technologies, including the Internet of Things, Big Data and Analytics, AI and Machine Learning (ML), which are progressively penetrating almost every industry.\\n\\nPesticides are traditionally administered across open-air or greenhouse farming areas to enhance crop yields. However, modern farming practices incorporate Machine Learning (ML) into precision agriculture management, enabling the targeted application of agrichemicals based on factors such as timing, location, and specific crop needs. Accurate detection and classification of crop quality attributes are crucial for farmers aiming to increase the value of their products and minimize wastage. With the aid of data, machines can identify and uncover novel characteristics that significantly contribute to crop quality. Water management plays a pivotal role in agriculture, affecting various aspects like agronomy, climate, and hydrology. ML-driven applications offer the capability to estimate evapotranspiration on a daily, weekly, or monthly basis, thereby facilitating more efficient usage of irrigation systems [2,3].\\n\\nIn our paper, we have highlighted the four major challenges of agriculture namely weed management, crop disease detection, soil health management and climatic changes. Our research aims to provide a comprehensive understanding of the current state of AI applications in tackling the above challenges, shedding light on innovative approaches and technologies designed to revolutionize farming practices. Additionally, we offer insights into the potential benefits of AI-driven solutions in improving crop yields, reducing losses, and promoting sustainability. Our paper serves as a valuable resource for farmers, researchers, and policymakers seeking to harness AI's potential to tackle the pressing issues in agriculture and secure the global food supply chain.\\n\\nMATERIALS AND METHODS\\n\\nTo identify pertinent research, we utilized key phrases such as ‘AI in agriculture’, ‘crop disease detection using AI’, ‘weed management using AI’, ‘crop production and AI’, ‘soil health monitoring using AI’, ‘climate monitoring using AI for agriculture’ to name a few. The initial pool comprised 187 papers, from which we rigorously filtered and selected 100 papers for our survey. Various parameters were considered during this process, including the performance metrics of machine learning and deep learning models, model architectures, and the incorporation of optimized datasets within the selected research articles.\\n\\nOne crucial criterion guiding our selection was the evaluation of different machine learning and deep learning models employed across the chosen papers. By scrutinizing the methodologies and outcomes of these models, we aimed to identify trends, strengths, and limitations in the application of AI in agriculture. This comprehensive analysis allowed us to gain insights into the diverse approaches researchers have taken in addressing challenges related to weed management, crop disease detection, soil health assessment, and climate monitoring changes.\\n\\nThe diversity in model architectures represented a pivotal aspect of our literature review methodology. By examining the structural components and design choices of the AI models discussed in the selected papers, we sought to discern the impact of architecture on the efficacy of weed management and other agricultural applications. Understanding the nuances of model architectures contributes to a holistic perspective on the potential scalability and adaptability of AI solutions in diverse agricultural contexts.\\n\\nAdditionally, the consideration of optimized datasets played a significant role in our literature survey methodology. The relevance and representativeness of datasets are crucial factors influencing the generalizability and reliability of AI models in agricultural applications. Analyzing the sources, sizes, and characteristics of these datasets across the selected papers allowed us to gauge the robustness of the models in real-world agricultural settings.\\n\\nOur meticulous approach in the paper ensures a comprehensive and systematic foundation for our literature review. By delving into the performance metrics, model architectures, and optimized datasets employed in the selected papers, we aim to provide a nuanced understanding of the current landscape of AI applications in agriculture, with a specific emphasis on weed management, crop disease detection, soil health assessment, and climate monitoring changes. This methodological transparency enhances the reliability and relevance of our literature review, contributing valuable insights to the broader discourse on the intersection of AI and agricultural practices.\\n\\nLITERATURE REVIEW\\n\\nA. Weed Management using AI\\n\\nUtilizing AI for weed management involves leveraging advanced algorithms and image processing techniques to precisely identify and control weeds, enhancing agricultural efficiency and minimizing crop interference. This technology enables targeted and sustainable approaches, optimizing resource utilization in farming practices. In one of the studies [4], the authors created AI-powered autonomous plant classification modules intended for precise herbicide spraying and weed control. These modules have removed the need for individuals to develop their own AI-based solutions, thereby increasing the agricultural sector's accessibility to AI-driven weed management. Deepfield Robotics' technology improves targeted fertilization, nano irrigation, automated phenotyping, and other areas of agriculture in addition to making weed management easier. Deepfield Robotics seeks to address the issues facing farmers, such as rising expenses and a shortage of human labor for weed control, as well as international restrictions on herbicide use, by utilizing AI and Deep Learning. \\n\\nIn order to mitigate the negative effects of agrochemicals and spraying techniques, Partel et al. [5] have introduced a novel and economical technology for precise weed management in specialty crops. The authors have developed a smart sprayer that precisely sprays target weeds at the desired location by using cutting-edge machine vision and artificial intelligence techniques. To evaluate the smart sprayer's effectiveness, the researchers ran two experiments: one with fake plants and the other with actual plants. The results were very promising, showing remarkable accuracy and recall rates for target spraying and plant detection. In a different study [6], three pre-trained image classification models- VGG16, ResNet50, and InceptionV3- that were implemented in the PyTorch and Keras frameworks were used to classify and identify different species of weeds. They used an object detection model based on the You Only Look Once (YOLOv3) library for the purpose of weed location and identification. The study used an annotated dataset that included RGB images of four early-season weeds—foxtail (Setaria viridis), giant ragweed (Ambrosia trifida), redroot pigweed (Amaranthus retroflexus), and cocklebur (Xanthium strumarium)—that are frequently encountered in corn and soybean production in the Midwest of the United States. In conclusion, the study shows that, given enough data, using YOLOv3 for object detection and pre-trained models for image classification could be useful in the field for identifying both single and multiple weeds.  \\n\\nIn order to train semantic segmentation models for weed detection in canola fields using deep learning techniques, one study [7] suggests a methodology to expedite the manual labeling of pixels. The approach consists of two steps: in the first, the maximum likelihood classification is used for separating the background and foreground, and in the second, the weed pixels are manually labeled. Semantic segmentation models are then trained on the labeled data, classifying all other vegetation as the second class and crop and background pixels as the first. In order to confirm wavelet texture features' potential for weed detection in a sugar beet crop, Bakhshipour et al. [8] have addressed the potential of wavelet texture features for weed detection in agriculture.  In order to identify the wavelet texture features for every image subdivision that would be supplied to an artificial neural network, a discrimination algorithm was developed with a series of steps. For every single-level wavelet transform-produced multi-resolution image, co-occurrence texture features were identified. The outcomes showed that even in the presence of substantial occlusion and leaf overlap, the wavelet texture features could successfully distinguish weeds from the crops.\\n\\nFor the purpose of weed detection from unmanned aerial vehicle (UAV) photos, one study [9] proposes a novel fully automatic learning technique that makes use of convolutional neural networks (CNNs) with an unsupervised training dataset collection. There are three primary stages to the suggested approach. To identify the weeds growing in between the rows, the authors first automatically identified the crop rows. The training dataset is created in the second phase using interrow weeds. In order to create a model that can identify weeds and crops in the photos, the CNNs were lastly run on this dataset. Espejo-Garcia et al. [10] delved into the prospect of enhancing neural network performance through fine-tuning on agricultural datasets rather than relying solely on ImageNet pre-training. The results of their study showcased notable improvements in overall performance. Specifically, a reduction of 13.67% in the number of epochs yielded enhancements in certain architectures, such as a 0.51% improvement for Xception and a 1.89% boost for Inception-Resnet. The findings advocate for the adoption of this recommended approach to bolster research efficiency and progress. Furthermore, the authors propose the establishment of an agricultural repository, emphasizing the importance of researchers openly sharing their pre-trained neural networks to foster collaboration and advancement in the field. Farooq et al. [11] addressed the challenge of distinguishing between weeds and crops, employing patch-based classification with convolutional neural networks (CNN) and histogram of oriented gradients (HoG). Their study evaluated the methods, considering the impact of varying sensor bands and spatial resolutions in remote sensing technologies. The results favored CNN, demonstrating its ability to extract more powerful features for accurate weed classification compared to HoG. The analysis of key parameters provided guidance for choosing the right patch size, spatial resolution, and number of bands for effective weed identification using CNN. \\n\\nIn a recent study [12], a new graph-based deep learning architecture, Graph Weeds Net (GWN), is proposed for recognizing various weed types in conventional RGB images from diverse rangelands. GWN captures regional patterns aligned with defined image scopes, generating multi-scale graph representations for effective weed classification. Furthermore, GWN offers insights into key regions, opening possibilities for additional within-image actions in robotic in-field systems. The architecture underwent evaluation on a recently released benchmark dataset, showcasing state-of-the-art performance with a top-1 accuracy of 98.1%. Jiang et al. [13] devised a CNN feature-based graph convolutional network (GCN), utilizing weed CNN features and their Euclidean distances for construction. Employing semi-supervised learning, the GCN graph enhanced the model by leveraging both labeled and unlabeled image features, propagating label information from labeled weed data through graph propagation. The GCN-ResNet-101 approach demonstrated impressive recognition accuracies of 97.80%, 99.37%, 98.93%, and 96.51% on four distinct weed datasets, surpassing state-of-the-art methods (AlexNet, VGG16, and ResNet-101). Notably, the proposed approach met real-time requirements for field weed control. This CNN feature-based GCN method proves advantageous for multi-class crops and weed recognition with limited labeled data, presenting a promising solution for similar agricultural recognition tasks.\\n\\nAnother study [24] devised a stereo vision system that uses artificial neural networks (ANNs) and two metaheuristic algorithms to differentiate between rice plants and weeds, as well as to further distinguish between two types of weeds in a rice field. In order to achieve this, stereo footage was captured throughout the rice field, and various channels were separated and broken down into their component frames. After the frames were pre-processed and segmented, green plants were taken out of the background. 302 distinct color, shape, and texture characteristics were found to be necessary for the precise differentiation of rice from weeds. Partel et al. [25] used machine vision to create an autonomous and intelligent herbicide sprayer for identifying the type of weeds in real-time and apply the appropriate herbicide only to the desired areas. In this paper, deep learning frameworks with two evaluation metrics—precision and recall—are compared to develop a smarter sprayer system with more accurate real-time target detection capabilities.\\n\\nA study [26] on robotics describes ways to eradicate weeds that are growing both inside and between crop plants. It works well with high-value vegetables, plantation crops, line-sown crops, and wider-spaced crops. Various robot types can be employed for weed control, based on the application and requirements in a particular crop land scenario. In robotics, the sensor could identify the weed and use chemical or mechanical control to manage it. It can be applied for weed control in a variety of unfavorable soil and climate conditions. Robotic weed control is a technology-driven process that necessitates high levels of automation in agricultural settings. One of the review papers [27] outlines the technologies of site-specific weed management (SSWM) systems, assesses the financial and environmental advantages of them, and provides an outlook for their practical farming application. Precise spraying and hoeing operations are described in conjunction with sensor technologies such as 3D cameras, multispectral imaging, and AI for weed classification and computer-based decision algorithms. \\n\\nAnother study [28] focussed on deep learning (DL) based weed detection methods and SSWM-related technologies. A thorough literature review disclosed that a lot of research work has used the transfer learning approach to address weed detection; custom neural networks have received less attention; no single model can be attributed to having achieved high accuracy on multiple field images related to several research studies to name a few. Adeniji et al. [29] devised an advanced image recognition algorithm that used smart machines to reduce costs and environmental risks. Computer vision technology was used to precisely identify and target weeds for removal. For accurate weed control, a machine learning model was trained with pertinent datasets. With its sophisticated image recognition algorithms, the AI-powered robot outperformed human labor in terms of speed and accuracy, completing weed removal and decomposition tasks 1.2 times quicker than before. \\n\\nKhan et al. [30] designed a field experiment to evaluate the effects of AI on wheat crops in comparison with specific synthetic herbicides during the 2020–21 growing season. The experiment was set up using a Randomized Complete Block design (RCBD), which maintained four replications. The outcomes of artificial intelligence (robotic weeding) and hand weeding treatments were statistically equivalent. AI had the highest CBR, followed by manual weeding and broad-spectrum herbicide. In conclusion, if AI is used extensively, it may prove to be a cost-effective and environmentally friendly method of controlling weeds. Another study [31] proposes a new model for classifying crops and weeds images, using a methodology based on transfer learning technique and a dataset of 5339 plant images. The model achieves an overall accuracy of 98.47% during validation and 96.04% on the test set. Future work includes the use of more features and descriptors to accurately distinguish specific classes of weeds and the possibility of extending the approach to other kinds of plants.\\n\\nA study [32] suggested a technique that effectively and with fewer parameters separates weeds from crops using pixel-by-pixel segmentation. A simplified form of the encoder-decoder network known as U-Net architecture is used in the process of classifying crops from weeds. It has a symmetric expanding path and contracting path. It facilitates the exact localization process. The suggested method reduces the parameters by about 27% and achieves a segmentation accuracy of about 95% with a lower error rate of about 7%. The degree of classification accuracy opens the door to mechanical weed removal as well as selective spraying. This lessens the impact of herbicides on the labor and field expenses. The novel weed identification system proposed in a study [33] is based on a combination of traditional machine learning classifiers (Support Vector Machines, XGBoost, and Logistic Regression) trained with the previously extracted deep features and fine-tuning pre-trained convolutional networks (Xception, Inception-Resnet, VGNets, Mobilenet, and Densenet). This method's objectives were to prevent overfitting and produce a reliable and steady performance. A few design heuristics for transfer-learning based systems that prevent overfitting without sacrificing performance are presented through the results analysis. The authors in one of the studies [34] trained small networks in a cascaded fashion to generate coarse-to-fine predictions, which are then aggregated to generate the ultimate outcomes. Four publicly available datasets were used for the evaluation of the proposed network and comparison with other state-of-the-art networks: a paddy-millet dataset, a carrot crop vs. weed dataset, the BoniRob dataset, and the rice seeding and weed dataset.\\n\\nTrong et al. [35] created a new voting method for classification by utilizing the late fusion of multimodal Deep Neural Networks (DNNs). Better DNNs models contribute more to the score vector used for voting, which is determined by either calculating priority weights or using a Bayesian conditional probability-based method. The authors employed five DNN models—NASNet, Resnet, Inception–Resnet, Mobilenet, and VGG—to conduct an experimental analysis of the Plant Seedlings and Chonnam National University (CNU) Weeds datasets. The outcomes demonstrate that their techniques obtained accuracy levels of 98.77% on the CNU Weeds dataset and 97.31% on the Plant Seedlings dataset. Moreover, the framework of their paper has near-real-time image classification capabilities. Another study [36] devised a method for Convolvulus sepium (hedge bindweed) and sugar beet detection that builds a deep convolutional neural network (CNN) based on the tiny YOLOv3 architecture. In order to train the created model, the authors first created 2271 synthetic images and then combined them with 452 field images. Using k-means clustering, YOLO anchor box sizes were computed from the training dataset. After training the developed model with both synthetic and original field images, the mean average precision (mAP) metric improved from 0.751 to 0.829 when compared to using collected field images alone, as demonstrated by testing the model on 100 field images. \\n\\nChen et al. [62] have presented the first thorough assessment of deep transfer learning (DTL) for the purpose of identifying common weed species unique to southern U.S. cotton (Gossypium hirsutum L.) production systems. A brand-new weed identification dataset was produced, with 5187 color photos of 15 different weed classes taken in cotton fields (mainly in North Carolina and Mississippi) in the 2020 and 2021 growth seasons, under natural light and at different stages of weed growth. By using transfer learning with multiple holdout validations, we assessed 35 cutting-edge deep learning models and created a comprehensive benchmark for the weed identification task under consideration. Another study [63] set out to determine whether deep convolutional neural networks (DCNNs) could be used to identify lamb's quarters (Chenopodium album) in potato fields. In Prince Edward Island (PEI) and New Brunswick (NB), Canada, five potato fields were chosen in order to gather photos of the lamb's quarters and potato plants that varied in both space and time. Images captured in various stages of potato growth, in clear, cloudy, and partly cloudy outdoor light, as well as in shadowy settings, were included in the image database. To classify potato plants and lamb's quarters, the images were trained for three different DCNN models: GoogLeNet, VGG-16, and EfficientNet. TensorFlow and PyTorch were the two frameworks whose performances were compared in terms of training, testing, and inferring DCNNs. The outcomes demonstrated the superior performance of DCNNs in the potato plant and lamb's quarters.\\n\\nB. Detection of Crop Diseases using AI\\n\\nThe agriculture industry is the most important industry for society as it serves the most important need of life. But the plant diseases in agriculture lead to a decrease in productivity and hence it is very important to prevent, detect, and get rid of the diseases. Paddy crop is one of the most demanding crops especially in South Asia. The authors [14] have used CNN and the knowledge of image processing for classifying and predicting diseases in paddy crops in initial stages itself to prevent the mass loss in productivity of the whole yield. Another study [15] has devised a similar CNN approach for  detecting diseases like Black rot, Scab and Cedar in Apple trees but the CNN has smaller layers which decreases the computational burden. They depend majorly on data augmentation (like scaling the image, zooming the image, shifting, etc.) to generate more samples. They achieved an accuracy of 98% with their approach. \\n\\nThe authors [16] focus on detecting White Scale Disease in Date Palms and they have used a simpler machine learning approach where they have compared various models like Support Vector Machines (SVM), K-Nearest Neighbour (KNN), Random Forest (RF) and Light Gradient Boosting Machine (LightGBM). The SVM model outperformed all others by achieving an accuracy of 98.29%. The authors [17] have tried a transfer learning based approach to detect 27 diseases in a set of 10 different crops in harsh environments. They have used the Inception-ResNet-V2, which in turn uses deep CNN as its architecture and used ReLu as their final activation function and they got an accuracy of 86.1%.\\n\\nShafiq et al. [18] have deeply analyzed 176 papers from 5 major academic databases,  namely Springer, IEEE Xplore, Scopus, Google Scholar, and ACM library. These papers encompass several crops like rice, grapes, apples, maize, etc. They found out that when machine learning approaches like Support Vector Machines (SVM) or Logistic Regression (LR) are used, disease localization serves as a bottleneck to disease detection. They deduced that Cognitive CNNs with attention mechanisms and transfer learning are being majorly used, possibly to eliminate the bottleneck. They finally propose a need to avail models with fewer parameters, implementable on small devices and large datasets accommodating several crops and diseases to have robust models. Another study [19] has implemented the approach we discussed. They combined the current mature AIoT technology and deep learning and applied it to smart agriculture. They used deep learning “YOLOv3” for image recognition to obtain the location of Tessaratoma papillosa and analyze the environmental information from weather stations (collected through IoT devices)  through Long Short-Term Memory (LSTM) to predict the occurrence of pests, and got an accuracy of 90%.\\n\\nPotato late blight is considered one of the most devastating diseases world over. Fenu et al. [20] has described the test conducted using the DSS LANDS in order to predict potato late blight disease in Sardinia. Their objective was to investigate if regional weather variables could be used to predict potato late blight risk in southern Sardinia using a Machine Learning approach. The disease severity is predicted using Feed-forward Neural Network and Support Vector Machine Classification based on meteorological parameters provided by ARPAS weather stations. The prediction accuracy for ANN was 96% and for SVM Classification was 98%.\\n\\nFor creating a website for the farmers to get a better crop, fertilizer recommendation, and plant disease prediction, Rani et al. [21] used the Open Weather API to get the live temperature and humidity of the respective locations and the users need to enter the soil nutrition values to get a better crop recommendation. Resnet architecture was used for leaf disease prediction. Resnet architecture performed significantly very well by giving 99.2% accuracy. “Early prediction of pathogen infestation is a key factor to reduce the disease spread in plants” quoted Elham Khalili et al. [22].  Prediction of charcoal rot disease in soybeans is very tedious and non-practical using traditional approaches. Authors tested several ML techniques for prediction of charcoal rot disease in soybean for a cohort of 2,000 healthy and infected plants. Gradient Tree Boosting (GBT) was the choice of algorithm which obtained an accuracy of 96.25%.\\n\\n“In recent years, deep learning has brought tremendous improvements in the recognition accuracy of image classification and object detection systems”, quotes Andrew et al. [23]. Researchers used (CNN)-based pre-trained models such as DenseNet-121, ResNet-50, VGG-16, and Inception V4 to detect 38 different diseases from the  popular PlantVillage dataset, which has 54,305 image samples. The experiments proved that DenseNet-121 achieved 99.81% higher classification accuracy, which was superior to state-of-the-art models.\\n\\nForecasting crop yield is an efficient way to help farmers in growing more crops, suggests Priyanka et al.[64]. Taking into consideration different parameters like meteorological conditions, rainfall, area,crop, production and yield and creating a decision-support application using machine learning. This tool can facilitate making decisions about the type of crops to grow and how to take care when they are growing. Different machine learning and deep learning techniques are used but Random forest and Convolutional Neural Networks stand out when tested on different metrics like accuracy, mean squared error, standard deviation, losses, root mean squared error, etc. Random forest gave an accuracy of 98.96%, mean absolute error of 1.97, rmse of 2.45 and standard deviation of 1.23. The convolutional neural network achieved a loss of 0.00060. These methods not only show good metrics on paper, but also predict the results very well. The results are then analyzed using root mean square to gain a better understanding of how the model’s shortcomings or errors compare to other methods.\\n\\nVision Transformer (ViT) techniques have been on the rise as they provide better outcome in image related tasks like classification and identification.Venkatasaichandrakanthand, et al. [65] propose an Enhanced vision transformer architecture (EViTA) model for identifying, segmenting and classifying pests. ViT has provided promising results than previous machine learning models and Convolutional neural Network algorithms. The authors focus on the best way to learn dual barch segment representations in ViT models for image arrangement. Here, the authors suggest a two layer transformer encoder based on its properties to combine pest image segments of different sizes to provide more grounded picture highlights. The three pest datasets used in this study—Aphids (IP102 Dataset), Wireworm (IP102 Dataset), and Gram Caterpillar—that have an impact on peanut crops were gathered from publicly accessible repositories. With two distinct components of varying computing complexity, our methodology handles both tiny and large segments of tokens. These tokens are then joined by simply considering them again until they are complete. The collected datasets are preprocessed using moth flame optimization (MFO) to maximize the characteristic. The images are then flattened using linear projector methodology to improve the missing quality in pest images. Finally, normalization techniques are applied to convert the datasets entirely to mathematical arrangement.\\n\\nThis processed information is standardized further using the self attention in StandardScaler techniques are carried out for choosing the best highlights in the dataset appropriately having enormous effect towards affecting insect picture forecasts. Finally, these optimal highlights are incorporated into the EViTA model, and the results are compared to state-of-the-art models, hence validating the dominance of the suggested EViTA+PCA+MFO model in pest image prediction with a high accuracy rate. Extensive experiments demonstrate that, despite successful CNN models, our methodology outperforms or is on par with a few simultaneous deals using vision transformers.\\n\\n“To ensure global food security and the overall profit of stakeholders, the importance of correctly detecting and classifying plant diseases is paramount”, quotes Sabbir et al.[66].. Many solutions have been presented in this regard with the advent of deep learning-based picture classification. However, quick, accurate, and computationally cheap systems are needed for these solutions to be applicable in low-end devices. Autohor_name proposes a lightweight transfer learning-based method for illness detection from tomato leaves. It improves the leaf images with lighting adjustment using a powerful preprocessing technique for better categorization. In order to achieve good prediction, the system uses a mixed model that consists of a pretrained MobileNetV2 architecture and a classifier network to extract features. Runtime augmentation takes the role of traditional augmentation techniques in order to prevent data leakage and solve the problem of class imbalance. The model was evaluated on tomato leaf images from the plant village dataset and an accuracy of 99.30% was achieved.\\n\\nCrop diseases lower yield and are mostly to blame for the global agriculture industry's financial losses. In order to improve human health, crop diseases need to be efficiently controlled and monitored, suggests Altaf et al.[67]. Previously, image classification and identification have been accomplished by researchers using manually created features.\\n\\nThese days, researchers can significantly increase the accuracy of object identification and classification because of advancements in deep learning. In this research, author_name have employed a deep-learning system to diagnose wheat illnesses based on in-place photos of different resolutions taken by camera devices. There are four types of wheat diseases in the dataset: powderly, stem rust, yellow rust, and normal. There were 2,207 photos in each category. They have employed the Convolutional Neural Network (CNN) to train their classifier. One of CNN's greatest benefits is that it can automatically get the features from an image by preprocessing the image directly. It achieved an accuracy of 85.58% and can be used in real world scenarios for the above mentioned diseases.\\n\\nA study [68] shows farmers have recently shown a great deal of interest in smart agriculture approaches. This is caused by a number of variables, one of which is the broad availability of low-cost, low-power wireless sensors based on the Internet of Things (IoT) that can be used to remotely monitor and report on crop, weather, and field conditions. This makes it possible to manage resources more effectively, reducing the amount of water needed for irrigation and the need for harmful pesticides. In order to reduce crop illnesses and insect infestation, farmers can also use autonomous farming equipment and improve their forecasting skills by utilizing historical data and current conditions. This is made possible by the recent explosion in artificial intelligence. These two revolutionary technologies have transformed traditional agricultural methods. This survey report offers: (a) A thorough overview of the most recent developments in the field of smart agriculture systems through IoT technologies and AI techniques; (b) A critical analysis of these two current technologies and the obstacles to their broad implementation; and (c) A comprehensive assessment of the technological and sociological trends that will shape the adoption of smart agriculture systems by farmers worldwide in the future.\\n\\nAgricultural infections are a serious issue for farmers who are enduring losses in agricultural production these days, for a variety of reasons. This is brought on by ignorance of the illness and the available insecticides and herbicides for its control. However, in order to control the condition, determining the present state of the illness and offering the best therapies require professional advice or prior expertise. This takes a lot of money and time. Prajwal et al.[69]  are creating a machine learning model utilizing the Convolutional Neural Network (CNN) technique to address the aforementioned problem. The model uses an image to identify the paddy crop illness and suggest an appropriate treatment. The treatments give the right information about which insecticide or pesticide to use to treat the disease.\\n\\nFood losses resulting from crop diseases caused by pathogens including bacteria, viruses, and fungi have been a recurring problem in agriculture for generations worldwide. Advanced disease detection and prevention in crops are essential to limit disease-induced damage throughout growth, harvest, and postharvest processing, as well as to improve yield and assure agricultural sustainability. This study [70] examines the techniques currently employed in agriculture for both direct and indirect disease identification. Direct detection methods include laboratory-based techniques like flow cytometry (FCM), gas chromatography-mass spectrometry (GC-MS), enzyme-linked immunosorbent assay (ELISA), fluorescence in-situ hybridization (FISH), immunofluorescence (IF), and polymerase chain reaction (PCR). Thermography, fluorescence imaging, and hyperspectral techniques are examples of indirect methods. Lastly, the paper offers a thorough synopsis of biosensors based on highly selective bio-recognition elements including enzyme, antibody, DNA/RNA, and bacteriophage.\\n\\nFood security is greatly threatened by crop diseases, but in many regions of the world, there is insufficient infrastructure to identify them quickly. The field of smartphone-assisted disease diagnosis has gained momentum due to the growing global smartphone penetration rate and the advancements in computer vision that deep learning has made possible. By training a deep convolutional neural network on a public dataset of 54,306 photos of healthy and diseased plant leaves that were collected under controlled conditions, Sharada et al.[71] are able to identify 26 diseases and 14 crop species (or lack thereof). The trained model achieves an accuracy of 99.35% on a held-out test set, indicating the practicality of this approach. Overall, the strategy of training deep learning models using increasingly huge and publicly available picture datasets represents a clear path toward smartphone-assisted crop disease diagnosis on a massive global scale.\\n\\n[72] Identification and monitoring of plant diseases, nutritional deficiencies, regulated irrigation, and prudent application of fertilizers and pesticides are all part of managing crops from early stages to mature harvest stages. The availability and ground visibility during important growth stages of crops remain major challenges, despite the growing number of remote sensing systems. The ground-based agricultural robot known as eAGROBOT (a prototype) solves problems with huge, complicated satellite-based solutions and helpdesk-style solutions that are offered as mobile services. It offers a compact, dependable, and transportable platform for automatically surveying farms, identifying illnesses, and applying pesticides. In the future, the farmer will have access to decision support statistics and a consolidated picture of the farm for planning needs. \\n\\nUsing One Class Classification for classification and Local Binary Patterns (LBPs) for feature extraction, the current approach shows how to automatically identify agricultural diseases on a variety of leaf sample photos that correspond to different crop species. The suggested approach [73] makes use of a specific One Class Classifier for every plant health issue, such as black rot, powdery mildew, and downy mildew in healthy plants. When evaluated in a range of crops, the algorithms trained on vine leaves demonstrated a very high level of generalisation behaviour. When ambivalent data instances may correspond to one or more conditions, an innovative method that suggests resolving conflicts between One Class Classifiers gives the right identification. A 95% success rate is attained for all 46 plant-condition combinations that were examined.\\n\\nSmart farming is a method that gathers multiple data from sensors, robots, live streams, social media, etc. to provide sophisticated applications of contemporary farming. Big data is the idea of combining different data from different sources and processing it with multilevel databases . While there have been many advancements in smart farming up until this point utilizing image processing, data mining, IOT, etc., the field that is now growing at the fastest rate is machine learning. Real-time machine learning applications, whether through supervised or unsupervised methods, are in greater demand. With reference to the current scenario in traditional farming, there has been a dire need for predicted data in farming which can help farmers to know about their real-time problems and act accordingly. To resolve their problems, Jayraj et al.[74] propose a system which can predict cotton crop diseases using 'Decision Tree Classifier' by taking parameters such as temperature, soil moisture, etc. This would help farmers by providing better quality productions and we would also be focusing on building an android application which will give real-time output prediction.\\n\\n[75] Approximately 70% of the population of India is employed in agriculture, making it an agricultural nation. Farmers can choose from a wide variety of fruits and vegetables because of this diversity. But growing these crops to their full potential and producing high-quality food requires a very precise approach. With the use of technology, it can be enhanced. Close observation is necessary for the management of perennial fruit crops, particularly for the control of diseases that have the potential to seriously impair output and, in turn, the life after harvest. \\n\\nWhen it comes to plants, a disease is any disturbance of their regular physiological function that results in recognizable symptoms. A symptom is a phenomenon that goes along with something and is thought to be proof positive that it exists. Pathogens, or any agent that causes disease, are what cause disease. Most of the time, bugs or illnesses are visible on the plant's leaves or stems. \\n\\nFor this reason, identifying plants, leaves, and stems as well as determining the presence of pests or diseases, their incidence rate, and their symptoms are crucial to the productive production of crops.  In the field of biology, an experiment can produce thousands of photos at times. These photos may be needed for additional research, such as categorizing lesions, grading quantitative characteristics, figuring out how much area insects eat, etc. Nearly all of these jobs are done by hand or with different software programs. In addition to being an enormous lot of effort, it has two main problems: processing too slowly and subjectivity varying across various people. In order to carry out tests at a high throughput, effective computer software is necessary for plant biologists to automatically extract and analyze important content. Image processing is crucial in this situation. \\n\\nWith the use of technology, it can be enhanced. Close observation is necessary for the management of illnesses that can have a major impact on output and, in turn, the post-harvest period when it comes to perennial fruit crops. When it comes to plants, a disease is any disruption of their regular physiological processes that results in recognizable signs. A symptom is an occurrence that goes along with something and is thought to be proof of it.\\n\\nPlants are susceptible to illnesses that hinder their growth, which then impacts the farmer's income. Plant diseases can be identified by their symptoms in components of the plant like the leaves and stem. By treating the plant and facilitating early diagnosis, the use of an automatic disease detection system helps to avoid crop loss. Thus, Priya et al.[76] have included a crop disease detection and monitoring system in our suggested system. K-means clustering is used to detect diseases. Periodic measurements of the temperature, humidity, and soil moisture content are among the other subsystems. To water the plants, the motor is turned on and off based on the input from the soil moisture sensor. The farmer receives a message using a wi-fi module that is recorded containing the activities made.\\n\\nThe tomato is the most widely grown crop worldwide, and it can be found in every kitchen, regardless of the type of food prepared. It's the most widely grown crop in the world, right behind sweet potatoes and potatoes. In terms of tomato production, India came in second. However, a variety of illnesses lower the amount and quality of the tomato harvest [77] . Thus, the paper discusses a deep learning-based method for illness detection. The method used for disease identification and classification is based on convolution neural networks. Two completely linked layers are positioned after three convolution and three max pooling layers in this model. The experimental findings demonstrate the suggested model's superiority over pre-trained models, such as VGG16, InceptionV3, and MobileNet. There is a variation in classification accuracy from 79% to 100% depending on the classes. The average accuracy of the model is 91.2% for 9 diseased and 1 healthy class.\\n\\nThe spatiotemporal dynamics of crop diseases need to be thoroughly understood in order to apply site-specific fungicide treatments, considers Jonas et al. [78]. Monitoring the heterogeneity of crop life within agricultural settings can be facilitated by the use of remote sensing. Nonetheless, it's critical to detect fungal infections early in the development phase. The possibility of multi-spectral remote sensing for a multi-temporal investigation of agricultural diseases is investigated in this work. A six-hectare winter wheat patch was planted in an experimental field, and it contained every infectious stage of the pathogens that cause leaf rust (Puccinia recondita) and powdery mildew (Blumeria graminis). The infection dynamics were analyzed spatiotemporally using three high-resolution remote sensing pictures. Using the Normalized Difference Vegetation Index and the results of mixture tuned matched filtering (MTMF), a decision tree was used to categorize the data into groups that represented varying degrees of disease severity. Data from the ground truth were compared to the classification results. The initial scene's categorization accuracy was just 56.8%, while the scenes from May 28 and June 20 had far higher accuracy rates of 65.9% and 88.6%, respectively. The findings demonstrated that while high-resolution multispectral data are generally appropriate for identifying crop vigor heterogeneities in the field, they are only mediocrely appropriate for identifying crop infections early on.\\n\\nC. Soil Health Management Using AI\\n\\nWere, K., Bui, et al, (2015) the study compared machine learning models for predicting soil organic carbon (SOC) stocks and found that Support Vector Regression (SVR) with the Sequential Minimal Optimization (SMO) algorithm was the most accurate. Total nitrogen (TN) concentration was a crucial variable. The study stressed the importance of data quality and recommended SVR and Artificial Neural Networks (ANN) for similar studies in different locations. The generated SOC stock map is valuable for climate change mitigation and land management [37].The paper highlights the importance of assessing soil quality in agriculture using a holistic approach that integrates physical, chemical, and biological indicators. It proposes a model that combines data from various sources, collected via Unmanned Aerial Vehicles (UAVs), to enhance agricultural practices and fertilizer management. The paper suggests a case study to validate the model and emphasizes the value of comprehensive soil quality assessment for decision-making by farmers and land managers [38].Szatmári, G., et al., (2021).used geostatistics to predict changes in soil organic carbon (SOC) stock in Hungary, addressing the limitations of machine learning in handling spatial correlation. They found that topsoil SOC stock in Hungary is expected to increase by 14.9 Tg from 1992 to 2010, with a 90% prediction interval between 11.2 Tg and 18.2 Tg. Spatial aggregation helped identify significant SOC stock changes, valuable for carbon accounting research [39].Sothe, C., Gonsamo, A., et al., (2022) the research employed a quantile regression forest method with 40 spatial predictors from satellite data to estimate soil organic carbon (SOC) concentration in Canada across different depths. The model effectively captured 83% of the variation in SOC, with soil depth, temperature, and elevation being influential factors. Forested areas had higher SOC in upper layers, while peatlands had elevated SOC throughout. The Pacific Maritime and Hudson Plain had the highest SOC, while Prairies and Mixed Wood Plain had the lowest [40].The study evaluated three machine learning models for predicting MAOC and found that Cubist performed the best. They used feature selection methods, with forward recursive feature selection (FRFS) being more effective. The research provides insights into improving machine learning-based predictions of SOC fractions by combining PTFs and legacy soil databases for better spatial coverage and accuracy [41].The study employs a “TCS3200” sensor and a smart prototype system to accurately measure soil nitrogen levels the accuracy of the sensor is 87.5%  and send the data to a web server. The Naïve Bayes algorithm classifies the nitrogen content into three categories that are low, medium, and high, based on 40 classifications. The hardware design involves detecting RGB values in the soil using the “TCS3200” sensor, classifying them with the Naïve Bayes algorithm, and displaying results on an LCD screen and sending them to a web server. The research successfully utilizes GIS to map soil nitrogen levels, categorizing them as low, medium, and high [42].Detecting soil total nitrogen content (TN) is crucial for crop growth, but traditional methods are time-consuming. This study investigates the use of hyperspectral technology, which combines energy and spectroscopy, to detect TN in soil. It analyzes six spectral data preprocessing methods and five modeling methods. All five models can be used for TN detection, with the support vector regression (SVR) model showing the best performance. The spectral model offers a rapid and valuable method for TN detection, providing insights for soil element detection [43].Three machine learning algorithms SVR, PLS-ANN, and GBRT were compared for predicting soil nutrient levels (TN, TP, and TK content). The study found that SVR and PLS-ANN performed similarly with full spectra, but PLS-ANN with reduced components was better depending on preprocessing. GBRT provided the most precise models for all three nutrients. The research highlights the reliability of using Vis-NIR spectroscopy and machine learning for soil nutrient measurement in cropland. Soil nutrient content was measured using standard methods, and model performance was evaluated using RMSE, correlation coefficient (r), and RPD [44].This study proposes using random forest (RF) models for predicting soil cohesion, a crucial but time-consuming property to determine. The RF model, based on 145 soil samples from Vietnam, considers six input parameters. It performed well, with high accuracy   0.891 and low error RMSE ≤ 3.323 and MAE ≤ 2.511, outperforming other machine learning models[45].The model combines soil heavy metal contamination and soil fertility data to achieve a 98.33% accuracy in assessing soil quality. Taiyuan city's soil quality is classified into five categories, with 50% falling into the good quality class IB. The paper's objectives are to create a comprehensive soil quality assessment method, utilize the support vector machine (SVM) for classifying heavy metal levels, and understand heavy metal distribution and soil quality patterns in Taiyuan city. The SVM-based model considers factors like heavy metal levels, organic chemicals, soil fertility, texture, and biodiversity in assessing soil quality [46].The study explores Machine Learning (ML) and Deep Learning (DL) techniques for soil nutrient analysis, comparing their effectiveness in predicting various soil properties. It discusses different soil datasets, including images and chemical data, and addresses research questions about these models and challenges in predicting soil nutrients using ML and DL techniques [47].The paper discusses the soil carbon balance in Pampean agroecosystems, emphasizing the accuracy of artificial neural networks over regression techniques for estimation. It highlights the positive impact of soybean rotations on soil carbon, despite lower carbon input, due to higher yields and inputs from other rotation components. Biomass production from weeds varies in corn experiments but is generally low in wheat and soybean experiments. Total carbon inputs have increased over time, averaging around 5 Mg C ha-1 yr-1 in both subregions [48].The paper explores using diffuse reflectance infrared spectroscopy and machine learning to estimate soil properties accurately and inexpensively. It introduces deep learning techniques, including convolutional neural networks and conditional restricted Boltzmann machines, to consider correlations among output variables for more precise predictions. The conditional restricted Boltzmann machine (CRBM) architecture, which conditions both hidden and visible layers, stands out for improved prediction accuracy [49].\\n\\nThe paper explores using hyperspectral data to predict soil nutrient properties efficiently. It investigates machine and deep learning techniques and emphasizes the importance of dimension reduction with Principal Component Analysis (PCA). Model performance is assessed with metrics like R2, MAE, and RMSE. The research aims to contribute to the development of a mobile app for rapid soil testing and learning-based algorithms for soil property prediction using visual band data [50].The paper focuses on using machine learning to map soil organic carbon (SOC) stocks in Argentina from 1982 to 2017. They employ quantile regression forest machine learning at a 250 m resolution for the 0-30 cm depth. The study found relatively stable spatial distribution of SOC stock over time, but prediction uncertainties were high. It emphasizes the approach's value in providing both spatial patterns and temporal trends in SOC stock, although the predicted changes had low signal-to-noise ratio and uncertainties. The study suggests enhancing the model with dynamic covariates, like climate data, for improved accuracy [51].The research paper delves into the use of machine learning for predicting critical soil properties, including Calcium, Phosphorus, pH, Soil Organic Carbon, and Sand. It underscores the significance of accurate soil property predictions for sustainable farming, particularly in agriculture-reliant countries like India. The study evaluates four machine learning models on an Africa Soil Property Prediction dataset and finds that gradient boosting excels in predicting most soil properties, with the exception of phosphorus, which remains a challenge. The research sheds light on the potential of machine learning in precision agriculture and soil management, carrying implications for sustainable farming practices [52].The paper tackles the vital task of mapping Soil Organic Carbon (SOC) in southeastern Nigeria using five machine learning algorithms. Among them, the Random Forest (RF) model excels in predicting SOC distribution, revealing a distinctive pattern with low levels in the east and high levels in the west, potentially indicating sediment transportation and deposition. The study underscores the potential of machine learning in digital soil mapping and its relevance for precise soil management. It also highlights the need for additional predictors and diverse soil types in future research to further enhance model performance [53].The paper predicts soil total nitrogen content with near-infrared spectroscopy. It employs techniques like spectral preprocessing and sensitive wavelength selection, finding that the random frog leaping algorithm combined with a wavelet neural network offers the most accurate prediction model. This approach addresses spectral absorbance nonlinearity and has potential for portable soil parameter detectors, emphasizing the importance of sensitive wavelength selection for accurate predictions [54].The paper addresses challenges in digital soil mapping in mountainous areas, focusing on sparse observations and complex relationships between environmental factors and soil properties. It introduces Support Vector Regression (SVR) as a promising solution, known for handling non-linearity and sparse datasets. The study outlines an SVR-based framework for mapping soil properties in the Italian Alps, emphasizing the importance of high-resolution soil maps for environmental conservation and land use planning in mountainous regions. SVR is considered a robust and accurate approach, particularly suitable for areas with intricate terrain and non-linear soil-environment relationships [55]\\n\\nThe paper stresses the importance of accurately predicting Soil Organic Matter (SOM) content on the Tibetan Plateau, a challenging environment. It proposes a two-stage approach that combines an Artificial Neural Network (ANN) with ordinary kriging to create precise SOM content maps using sparse data and environmental information. The results show that this approach outperforms other methods, offering lower prediction errors and higher correlation coefficients. This methodology enhances large-scale SOM content mapping, vital for understanding soil carbon dynamics and climate change monitoring. It highlights the potential of machine learning and kriging in regions with limited data, like the Tibetan Plateau [56].The framework combines nitrate data with spatial information using the Random Forest algorithm, explaining 58% of nitrate concentration variance and identifying factors like land use and geomorphology. It can inform regional policies for balancing agriculture and environmental protection [57]. The paper compares satellite sensors (Landsat-8, Sentinel-2, and Sentinel-3) with different resolutions for predicting soil organic carbon (SOC) content and carbon-to-nitrogen ratio (C:N) in Switzerland. Machine learning techniques were used at various spatial resolutions. They employed 150 soil samples and different environmental data combinations as inputs for prediction models.The results indicated that model type, resolution, and sensor choice significantly affected prediction accuracy. Remote sensing, along with topographic and climatic variables, explained a significant portion of SOC content and C:N ratio variations [58].The paper's objective is to estimate soil salinity within the Aral Sea Basin using a neural network model and readily accessible environmental parameters. The methodology involves employing a neural network model and a range of attributes, such as terrain indices, remote sensing data, distance to drains, and long-term groundwater observations, to predict soil salinity at varying scales. Remote sensing parameters from a Landsat 7 satellite image, including the ratio vegetation index and raw bands 3 and 5, are utilized to identify areas with reduced reflectance due to salinity and establish correlations between terrain attributes and soil salinity. The study's validation process involves using 1,755 randomly generated points to validate the generated salinity map, as well as ground-truthing at 315 randomly chosen locations to evaluate the accuracy of the predictions. The study identifies that the neural network model tends to overestimate low salinity values and underestimate higher ones, possibly due to the limited number of high-value samples in the training set [59].The paper emphasizes the importance of soil fertility and maintenance for optimal crop growth, especially among small-scale farmers with limited access to services. It employs unsupervised learning, specifically K-Means clustering, to automatically differentiate between various soil conditions without labels. The research showcases the sensitivity of unsupervised learning to minor soil condition differences, making it a suitable approach for soil condition monitoring. Additionally, the paper discusses the role of soil organic carbon (SOC) in enhancing soil quality and crop yield, along with the use of clustering methods to predict SOC models [60].The paper introduces an evaluation criterion for selecting soil total nitrogen (TN) content-sensitive wavebands based on relevance, representativeness, and redundancy. Two methods, mutual information (MI) and a combination of ant colony optimization (ACO) and MI, are used to identify these wavebands, resulting in a set of eight wavelengths. Models based on these wavebands, using partial least squares (PLS), multiple linear regression (MLR), and support vector machine (SVM), show that MLR and SVM outperform PLS. The SVM models achieve high accuracy, with R2 values of 0.989 and 0.96 in the calibration and validation groups, respectively. The ACO-MI method demonstrates its value for soil sensing in precision agriculture, offering good mechanism, universality, and predictive ability for soil TN content estimation [61].\\n\\nCONCLUSION\\n\\nThe diverse and dynamic landscape of the agricultural sector stands to benefit significantly from the multifaceted applications of AI. Through the comprehensive review of research across four pivotal domains- crop disease detection, weed management, and soil health- we have witnessed the transformative potential of AI in revolutionizing traditional farming practices. The amalgamation of advanced sensing technologies, machine learning algorithms, and data analytics has ushered in a new era of precision agriculture, enhancing efficiency, sustainability, and overall crop productivity.\\n\\nIn the realm of crop disease detection, AI has exhibited remarkable prowess in early identification and diagnosis, enabling timely interventions to mitigate yield losses. The integration of image recognition and data-driven models has proven instrumental in providing farmers with accurate and real-time information, empowering them to make informed decisions.\\n\\nWeed management, a perennial challenge in agriculture, has witnessed a paradigm shift with the introduction of AI. Autonomous robotic systems, guided by AI algorithms, offer a targeted and resource-efficient approach, minimizing the need for chemical inputs and reducing environmental impact.\\n\\nSoil health, a cornerstone of sustainable agriculture, has seen advancements through AI-driven technologies. Smart sensors, coupled with machine learning algorithms, enable precise monitoring of soil conditions, facilitating optimized nutrient management and improved overall soil fertility.\\n\\nAs we navigate the complex challenges of feeding a growing global population while addressing environmental concerns, the application of AI in agriculture emerges as a key enabler. However, the successful integration of these technologies requires continued interdisciplinary collaboration, regulatory frameworks, and a commitment to ethical and responsible AI deployment.\\n\\nIn conclusion, the reviewed literature underscores the transformative impact of AI in agriculture, offering a glimpse into the future of smart, sustainable, and resilient farming practices. As we move forward, it is imperative to foster ongoing research and innovation, ensuring that AI continues to evolve as a driving force in shaping the future of agriculture.\\n\\nREFERENCES\\n\\n[1] Javaid, M., Haleem, A., Khan, I. H., & Suman, R. (2023). Understanding the potential applications of Artificial Intelligence in Agriculture Sector. Advanced Agrochem, 2(1), 15-30.\\n\\n[2] Waleed, M., Um, T. W., Kamal, T., Khan, A., & Iqbal, A. (2020). Determining the precise work area of agriculture machinery using internet of things and artificial intelligence. Applied Sciences, 10(10), 3365.\\n\\n[3] Eli-Chukwu, N. C. (2019). Applications of artificial intelligence in agriculture: A review. Engineering, Technology & Applied Science Research, 9(4).\\n\\n[4] Amend, S., Brandt, D., Di Marco, D., Dipper, T., Gässler, G., Höferlin, M., ... & Winkler, J. (2019). Weed management of the future. KI-Künstliche Intelligenz, 33(4), 411-415.\\n\\n[5] Partel, V., Kakarla, S. C., & Ampatzidis, Y. (2019). Development and evaluation of a low-cost and smart technology for precision weed management utilizing artificial intelligence. Computers and electronics in agriculture, 157, 339-350.\\n\\n[6] Ahmad, A., Saraswat, D., Aggarwal, V., Etienne, A., & Hancock, B. (2021). Performance of deep learning models for classifying and detecting common weeds in corn and soybean production systems. Computers and Electronics in Agriculture, 184, 106081.\\n\\n[7] Asad, M. H., & Bais, A. (2020). Weed detection in canola fields using maximum likelihood classification and deep convolutional neural network. Information Processing in Agriculture, 7(4), 535-545.\\n\\n[8] Bakhshipour, A., Jafari, A., Nassiri, S. M., & Zare, D. (2017). Weed segmentation using texture features extracted from wavelet sub-images. Biosystems Engineering, 157, 1-12.\\n\\n[9] Bah, M. D., Hafiane, A., & Canals, R. (2018). Deep learning with unsupervised data labeling for weed detection in line crops in UAV images. Remote sensing, 10(11), 1690.\\n\\n[10] Espejo-Garcia, B., Mylonas, N., Athanasakos, L., & Fountas, S. (2020). Improving weeds identification with a repository of agricultural pre-trained deep neural networks. Computers and Electronics in Agriculture, 175, 105593.\\n\\n[11] Farooq, A., Hu, J., & Jia, X. (2018). Analysis of spectral bands and spatial resolutions for weed classification via deep convolutional neural network. IEEE Geoscience and Remote Sensing Letters, 16(2), 183-187.\\n\\n[12] Hu, K., Coleman, G., Zeng, S., Wang, Z., & Walsh, M. (2020). Graph weeds net: A graph-based deep learning method for weed recognition. Computers and electronics in agriculture, 174, 105520.\\n\\n[13] Jiang, H., Zhang, C., Qiao, Y., Zhang, Z., Zhang, W., & Song, C. (2020). CNN feature based graph convolutional network for weed and crop recognition in smart farming. Computers and electronics in agriculture, 174, 105450.\\n\\n[14] Ritesh Sharma, Sujay Das, Mahendra Kumar Gourisaria, Siddharth Swarup Rautaray & Manjusha Pandey (2020). A Model for Prediction of Paddy Crop Disease Using CNN. Advances in Intelligent Systems and Computing book series (AISC,volume 1119)\\n\\n[15] Vibhor Kumar Vishnoi; Krishan Kumar; Brajesh Kumar; Shashank Mohan; Arfat Ahmad Khan (2022). Detection of Apple Plant Diseases Using Leaf Images Through Convolutional Neural Network. IEEE Access ( Volume: 11)\\n\\n[16] Abdelaaziz Hessane; Ahmed El Youssefi; Yousef Farhaoui; Badraddine Aghoutane; Fatima Amounas (2023). A Machine Learning Based Framework for a Stage-Wise Classification of Date Palm White Scale Disease. Big Data Mining and Analytics ( Volume: 6, Issue: 3, September 2023)\\n\\n[17] Yong Ai; Chong Sun; Jun Tie; Xiantao Cai (2020).Research on Recognition Model of Crop Diseases and Insect Pests Based on Deep Learning in Harsh Environments. IEEE Access ( Volume: 8)\\n\\n[18] Wasswa Shafik; Ali Tufail; Abdallah Namoun; Liyanage Chandratilak De Silva; Rosyzie Anna Awg Haji Mohd Apong (2023). A Systematic Literature Review on Plant Disease Detection: Motivations, Classification Techniques, Datasets, Challenges, and Future Trends.  IEEE Access ( Volume: 11)\\n\\n[19] Ching-Ju Chen; Ya-Yu Huang; Yuan-Shuo Li; Chuan-Yu Chang; Yueh-Min Huang.An AIoT Based Smart Agricultural System for Pests Detection. Data Mining for Internet of Things\\n\\n[20] Gianni Fenu, Francesca Maridina Malloci (2020). An Application of Machine Learning Technique in Forecasting Crop Disease. ICBDR '19: Proceedings of the 3rd International Conference on Big Data Research\\n\\n[21] G. Elizabeth Rani; Ede Venkatesh; Karnam Balaji; Balasaraswathi Yugandher; Adiki Nithin Kumar; M. SakthiMohan (2020). An automated prediction of crop and fertilizer disease using Convolutional Neural Networks (CNN). 2022 2nd International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE).\\n\\n[22] Elham Khalili, Samaneh Kouchaki, Shahin Ramazi, Faezeh Ghanati (2020). Machine Learning Techniques for Soybean Charcoal Rot Disease Prediction. Front. Plant Sci.,14 December 2020 Sec. Technical Advances in Plant Science\\n\\n[23] Andrew J.,Jennifer Eunice,Daniela Elena Popescu, M. Kalpana Chowdary and Jude Hemanth (2022). Deep Learning-Based Leaf Disease Detection in Crops Using Images for Agricultural Applications. Agronomy 2022, 12(10), 2395\\n\\n[24] Dadashzadeh, M., Abbaspour-Gilandeh, Y., Mesri-Gundoshmian, T., Sabzi, S., Hernández-Hernández, J. L., Hernández-Hernández, M., & Arribas, J. I. (2020). Weed classification for site-specific weed management using an automated stereo computer-vision machine-learning system in rice fields. Plants, 9(5), 559.\\n\\n[25] Partel, V., Kim, J., Costa, L., Pardalos, P. M., & Ampatzidis, Y. (2020). Smart Sprayer for Precision Weed Control Using Artificial Intelligence: Comparison of Deep Learning Frameworks. In ISAIM.\\n\\n[26] Dash, S., Sarkar, S., Tripathy, H. P., Pattanaik, P., & Patnaik, S. (2021, December). Robotics in weed management: A new paradigm in agriculture. In 2021 International Conference on Electronic Information Technology and Smart Agriculture (ICEITSA) (pp. 561-564). IEEE.\\n\\n[27] Gerhards, R., Andujar Sanchez, D., Hamouz, P., Peteinatos, G. G., Christensen, S., & Fernandez‐Quintanilla, C. (2022). Advances in site‐specific weed management in agriculture—A review. Weed Research, 62(2), 123-133.\\n\\n[28] Rai, N., Zhang, Y., Ram, B. G., Schumacher, L., Yellavajjala, R. K., Bajwa, S., & Sun, X. (2023). Applications of deep learning in precision weed management: A review. Computers and Electronics in Agriculture, 206, 107698.\\n\\n[29] Adeniji, A. A., Jack, K. E., Idris, M. K., Oyewobi, S. S., Musa, H., & Oyelami, A. O. (2023). Deployment of an Artificial Intelligent Robot for Weed Management in Legumes Farmland. ABUAD Journal of Engineering Research and Development, 6(2), 28-38.\\n\\n[30] Khan, S., Hussain, Z., Khan, H., & Uslu, O. S. (2023). Comparison of artificial intelligence and synthetic herbicides for weed control in wheat crop. Pakistan Journal of Weed Science Research, 29(2), 81-87.\\n\\n[31]  Binguitcha-Fare, A. A., & Sharma, P. (2019). Crops and weeds classification using convolutional neural networks via optimization of transfer learning parameters. Int J Eng Adv Technol (IJEAT), 8(5), 2249-8958.\\n\\n[32] Arun, R. A., Umamaheswari, S., & Jain, A. V. (2020, November). Reduced U-Net architecture for classifying crop and weed using pixel-wise segmentation. In 2020 IEEE International Conference for Innovation in Technology (INOCON) (pp. 1-6). IEEE.\\n\\n[33] Espejo-Garcia, B., Mylonas, N., Athanasakos, L., Fountas, S., & Vasilakoglou, I. (2020). Towards weeds identification assistance through transfer learning. Computers and Electronics in Agriculture, 171, 105306.\\n\\n[34] Khan, A., Ilyas, T., Umraiz, M., Mannan, Z. I., & Kim, H. (2020). Ced-net: crops and weeds segmentation for smart farming using a small cascaded encoder-decoder architecture. Electronics, 9(10), 1602.\\n\\n[35] Trong, V. H., Gwang-hyun, Y., Vu, D. T., & Jin-young, K. (2020). Late fusion of multimodal deep neural networks for weeds classification. Computers and Electronics in Agriculture, 175, 105506.\\n\\n[36] Gao, J., French, A. P., Pound, M. P., He, Y., Pridmore, T. P., & Pieters, J. G. (2020). Deep convolutional neural networks for image-based Convolvulus sepium detection in sugar beet fields. Plant Methods, 16(1), 1-12.\\n\\n[37] Were, K., Bui, D. T., Dick, Ø. B., & Singh, B. R. (2015). A comparative assessment of support vector regression, artificial neural networks, and random forests for predicting and mapping soil organic carbon stocks across an Afromontane landscape. Ecological Indicators, 52, 394-403.\\n\\n[38] Diaz-Gonzalez, F. A., Vuelvas, J., Correa, C. A., Vallejo, V. E., & Patino, D. (2022). Machine learning and remote sensing techniques applied to estimate soil indicators–review. Ecological Indicators, 135, 108517.\\n\\n[39] Szatmári, G., Pásztor, L., & Heuvelink, G. B. (2021). Estimating soil organic carbon stock change at multiple scales using machine learning and multivariate geostatistics. Geoderma, 403, 115356.\\n\\n[40] Sothe, C., Gonsamo, A., Arabian, J., & Snider, J. (2022). Large scale mapping of soil organic carbon concentration with 3D machine learning and satellite observations. Geoderma, 405, 115402.\\n\\n[41] Xiao, Y., Xue, J., Zhang, X., Wang, N., Hong, Y., Jiang, Y., ... & Chen, S. (2022). Improving pedotransfer functions for predicting soil mineral associated organic carbon by ensemble machine learning. Geoderma, 428, 116208.\\n\\n[42] Yudhana, A., Sulistyo, D., & Mufandi, I. (2021). GIS-based and Naïve Bayes for nitrogen soil mapping in Lendah, Indonesia. Sensing and Bio-Sensing Research, 33, 100435.\\n\\n[43] Ma, J., Cheng, J., Wang, J., Pan, R., He, F., Yan, L., & Xiao, J. (2022). Rapid detection of total nitrogen content in soil based on hyperspectral technology. Information Processing in Agriculture, 9(4), 566-574.\\n\\n[44] Bulan, R., & Sitorus, A. (2022). Vis-NIR spectra combined with machine learning for predicting soil nutrients in cropland from Aceh Province, Indonesia. Case Studies in Chemical and Environmental Engineering, 6, 100268.\\n\\n[45] Ly, H. B., Nguyen, T. A., & Pham, B. T. (2021). Estimation of soil cohesion using machine learning method: A random forest approach. Advances in civil engineering, 2021, 1-14.\\n\\n[46] Liu, Y., Wang, H., Zhang, H., & Liber, K. (2016). A comprehensive support vector machine-based classification model for soil quality assessment. Soil and Tillage Research, 155, 19-26.\\n\\n[47] Jain, S., & Sethia, D. (2023, May). A Review on Applications of Artificial Intelligence for Identifying Soil Nutrients. In International Conference on Agriculture-Centric Computation (pp. 71-86). Cham: Springer Nature Switzerland.\\n\\n[48] Alvarez, R., Steinbach, H. S., & Bono, A. (2011). An artificial neural network approach for predicting soil carbon budget in agroecosystems. Soil Science Society of America Journal, 75(3), 965-975.\\n\\n[49] Veres, M., Lacey, G., & Taylor, G. W. (2015, June). Deep learning architectures for soil property prediction. In 2015 12th Conference on Computer and Robot Vision (pp. 8-15). IEEE.\\n\\n[50] Datta, D., Paul, M., Murshed, M., Teng, S. W., & Schmidtke, L. (2023). Comparative Analysis of Machine and Deep Learning Models for Soil Properties Prediction from Hyperspectral Visual Band. Environments, 10(5), 77.\\n\\n[51] Heuvelink, G. B., Angelini, M. E., Poggio, L., Bai, Z., Batjes, N. H., van den Bosch, R., ... & Sanderman, J. (2021). Machine learning in space and time for modelling soil organic carbon change. European Journal of Soil Science, 72(4), 1607-1623.\\n\\n[52] Kumar, V., Malhotra, J. S., Sharma, S., & Bhardwaj, P. (2022). Soil Properties Prediction for Agriculture using Machine Learning Techniques. Journal of Engineering Research and Sciences, 1(3), 9-18.\\n\\n[53] John, K., Abraham Isong, I., Michael Kebonye, N., Okon Ayito, E., Chapman Agyeman, P., & Marcus Afu, S. (2020). Using machine learning algorithms to estimate soil organic carbon variability with environmental variables and soil nutrient indicators in an alluvial soil. Land, 9(12), 487.\\n\\n[54] Yao, X., Yang, W., Li, M., Zhou, P., Chen, Y., Hao, Z., & Liu, Z. (2018). Prediction of total nitrogen in soil based on random frog leaping wavelet neural network. IFAC-PapersOnLine, 51(17), 660-665.\\n\\n[55] Ballabio, C. (2009). Spatial prediction of soil properties in temperate mountain regions using support vector regression. Geoderma, 151(3-4), 338-350.\\n\\n[56] Dai, F., Zhou, Q., Lv, Z., Wang, X., & Liu, G. (2014). Spatial prediction of soil organic matter content integrating artificial neural network and ordinary kriging in Tibetan Plateau. Ecological Indicators, 45, 184-194.\\n\\n[57] Spijker, J., Fraters, D., & Vrijhoef, A. (2021). A machine learning based modelling framework to predict nitrate leaching from agricultural soils across the Netherlands. Environmental Research Communications, 3(4), 045002.\\n\\n[58] Zhou, T., Geng, Y., Ji, C., Xu, X., Wang, H., Pan, J., ... & Lausch, A. (2021). Prediction of soil organic carbon and the C: N ratio on a national scale using machine learning and satellite data: A comparison between Sentinel-2, Sentinel-3 and Landsat-8 images. Science of the Total Environment, 755, 142661.\\n\\n[59] Akramkhanov, A., & Vlek, P. L. (2012). The assessment of spatial distribution of soil salinity risk using neural network. Environmental monitoring and assessment, 184, 2475-2485.\\n\\n[60] Rameshar, V., Doorsamy, W., & Paul, B. S. (2022, February). On the use of Machine Learning for Soil Condition Monitoring. In Proceedings of 2nd International Conference on Artificial Intelligence: Advances and Applications: ICAIAA 2021 (pp. 373-382). Singapore: Springer Nature Singapore.\\n\\n[61] Zhang, Y., Li, M., Zheng, L., Qin, Q., & Lee, W. S. (2019). Spectral features extraction for estimation of soil total nitrogen content based on modified ant colony optimization algorithm. Geoderma, 333, 23-34.\\n\\n[62] Chen, D., Lu, Y., Li, Z., & Young, S. (2022). Performance evaluation of deep transfer learning on multi-class identification of common weed species in cotton production systems. Computers and Electronics in Agriculture, 198, 107091.\\n\\n[63] Hussain, N., Farooque, A. A., Schumann, A. W., Abbas, F., Acharya, B., McKenzie-Gopsill, A., ... & Cheema, M. J. (2021). Application of deep learning to detect Lamb’s quarters (Chenopodium album L.) in potato fields of Atlantic Canada. Computers and Electronics in Agriculture, 182, 106040.\\n\\n[64] Sharma, P., Dadheech, P., Aneja, N., & Aneja, S. (2023). Predicting Agriculture Yields Based on Machine Learning using Regression and Deep Learning. IEEE Access.\\n\\n[65] Venkatasaichandrakanth, P., & Iyapparaja, M. (2023). Pest Detection and Classification in Peanut Crops Using CNN, MFO, and EViTA Algorithms. IEEE Access.\\n\\n[66] Ahmed, S., Hasan, M. B., Ahmed, T., Sony, M. R. K., & Kabir, M. H. (2022). Less is more: Lighter and faster deep neural architecture for tomato leaf disease classification. IEEE Access, 10, 68868-68884.\\n\\n[67] Hussain, A., Ahmad, M., Mughal, I. A., & Ali, H. (2018, November). Automatic disease detection in wheat crop using convolution neural network. In The 4th International Conference on Next Generation Computing (Vol. 34, p. 22).\\n\\n[68] Qazi, S., Khawaja, B. A., & Farooq, Q. U. (2022). IoT-equipped and AI-enabled next generation smart agriculture: A critical review, current challenges and future trends. IEEE Access, 10, 21219-21235.\\n\\n[69] PrajwalGowda, B. S., Nisarga, M. A., Rachana, M., Shashank, S., & Raj, B. S. (2020). Paddy crop disease detection using machine learning. International Journal of Engineering Research & Technology, 8(13).\\n\\n[70] Fang, Y., & Ramasamy, R. P. (2015). Current and prospective methods for plant disease detection. Biosensors, 5(3), 537-561.\\n\\n[71] Mohanty, S. P., Hughes, D. P., & Salathé, M. (2016). Using deep learning for image-based plant disease detection. Frontiers in plant science, 7, 1419.\\n\\n[72] Pilli, S. K., Nallathambi, B., George, S. J., & Diwanji, V. (2015, February). eAGROBOT—A robot for early crop disease detection using image processing. In 2015 2nd International Conference on Electronics and Communication Systems (ICECS) (pp. 1684-1689). IEEE.\\n\\n[73] Pantazi, X. E., Moshou, D., & Tamouridou, A. A. (2019). Automated leaf disease detection in different crop species through image features analysis and One Class Classifiers. Computers and electronics in agriculture, 156, 96-104.\\n\\n[74] Chopda, J., Raveshiya, H., Nakum, S., & Nakrani, V. (2018, January). Cotton crop disease detection using decision tree classifier. In 2018 International Conference on Smart City and Emerging Technology (ICSCET) (pp. 1-5). IEEE.\\n\\n[75] Jaware, T. H., Badgujar, R. D., & Patil, P. G. (2012). Crop disease detection using image segmentation. World Journal of Science and Technology, 2(4), 190-194.\\n\\n[76] Priya, L. R., Rajathi, G. I., & Vedhapriyavadhana, R. (2019). Crop disease detection and monitoring system. International Journal of Recent Technology and Engineering (IJRTE), 8(4).\\n\\n[77] Agarwal, M., Singh, A., Arjaria, S., Sinha, A., & Gupta, S. (2020). ToLeD: Tomato leaf disease detection using convolutional neural network. Procedia Computer Science, 167, 293-301.\\n\\n[78] Franke, J., & Menz, G. (2007). Multi-temporal wheat disease detection by multi-spectral remote sensing. Precision Agriculture, 8, 161-172.\"),\n",
       " Document(metadata={'source': 'D:\\\\demo folder\\\\speech.docx'}, page_content=\"You'll never amount to anything. You're crazy. You're not realistic. You work too hard. You're bipolar. You're too cocky. You're all about the money. You're not who you used to be. If you allow the world to label you, the list will be long.\")]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs\n",
    "# docs[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb4efe8",
   "metadata": {},
   "source": [
    "#### PDF Loader: Loads PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c22f5a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(r\"D:\\Homeowrk\\Cloud\\new papaers\\HealthFog An ensemble deep learning based Smart Healthcare System for Automatic Diagnosis of Heart Diseases in integrated IoT and fog computing environments.pdf\")\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8b762601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'D:\\\\Homeowrk\\\\Cloud\\\\new papaers\\\\HealthFog An ensemble deep learning based Smart Healthcare System for Automatic Diagnosis of Heart Diseases in integrated IoT and fog computing environments.pdf', 'page': 0}, page_content='HealthFog: An Ensemble Deep Learning based Smart Healthcare System for Automatic \\nDiagnosis of Heart Diseases in Integrated IoT and Fog Computing Environments  \\n \\nShreshth Tuli1,2, Nipam Basumatary1,3, Sukhpal Singh Gill4, Mohsen Kahani1,5, Rajesh Chand Arya6, Gurpreet Singh Wander6, \\nRajkumar Buyya1 \\n \\n \\n \\n \\nAbstract  \\nCloud computing provides resources over the Internet and allows a plethora of applications to be deployed to provide services  for \\ndifferent industries. The major bottleneck being faced currently in the se cloud frameworks is their limited scalability and hence \\ninability  to cater  to the requirements  of centralized  Internet  of Things  (IoT)  based  compute  environments.  The main  reason  for this \\nis that latency -sensitive applications like health monitoring and  surveillance systems now require computation over large amounts \\nof data (Big Data) transferred to centralized database and from database to cloud data centers which leads to drop in perform ance \\nof such systems. The new paradigms of fog and edge computing provide innovative solutions by bringing resources closer to the \\nuser and provide low latency and energy e fficient solutions for data processing compared to cloud domains. Still, the current fog \\nmodels have many limitations and focus from a limited perspec tive on either accuracy of results or reduced response time but not \\nboth. We proposed a novel framework called HealthFog for integrating ensemble deep learning in Edge computing devices and \\ndeployed it for a real-life application  of automatic  Heart  Disease  analysis.  HealthFog  delivers  healthcare as a fog service using IoT \\ndevices  and efficiently  manages  the data of heart  patients,  which  comes  as user requests.  Fog- enabled  cloud  framework,  FogBus  is \\nused to deploy and test the performance of the proposed  model  in terms  of power  consumption,  network bandwidth,  latency,  jitter, \\naccuracy and execution time. HealthFog is configurable to various operation modes which provide the best Quality of Service o r \\nprediction accuracy, as required, in diverse fog computation scenarios and for di fferent user  requirements.  \\nKeywords: Fog Computing, Internet of Things, Healthcare, Deep Learning, Ensemble Learning, Heart Patient analysis  \\n \\n \\n1. Introduction  \\nFog and Cloud computing paradigms have emerged as a \\nbackbone of modern economy and utilize Internet to provide \\non-demand se rvices to users [1]. Both of these domains have \\ncaptured significant attention of industries and academia. But \\nbecause of high time delay, cloud computing is not a good op- \\ntion for applications requiring real -time response. Technologi - \\ncal developments  like edge  computing,  fog computing,  Internet \\nof Things (IoT), and Big Data have gained importance due to \\ntheir robustness and ability to provide diverse response charac-  \\nteristics based on target application [2].  These emerging tech - \\nnologies provide storage, computation, and communication to \\n \\n1Cloud Computing and Distributed Systems (CLOUDS) Laboratory, \\nSchool of Computing and Information Systems, The University of  Melbourne, \\nAustralia  \\n2Department of Computer Science and Engineering, Indian Institute of \\nTechnology (IIT), Delhi, India  \\n3Department  of Computer Science and Engineering, Indian Institute of \\nTechnology (IIT), Madras,  India  \\n4School of Electronic Engineering and Computer Science (EECS), Queen \\nMary University of London,  UK \\n5Web Technologies Laboratory, Ferdowsi University Of Mashhad, Iran  \\n6Department of Cardiology, Hero Heart Institute, Dayanand Medical \\nCollege and Hospital, Ludhiana, Punjab, India  \\nE-mail addresses: shreshthtuli@gmail.com  (S. Tuli), nipamba - \\nsumatary1@gmail.com  (N. Basumatary), s.s.gill@qmul.ac.uk  (S.S. Gill), \\nkahani@um.ac.ir  (M. Kahani), drrajesh arya@yahoo.com  (R.C. Arya),'),\n",
       " Document(metadata={'source': 'D:\\\\Homeowrk\\\\Cloud\\\\new papaers\\\\HealthFog An ensemble deep learning based Smart Healthcare System for Automatic Diagnosis of Heart Diseases in integrated IoT and fog computing environments.pdf', 'page': 0}, page_content='sumatary1@gmail.com  (N. Basumatary), s.s.gill@qmul.ac.uk  (S.S. Gill), \\nkahani@um.ac.ir  (M. Kahani), drrajesh arya@yahoo.com  (R.C. Arya), \\ndrgswander@yahoo.com (G.S. Wander), rbuyya@unimelb.edu.au (R. Buyya)  edge devices, which facilitate and enhance mobility, privacy, security, low latency, and network bandwidth so that fog com - \\nputing can perfectly match latency -sensitive or real -time appli - \\ncations [2, 6, 10, 12, 27, 40, 45, 46, 47, 48]. Now, cloud com- \\nputing fram eworks  also extend  support  to emerging  application \\nparadigms such as IoT, Fog computing, Edge, and Big Data \\nthrough service and infrastructure [3, 4]. Fog computing uses \\nrouters, compute nodes a nd gateways to provide services with \\nminimum possible energy consumption, network latency and \\nresponse  time.  \\nMutlag et al. [40] explored the challenges of Fog comput - \\ning in healthcare applications and identified that latency  and \\nresponse time are the most important and di fficult to optimize \\nQuality of Service (QoS) parameters in real time fog environ - \\nments. Healthcare is one of the prominent application areas that requires  accurate and real-time results,  and people  have  in- \\ntroduced Fog Computing in this field which leads to a positive \\nprogress. With Fog computing, we bring the resources closer \\nto the users thus decreasing the latency and thereby increas - \\ning the safety measure. Getting quicker results implies fast ac- \\ntions for critical heart patients.  But faster delivery o f results  \\nis not enough as with such delicate data we can not compro - \\nmise with the accuracy of the result. One way to obtain high \\naccuracies is by using state- of-the-art analysis softwares typi-  \\ncally those that employ deep learning and their variants  trained \\non a large  dataset.  In the recent  years,  deep  learning  [5] has \\nPreprint submitted to Future Generation  Computing  Systems  November 15,  2019'),\n",
       " Document(metadata={'source': 'D:\\\\Homeowrk\\\\Cloud\\\\new papaers\\\\HealthFog An ensemble deep learning based Smart Healthcare System for Automatic Diagnosis of Heart Diseases in integrated IoT and fog computing environments.pdf', 'page': 1}, page_content='2  seen an exponential  growth in the fields  ranging from  computer \\nvision [6] to speech recognition, but has more recently been \\nproven useful in natural language processing, sequence  predic - \\ntion, and mixed modality data settings. Moreover, ensemble \\nlearning [7] is used to get the best of multiple classifiers. One \\nof the ensemble methods is called bagging classifier where the \\nestimator  fits trains  the base classifier  on random  subsets of data \\nand then aggregates their individual predictions either by vot- \\ning or by averaging to get the final prediction. Such estimators \\nhelp in reducing the variance as compared to a single estima-  \\ntor by introducing randomization into the dataset distribution \\nprocedure. Another advancement of deep lear ning has been to \\npredict and classify healthcare data with extremely high accu - \\nracies  [5]. However,  recent  deep  learning  models  for healthcare \\napplications are highly sophisticated and require large number \\nof computational  resources  both for training  and prediction  [8]. \\nIt also takes large amount of time to train these complex  neural \\nnetworks  and analyze data using them.  The higher  the accuracy \\nrequired, the more sophisticated the network and higher is the \\nprediction time [9].  This has been a major problem for health - \\ncare and similar IoT applications where it is critical to obtain \\nresults in real- time. As computation on the Edge has the great \\nadvantage of reducing response time, this gives a new direc-  \\ntion of research  of integrating  complex  ensemble deep  learning \\nmodels with Edge Computing such that we obtain high accu - \\nracy results in real -time. One of the fundamental aims of this \\nwork is to bridge this gap and provide a computing platform \\nthat not only provides  low latency  results  by leveraging  edge  re- \\nsources but also is able to use deep learning based frameworks to provide highly accurate results. There has been some work \\nto bring computation to the Edge devices, closer to the patient \\nto reduce result delivery time. Some of these works still de - \\npend on simulations [10] and have not provided a deploy- able \\nframework. This work also aims to fill this void in healthcare industry.  \\nUsually,  detecting  heart  problems  is difficult [49, 50] and \\nmany times people do not even get to know that they are in \\ncritical condition till they get heart related problems like  tachy - \\ncardia or even stroke. Conventionally symptoms of heart prob-  \\nlems are di fficult to identify and requires an experienced doc - \\ntor to observe the patient to ascertain t hat he /she has a heart \\nproblem. This is di fficult to do practically due to shortage of \\ndoctors as most countries still do not trust computer systems to \\nbe able to detect  heart  problems  with the required  accuracy  and \\nexplain -ability [51, 52]. Existing healthcare systems that are \\ndeployed on IoT driven Fog or cloud computing frameworks \\nconnect  pre-configured devices  for patient data processing such \\nthat the results are delivered to users within the deadline time. \\nMany prior works have tried to use IoT to predict health prob- \\nlems  related  to heart  but are unable  to ascertain  with the accura-  \\ncies required by the stringent regulations of medical standa rd- \\nization agencies. In recent past, as deep learning has gained popularity more recent technologies can even surpass doctors in heart disease detection accuracy [53, \\n54]. This work aims to \\nbring together deep learning and IoT in healthcare industry in \\nhope  that it motivates  medical  standardization  agencies  to adopt \\nthis model providing low latency and high accuracy to mitigate  the problem  of lack of doctors.  There  exist  very few works  that \\naim to bring together these two paradigms like [19], but none \\nutilize the distributed nature of edge computing to improve ac- \\ncuracy  by utilizing  ensemble deep  learning  models.  We present'),\n",
       " Document(metadata={'source': 'D:\\\\Homeowrk\\\\Cloud\\\\new papaers\\\\HealthFog An ensemble deep learning based Smart Healthcare System for Automatic Diagnosis of Heart Diseases in integrated IoT and fog computing environments.pdf', 'page': 1}, page_content='aim to bring together these two paradigms like [19], but none \\nutilize the distributed nature of edge computing to improve ac- \\ncuracy  by utilizing  ensemble deep  learning  models.  We present \\nmore comprehensive comparisons i n Sections 2 and 7.9. More - \\nover,  extension  of deep  learning  models  to allow  ensembling of \\nresults is a non trivial extension as it requires careful balance \\nof accuracy improvement and latency in crease to provide the \\nmost  desired  service quality.  Furthermore,  building on previous \\nworks like [2, 19, 46], HealthFog provides a novel architecture \\nfor healthcare computation integrating /harnessing diverse  back- \\nend frameworks like FogBus [27] and Aneka [28] making it a \\nscalable model.  \\nPrior works have reported that there are two major types of \\nhealthcare data collection schemes for heart patients using dif - \\nferent  devices  (IoT sensors and file input  data).  The first is Little \\ndata which  is processed  at fog nodes  and the second  is Big data \\nprocessed at Cloud Data Centers (CDC) [1, 3]. The healthcare \\npatient data is received by the network at high speeds (250  MB \\nper minute or more) [1]. Existing frameworks are not versa - \\ntile enough  to capture and provide  results  for both types  of data \\nscenarios and thus there is a need to utilize edge and cloud re-  \\nsources  in order  to cater  to applications  with these  types  of data \\nvolumes. Data is stored and proc essed on edge nodes or cloud \\nservers after collection and aggregation of data from smart de- \\nvices of IoT  networks.  \\nTo provide e fficient compute services to heart patients and \\nother users requiring real -time results, an integrated Edge -Fog- \\nCloud based computation model is required to deliver health-  \\ncare and other latency sensitive results with low response time, \\nminimum energy consumption and high accuracy. The lack of such models or frameworks that integrate the power of high \\naccuracy of d eep learning models simultaneously with low la- \\ntency of edge computing nodes motivated this work.  \\nIn this work, we propose a Fog based Smart Healthcare Sys - \\ntem for Automatic Diagnosis of Heart Diseases using deep \\nlearning  and IoT called  HealthFog . Health Fog provides  health - \\ncare as a lightweight fog service and effi ciently manages the \\ndata of heart patients which is coming from di fferent IoT de- \\nvices. HealthFog provides this service by using the FogBus \\nframework \\n[27] and de monstrates application enablement and \\nengineering simplicity for leveraging fog resources to achieve \\nthe same.  \\nThe key contributions of this paper are:  \\nProposed  a generic  system  architecture for development  of \\nensemble deep learning on fog  computing  \\nDeveloped  a lightweight automatic  heart  patient data diag- \\nnosis system using ensemble deep learning called Health - \\nFog. \\nDeployed  HealthFog  using FogBus  framework  for integra - \\ntion of IoT -Edge -Cloud for rea l-time data  analysis.  \\nDemonstrated and analyzed the HealthFog deployment in \\nterms of various performance metrics like accuracy, re - \\nsponse time, network bandwidth and energy consumption.  • \\n• \\n• \\n•'),\n",
       " Document(metadata={'source': 'D:\\\\Homeowrk\\\\Cloud\\\\new papaers\\\\HealthFog An ensemble deep learning based Smart Healthcare System for Automatic Diagnosis of Heart Diseases in integrated IoT and fog computing environments.pdf', 'page': 2}, page_content='3  All analysis has been done for heart patient data for pre - \\ndiction if the patient has a heart problem or not.  \\nThe rest of the paper is organized as follows. Section 2 \\npresents related work of existing healthcare systems. Bac k- \\nground of FogBus and Aneka are is provided in Section 3. Pro- \\nposed model  is presented  in Section  4 and its design and imple - \\nmentation is described in Section 5. Section 7 describes the ex - \\nperimental setup and presents the results of performance eval - \\nuation. Section 8 presents conclusions with future work pro - \\nposed.  \\n \\n2. Related  Work  \\n \\nFog computing environment  is an emerging  paradigm  for ef- \\nficient processing of healthcare data,  which  is coming from  dif- \\nferent  IoT devices.  Fog computing  is capable to handle  the data \\nof heart patients at edge devices or fog nodes with large com - \\nputing capacity to reduce latency, response time or delay be- \\ncause edge  devices  are closer  to the IoT devices  than cloud  data \\ncenter.  \\nGia et al. [11]  proposed a Low Cost Health Monitoring \\n(LCHM) model to gather the health information of di fferent \\nheart patients. Moreover, sensor nodes monitor and analyse  the \\nElectro Cardio Graphy (ECG) in a real -time manner for pro - \\ncessing of heart patients data effi ciently, but LCHM has more \\nresponse time which reduces the performance. Further, sen - \\nsor nodes gather ECG, respiration rate, and body temperature \\nand transmits to a smart gateway using wireless communica - \\ntion mode to take automatic decision quickly to hel p patient. \\nOrange Pi One based small -scale testbed is used to test the \\nperformance of LCHM model in terms of execution time, but LCHM consumes more energy during collection and transmis - \\nsion of data. He et al. [12] proposed an IoT based healthcare \\nmanagement  model  called  FogCepCare  to integrate  cloud layer \\nwith sensor layer to find out the health status of heart patients \\nand reduces the execution time of job processing at runtime. \\nFogCepCare uses the partitioning and clusteri ng approach and \\na communication  and parallel  processing policy  to optimize  the \\nexecution time. The performance of FogCepCare is compared with existing  model  using simulated  cloud environment  and op- \\ntimizes the execution time but this work lacks the evaluation \\nof performance in terms of important QoS parameters such as \\npower consumption, latency, accuracy etc. Ali and Ghazal  [13] \\nproposed an IoT e -health service based an  application using \\nSoftware Defined Network (SDN), which collects data through \\nsmartphone in the form of voice control and finds the health \\nstatus of patients. Further, an IoT e -health service finds the \\ntype of heart attack using mobile application based c onceptual \\nmodel but performance of the proposed application is not eval- \\nuated on cloud environments. Akrivopoulos et al. [14]  pro- \\nposed an ECG -based Healthcare (ECGH) system to diagnose \\ncardiac abnormalities  [15] using ECG  but has low accuracy  and \\nhigh response time of detecting abnormal events because they \\nare fetching data directly without using data analytics or other \\nfeature extraction techniques. Further, the data transmission  to cloud se rver in case of large number of requests increases la-  \\ntency  and consumes  more  energy consumption,  which  degrades \\nthe performance of the system. Manikandan et al. \\n[16] pro- \\nposed an Autonomous Monitoring System (AMS) model for \\nInternet of Medical Things (IoMT) to provide healthcare fa - \\ncilities. In this research work, a reward -based mechanism de - \\nsigned which utilizes the Analytical Hierarchy Process (AHP) \\nfor fair distribution of energy among the nodes. The simulated \\ncloud environment is used to test the performance of the AMS \\nmodel in terms of energy consumption and AMS model per- \\nforms better than FGCS method but the communication time \\namong nodes leads to high latency of processing a patient re - \\nquest.'),\n",
       " Document(metadata={'source': 'D:\\\\Homeowrk\\\\Cloud\\\\new papaers\\\\HealthFog An ensemble deep learning based Smart Healthcare System for Automatic Diagnosis of Heart Diseases in integrated IoT and fog computing environments.pdf', 'page': 2}, page_content='model in terms of energy consumption and AMS model per- \\nforms better than FGCS method but the communication time \\namong nodes leads to high latency of processing a patient re - \\nquest.  \\nChoi et al. [17] proposed a Graph- based Attention Model \\n(GRAM) for healthcare representation learning that supple - \\nments electronic health records with hierarchical information \\ninherent to medical ontologies. Further, the performance of GRAM  is optimized  in terms  of training  accuracy.  GRAM  uses \\npredictive analysis to predict the chances of heart attack and \\ncompared the performance of GRAM with Recurrent Neural \\nNetwork (RNN) using very small dataset and performs better than RNN in terms of training accuracy. The performance of GRAM can be degraded in case of large datasets. Nicholas et \\nal. [18] proposed a Smart Fog Gateway (SFG) model for end - \\nto-end analytics in wearable IoT devices and demonstrated the \\nrole of the SFG in orchestrating the process of data condition-  \\ning, intelligent filtering, smart analytics, and selective transfer to the cloud  for long-term storage  and temporal  variability  mon- \\nitoring. SFG model optimizes the performance in terms of exe- \\ncution time and energy consumption, but it does not consider \\nlatency as a performance parameter. Iman et al. [19]  pro- \\nposed Hierarchical Edge- based deep learning (HEDL) based \\nhealthcare IoT system to investigate the feasibility of deploy-  \\ning the Convolutional  Neural  Network  (CNN)  based  classifica-  \\ntion model as an example of deep learning methods.  Further,  a case study of ECG classifications is used to test the perfor-  \\nmance of proposed system in terms of accuracy and execution \\ntime. Liangzhi et al. [20] proposed Fog based E fficient Manu - \\nfacture Inspection  (FEMI) system  using deep  learning  for smart \\nindustry to process a large amount of data in an e fficient man- \\nner. Further, FEMI system adap ts the CNN model to the fog \\ncomputing environment, which significantly improves its  com- \\nputing e fficiency and optimizes the performance only in terms \\nof testing  accuracy.  \\nMahmud et al. [21]  proposed a Fog- based IoT-Healthcar e \\n(FIH) solution structure and explore the integration of Cloud - \\nFog services in interoperable Healthcare solutions extended \\nupon the traditional Cloud- based structure. Further, iFogSim \\nsimulator [43] is used to test the performance of FIH solution \\nin terms of power consumption and latency only. The perfor - \\nmance of FIH solution can be evaluated in terms of execution \\ntime and accuracy. Rabindra and Rojalina [22] proposed a  fog- \\nbased machine learning model for smart system big data an- \\nalytics called FogLearn for application of K -means clustering \\nin Ganga River Basin Management and real -world feature data \\nfor detecting diabetes patients su ffering from diabetes melli - \\ntus. A lvin et al. [23] proposed a Scalable and Accurate deep'),\n",
       " Document(metadata={'source': 'D:\\\\Homeowrk\\\\Cloud\\\\new papaers\\\\HealthFog An ensemble deep learning based Smart Healthcare System for Automatic Diagnosis of Heart Diseases in integrated IoT and fog computing environments.pdf', 'page': 3}, page_content='4   \\n \\nWork  Fog \\nComputing   \\nIoT Deep  \\nLearning  Ensemble  \\nLearning  Heart Disease  \\nPrediction \\nSystem  Performance Parameters  Power  Latency  Jitter  Testing  Training  \\nConsumption   Execution  \\nTime  Arbitration  \\nTime  Network  \\nBandwidth   Accuracy  Accuracy  \\nLCHM [11] ✓       ✓      \\nFogCepCare [12] ✓       ✓      \\nIoT e -health service[13]   ✓   ✓         \\nECGH [14] ✓ ✓          ✓  \\nAMS [16]  ✓    ✓        \\nGRAM [17]   ✓  ✓        ✓ \\nSFG [18] ✓ ✓    ✓  ✓      \\nHEDL [19] ✓ ✓ ✓     ✓     ✓ \\nFEMI [20] ✓  ✓         ✓  \\nFIH [21] ✓ ✓    ✓ ✓       \\nFogLearn [22]   ✓           \\nSADL [23]   ✓         ✓  \\nCoSHE [39]  ✓            \\nEOTC [41] ✓ ✓            \\nSLA -HBDA [42]        ✓    ✓  \\nCFBA [43] ✓      ✓       \\nHealthFog (this work)  ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ \\n \\nTable 1: Comparison of existing models with HealthFog \\n \\nlearning (SADL) model with electronic health records of pa- \\ntients based on the Fast Healthcare Interoperability Resources \\n(FHIR) format. The deep learning methods in SADL model \\nusing FHIR representation are capable of accurately predict - \\ning multiple medical events from multiple centers without site- \\nspecific data harmonization. Further, proposed approach is  val- \\nidated  using de-identified  Electronic  Health  Record  (EHR) data \\nfrom two US academic medical centers with 216,221 adult pa - \\ntients hospitalized for at least 24 hours and improves the ac- \\ncuracy of predictio n. Table 1 compares the proposed model \\n(HealthFog) with existing  models.  \\nPham et al. [39] proposed a Cloud- based Smart Home En - \\nvironment (CoSHE) to deliver home healthcare to provide hu - \\nmans co ntextual information and monitors the vital signs  using \\nrobot assistant. Initially, CoSHE uses non- invasive wearable \\nsensors to gather the audio, motion and physiological signals and delivers  the contextual  information  in terms  of the residents \\ndaily activity. Further, the CoSHE allows healthcare profes - \\nsional s to explore behavioural changes and daily activities of a \\npatient to monitor the health status periodically. Moreover, the \\ncase study of robotic assistance is presented to test the perfor - \\nmance of CoSHE by utilizing Google APIs. However, CoSHE is general  healthcare application to collect and process patient \\ndata at small  scale without  data analytics  and they have  not eval- \\nuated  on real cloud  environment  to test its performance  in terms \\nof QoS  parameters.  \\nAlam et al. [41] proposed a general Edge -of-Things  Compu - \\ntation  (EoTC) framework  for healthcare service provisioning to \\noptimize the cost of data processing. Further, a portfolio opti - \\nmization solution is presented for the selection of Virtual Ma-  \\nchines (VMs) and designed Alternating Direction Method of \\nMultipliers (ADMM) based distributed provisioning technique \\nfor efficient processing of healthcare data. Further, experimen - \\ntal results demonstrate that EoTC framework performs better \\nthan greedy  approach  in terms  of cost, but this framework  lacks \\nin performance evaluation in terms of QoS  parameters.  \\nSahoo et al. [42] proposed a Service Level  Agreement  (SLA) \\nbased Healthcare Big Data Analytic (SLA -HBDA)  architecture \\nto perform  the ranking of patients  data,  which  improves  its pro- cessing speed. Further, an e fficient data distribution technique \\nis developed to allocate batch and streaming data using Spark \\nplatform to predict the health status of the patient.  SLA-HBDA \\narchitecture improves the performance in terms of accuracy as \\ncompared to Naive -Bayes (NB) algori thm but it does not con-  \\nsider latency and other important QoS  parameters.  \\nAbdelmoneem et al. [43] proposed a Cloud- Fog Based Ar - \\nchitecture (CFBA) for IoT based healthcare applications to \\nmonitor the health status of the pat ience. Further, a task \\nscheduling and allocation mechanism is proposed for the pro - \\ncessing  of healthcare data by distributing  the healthcare tasks in'),\n",
       " Document(metadata={'source': 'D:\\\\Homeowrk\\\\Cloud\\\\new papaers\\\\HealthFog An ensemble deep learning based Smart Healthcare System for Automatic Diagnosis of Heart Diseases in integrated IoT and fog computing environments.pdf', 'page': 3}, page_content='monitor the health status of the pat ience. Further, a task \\nscheduling and allocation mechanism is proposed for the pro - \\ncessing  of healthcare data by distributing  the healthcare tasks in \\nan efficient  manner.  The performance of CBFA  is evaluated  us- \\ning iFogSim simulator \\n[44] in terms of only latency. Research \\nwork  [39, 41, 42, 43] developed general  healthcare  applications \\nat small scale and none of the work focused on heart patient - \\nbased healthcare application to diagnose the health status of \\nheart  patients.  \\nSanaz et al. [46] proposed an end- to-end security scheme  for \\nmobility enabled healthc are IoT, which uses Datagram Trans - \\nport Layer  Security  (DTLS) handshake  protocol  to establish  se- \\ncure communication among various interconnected smart gate - \\nways without requiring any reconfiguration at the device layer. \\nFurther, the proposed scheme is i mplemented using simulation \\nenvironment  (Cooja)  and demonstrate  that the proposed  scheme \\nis effective in reducing communication overhead by 26% and \\nlatency by 16%. Building on this work, HealthFog aims to deploy healthcare applications on real systems and fog nodes \\nproviding a more promising solution.  \\nAmir et al. [2]  proposed a system called Smart e- Health \\nGateway to exploit the strategic position of such gateways at \\nthe edge  of the network to provide  various  services  such as em- \\nbedded data mining, real -time local data processing and local \\nstorage. Further, it distributes the burden of various sensors by \\ncreating  a Geo-distributed  intermediary  layer  of intelligence  be- \\ntween C loud and sensor nodes, which increases the reliability, \\nenergy  efficient  and scalability.  Further,  proposed system  is val- \\nidated using an mobile application of IoT -based Early Warning \\nScore  (EWS) health  monitoring.  Building  on this work,  Health - \\nFog architecture  provides  additional features  of being able to'),\n",
       " Document(metadata={'source': 'D:\\\\Homeowrk\\\\Cloud\\\\new papaers\\\\HealthFog An ensemble deep learning based Smart Healthcare System for Automatic Diagnosis of Heart Diseases in integrated IoT and fog computing environments.pdf', 'page': 4}, page_content='5  use distributed deep learning models in ensembling fashion to \\nfurther increase the prediction accuracy and provide more pre - \\ncise results for critical heart patients.  \\nThere  is a need  to solve  the following challenges  [24, 25, 11, \\n12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 26, 39, 42, 43, 44] \\nto recognize the full capability of IoT based fog- computing for \\nhealthcare systems: (a) An effi cient IoT based Healthcare ap - \\nplication is needed which can process a large amount of heart patients data with minimum energy consumption and low re- \\nsponse time, (b) a well -organized resource scheduling tech - \\nnique is needed for fog computing environments to execute user workloads  with maximum  resource utilization  to fulfill  the \\ndeadline of workloads and (c) ensemble deep learning based \\nfog computing model to automatically diagnose the heart dis - \\nease severity in patients in  real-time.  \\n \\n3. Background  Technologies  \\nFogBus  [27] is a framework  for development  and deployment \\nof integrated Fog -Cloud environments with structured commu - \\nnication and platform independent execution of applications. FogBus connects various IoT sensors which can be healthcare sensors with gateway devices to send data and tasks to fog \\nworker nodes. The resource management and task initiation is \\ndone  on fog broker  nodes.  To ensure  data integrity,  privacy  and \\nsecurity, FogBus uses blockchain, authentication and encryp - \\ntion techniques which increase the reliability and robustness of the fog environment. FogBus uses HTTP RESTful APIs for \\ncommunication and seamlessly integrates fog setup with Cloud \\nusing Aneka software platform  [28].  \\nAneka [28] is a software platform and framework facilitat-  \\ning the development and deployment of distributed applica - \\ntions onto clouds. Aneka provides developers with APIs for \\nexploiting  virtual resources  on the cloud.  The core comp onents \\nof the Aneka framework are designed and implemented in a \\nservice- oriented fashion. Dynamic provisioning is the ability \\nto dynamically acquire resources and integrate them into ex- \\nisting infrastructures and software systems. In the most com - \\nmon case, resources  are Virtual Machines  (VMs)  acquired  from \\nan Infrastructure -as-a-Service (IaaS) cloud provider. Dynamic \\nprovisioning in Aneka  happens  as part of the Fabric  Services  by \\noffering provisioning services for allocating virtual nodes  from \\npublic clou d providers to complement local resources. This is \\nmainly achieved as a result of the interaction between two ser - \\nvices: the Scheduling Service and the Resource Provisioning \\nService. Aneka currently supports four di fferent programming \\nmodels [28]:  Bag of tasks model, Distributed threads model, \\nMapReduce model, and Parameter sweep model. In Health - \\nFog, we used the Bag of tasks model  for task distribution  across \\ncloud VMs. HealthFog uses FogBus to harness fog resources \\nand Aneka to harness cloud resources.  \\n \\n4. System  Architecture \\nThe HealthFog model is an IoT based fog -enabled cloud  \\ncomputing model for healthcare, which can manage the data  of heart patients e ffecti vely and diagnose the health status to \\nidentify heart disease severity. HealthFog integrates diverse \\nhardware instruments through software components and allows \\nstructured and seamless end -to-end integration of Edge -Fog- \\nCloud for fast and accurate deliver y of results.  Figure  1 presents \\nthe architecture of HealthFog  which  comprises  of various  hard- \\nware and software components that are described  next.  \\n \\n4.1. HealthFog hardware components  \\nThe HealthFog  model  comprises  of following  hardware  com- \\nponents:  \\n1. Body Area Sensor Network : Three di fferent types of \\nsensors constitute this component: medical sensors, ac- \\ntivity sensors and environment sensors. Medical sensors \\ninclude Electro Cardio Gram (ECG) sensor, Electro En- \\ncephal o Gram (EEG) sensor, Electro Myo Graphy (EMG)'),\n",
       " Document(metadata={'source': 'D:\\\\Homeowrk\\\\Cloud\\\\new papaers\\\\HealthFog An ensemble deep learning based Smart Healthcare System for Automatic Diagnosis of Heart Diseases in integrated IoT and fog computing environments.pdf', 'page': 4}, page_content='tivity sensors and environment sensors. Medical sensors \\ninclude Electro Cardio Gram (ECG) sensor, Electro En- \\ncephal o Gram (EEG) sensor, Electro Myo Graphy (EMG) \\nsensor, oxygen level sensor, temperature sensor, respira - \\ntion rate sensor and glucose level sensor. This component \\nsenses the data from heart patient and transfers to con - \\nnected gateway  devices.  \\n2. Gateway: Ther e are three di fferent types of Gateway de-  \\nvices  (mobile  phones,  laptop  and tablets),  which  are acting \\nas a fog device to collect  sensed  data from  different  sensors \\nand forward this data to Broker /Worker nodes for further \\nprocessing.  \\n3. FogBus Modules : The FogBus framework comprises of \\nthe following:  \\n(a) Broker node: This component receives the job re - \\nquests and/ or input data from Gateway devices. Re - \\nquest input module receives job requests from Gate - \\nway devices just before transferring the data. Se - \\ncurity  Management  module  provides  secure  commu - \\nnication between di fferent components and protects \\nthe collected data from unauthorized access or ma - \\nlicious tampering of data to improve system credi - \\nbility  and data integrity. Arbitration module (part of \\nResource  Manager  in broker  node)  takes  as input  the \\nload statistics of all worker nodes and decides  which \\nnode or subset of nodes to send jobs to in real  time.  \\n(b) Worker node : This is the component that performs \\ntasks allocated by the Resource Manager of the Bro - \\nker node. Worker nodes can comprise of embed - \\nded devices and Single Board Computers (SBC)  like \\nRaspberry Pis. In HealthFog, Worker nodes can  con- \\ntain sophisticated deep learning models to process \\nand analyse  the input  data and generate results.  Apart \\nfrom  this, the Worker  node  can include  other  compo - \\nnents for data processing, data filtering and mining, \\nBig Data analytics and storage. The Worker nodes \\ndirectly  get the input  data from  the Gateway  devices, \\ngenerate results and share with the same. In Health - \\nFog model, the Broker node can also behave as a \\nWorker  node.  \\n(c) Cloud Data  Center:  When  the fog infrast ructure  be- \\ncomes  overloaded,  services  are latency  tolerant or the \\ninput  data size is much  larger  than average  size, then'),\n",
       " Document(metadata={'source': 'D:\\\\Homeowrk\\\\Cloud\\\\new papaers\\\\HealthFog An ensemble deep learning based Smart Healthcare System for Automatic Diagnosis of Heart Diseases in integrated IoT and fog computing environments.pdf', 'page': 5}, page_content='6  FogBus based edge/fog computing environment  \\n \\nPatient  Doctor   \\nFigure 1: HealthFog Architecture  \\n \\n \\n \\n \\nFigure 2: Resource Scheduling in HealthFog  \\n \\n \\nHealthFog harnesses resources of Cloud Data Cen - \\nters (CDC). This makes it more robust, capable of \\nperforming heavy load tasks quickly and also makes \\ndata processing location  independent.  \\n \\n4.2. HealthFog software components  \\nThe HealthFog model comprises of the following software \\ncomponents:  \\nData filtering and pre -processing : The first step after \\ndata input is to pre -process it. This includes data filter - \\ning using data analytics tools. The filtered data is re - \\nduced to a smaller dimension using Principal Compo -  \\nnent Analysis  (PCA)  using Set Partitioning  In Hierarchical  Trees (SPIHT) algorithm [29] and encrypted using Singu - \\nlar Value Decomposition (SVD) technique [30] with the \\ngoal of extracting key components of data feature vectors \\nthat a ffect the health sta tus of patients. Based on the ex - \\ntracted data, it automatically makes the decision, which \\nrecommends medication and suitable check -up based on \\nthe continuous training data of healthcare providers and doctors and stores in database for re -training when re- \\nquired.  \\n \\nResource Manager: This comprises of two modules: \\nworkload manager and arbitration module [27].  Work - \\nload manager maintains job request and task queues for data processing. It also handles bulk of data which needs \\nto be processed. The Arbitration module schedules the provisioned fog or cloud resources for processing of tasks \\nqueued and maintained  by the workload manager.  Arbitra - \\ntion module resides in the Br oker node and decides which \\nFog computing node should be forwarded the data to ob - \\ntain the results, the Broker itself, Fog worker node or the \\nCloud Data Center [27].  The main goal is to divide tasks \\nto different devices to balance load and provide optimum \\nperformance.  HealthFog  allows  users to set their own load \\nbalancing and arbitration schemes based on the applica - \\ntion requirements. The current scheme is described as a \\nflowchart in Figure  2. \\n \\nDeep learning Module : This module uses the dataset to \\ntrain a Neural Network to classify data -points which are \\nfeature vectors obtained after pre- processing the data ob - \\ntained from the Body Area Sensor Network. Based on the task allocated by the Resource Manager, it also pre dicts \\nand generates results for the data obtained from the Gate - \\nStart  \\nInitialize threshold  based  \\npast workload  \\nInput task T and  \\nWorker loads L 1, .. , Ln \\nmin(L 1, .., L n) > \\nthreshold?  Yes Send T  \\nto cloud  \\nNo \\nSend  T to argmin workers (Worker  Loads)  \\n1 = Training  Job/result  \\nFogBus Worker 1  \\n2 = Testing  \\nJob request/  \\nArbitration \\nresult  \\n2 Load  \\nstatistics  \\n \\n2 \\n.. \\nJob/result  \\n2 Load  \\nstatistics  \\n2 \\nGateway  \\ndevice  1 \\nUpdate Model  \\n1 Using Aneka  \\nTest Data  \\nSample Data  \\nand results  Job/result  \\nForwarding  Cloud \\nIntegrator  FogBus Broker  \\nSensor 3  Activity level  Blood pressure  \\n \\nGlucose level  Sensor 2  EEG  \\nECG \\nEMG  Sensor 1  Respiration Rate  Blood Oxygen  \\n \\nHeart Rate  \\nFogBus Worker n   \\n \\n.. \\n \\n \\n \\nCloud  \\nHeart Patient \\nData Knowledge \\nBase  Deep \\nLearning \\nModel  Resource \\nMonitor  Resource  \\nManager   \\nData Manager  Deep \\nLearning \\nModel  Security \\nManager  Resource \\nMonitor  \\n• • \\n•'),\n",
       " Document(metadata={'source': 'D:\\\\Homeowrk\\\\Cloud\\\\new papaers\\\\HealthFog An ensemble deep learning based Smart Healthcare System for Automatic Diagnosis of Heart Diseases in integrated IoT and fog computing environments.pdf', 'page': 6}, page_content='7  \\nway devices.  \\nEnsembling  Module : This module  receives  prediction  re- \\nsults from di fferent models and uses voting to decide the \\noutput  class  which  is whether  the patient has heart  disease \\nor not. This module resides in the FogBus node which is \\nassigned the task and is responsible for distributing data \\nand collecting results from other worker  nodes.  \\n \\n4.3. HealthFog topology  \\nThe HealthFog components described previously share  large \\namount of data, information and control signals among them - \\nselves. To facilitate this stable network communication is nec - \\nessary.  In addition,  the communication  should be persistent  and \\nfault- tolerant.  Taking  all these  into account,  the components  are \\nstructured  in a topology  shown  in Figure  1. The communication \\nacross all devices on the Edge is facilitated using FogBus [27]  \\nand that with Cloud VM is using Aneka  [28].  \\nThe Network  topology  in HealthFog  follows  Master -Slave  fash- \\nion where  the Broker  Node  (Master)  controls  the Worker  Nodes  load checks need to be done. In non- cloud case, the Gateway \\ndevice sends job i.e. input data for analysis to Worker /Broker \\nnode  which  then run pre-processing,  prediction  model  and send \\nresults back to Gateway device. In cloud forwarding case, as the Gateway device may not be on the VPN, so it sends the in - \\nput data to Broker  node  which  then forwards  it to the CDC.  This \\nalso ensures that the IoT sensors and gateway devices are pro - \\ntected from malicious entities and hackers as they may not be \\nconnected to Internet but only the LAN with other Fog nodes. \\nDue to larger  resource availability  at Cloud,  the Execution time \\nis expected to be lower but latency higher due to communi - \\ncation overheads and queuing delay at both Broker and CDC. \\nWhen ensemble is enabled then the data received by the Bro - \\nker/worker node is forwarded to all other edge nodes and ma- \\njority class is c hosen by the worker node to which the data was \\nsent using bagging.  \\n(Slaves). In HealthFog all the edge devices including the Gate - \\nway devices, Broker node and Worker nodes are present in the \\nsame  Local  Area  Network  (LAN).  The Resource  Manager  soft- \\nware component resides in the Broker Node and thus the  Gate - Gateway  Broker  \\n \\nJob request  \\n \\na Worker  Cloud  \\nway devices send job requests to it. The arbitration results ob - \\ntained from the Resource Manager is received by the Gateway \\ndevice which instructs it where to send the data. Three sce-  \\nnarios arise here: (1) Broker processing data as Worker Node,  \\n(2) Another Worker node to send data and (3) Cloud Data  Cen- \\nter based processing. Based on the scenario, the Gateway de - \\nvice may send the data directly to Worker node or Broker  node \\n(with /without cloud forwarding). Broker may provide compu - \\ntation servic es for tasks only when it has suffi cient resources \\nand/or the worker nodes are overloaded. If the data is to be  for- \\nwarded to Cloud, then it goes through the Broker node as the \\nGateway may not have access to the Virtual Private Network \\n(VPN) in which the Cloud Virtual Machine is present. Apart \\nfrom  this, the Worker  nodes  periodically  send heartbeat  packets \\nto the Broker to indicate that they are alive. These packets also \\ninclude load information that is used by the Resource manager \\nfor load  balancing.   \\n \\n \\nBroker \\nOnly  e \\n \\n \\n \\nf \\n   \\n \\n \\n \\n \\n \\n \\n  \\nWorker  \\ne \\n \\n \\n \\nf Master IP  \\n \\nJob \\n  \\n \\n \\n \\nresult  \\n \\n \\nJob request  \\n \\n \\n \\n \\n \\nWorker IP  \\n \\nJob \\n  \\n \\n  \\nresult    \\n \\nb \\nc \\nRun prediction \\nd \\n \\n \\n \\n \\nLoad request  \\n \\n \\na \\nreturn  \\n \\n \\n \\nb \\nc \\nRun prediction  \\n   d \\n \\n4.4. Sequence of  communication  \\nIn HealthFog, all hardware components interact based on \\npredefined protocols described in Figure 3 for the three sce- \\nnarios defined earlier: Broker Only, Worker  Node or Cloud.  \\nIn every scenario the Gateway fir st sends a Job request to the'),\n",
       " Document(metadata={'source': 'D:\\\\Homeowrk\\\\Cloud\\\\new papaers\\\\HealthFog An ensemble deep learning based Smart Healthcare System for Automatic Diagnosis of Heart Diseases in integrated IoT and fog computing environments.pdf', 'page': 6}, page_content='predefined protocols described in Figure 3 for the three sce- \\nnarios defined earlier: Broker Only, Worker  Node or Cloud.  \\nIn every scenario the Gateway fir st sends a Job request to the \\nBroker node. Based on the scenario, the Broker node sends  \\nthe Gateway either the Worker IP address (of the same LAN) \\nor Master IP address (with /without cloud forwarding). In the \\nBroker only case, the Broker node may or may not check  loads \\nof workers. If all workers have heavy loads or all are compro-  \\nmised  and Cloud is disabled,  then the Broker  sends  the Gateway   \\n \\n \\n \\n \\n \\n \\n \\n \\nCloud e \\n \\n \\n \\n \\n \\n \\nf  \\nJob request  \\n \\na \\nCloud \\nJob \\ng \\n  \\n \\n \\n \\n \\n \\n \\n \\nresult    \\n \\n \\n \\n \\n \\n \\n \\nJob \\n \\n \\n \\n \\n \\nresult         \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nc \\nRun prediction \\nd \\ndevices its IP without cloud forwarding. If there exist work - \\ners not heavily loaded then the Broker sends the IP address of \\nleast loaded  Worker  node  to the Gateway  device.  Increasing  the a = Arbitration time \\nb = Job upload time \\nc = Queuing delay  d = Execution time \\ne = Latency  f = Total execution time  \\ng = Broker queuing delay  \\nnumber of Workers would increase the arbitration time as more Figure 3: Communication sequence in HealthFog  •'),\n",
       " Document(metadata={'source': 'D:\\\\Homeowrk\\\\Cloud\\\\new papaers\\\\HealthFog An ensemble deep learning based Smart Healthcare System for Automatic Diagnosis of Heart Diseases in integrated IoT and fog computing environments.pdf', 'page': 7}, page_content='8  \\nNew \\nHeart \\nPatient \\nData  5. HealthFog  Design  \\nThe fog computing model described in Section 4 takes heart \\npatient data as input from the sensors and sends back results \\nwhich comprise of whether the patient has heart disease or not, \\nwith the confidence of the claim. This is implemented with components which include data pre -processing modules, en- \\nsemble  deep  learning  modules  and gateway  interface described \\nnext.  \\n \\n5.1. Heart Patient Data  pre-processing  \\nThe data obtained from common pule -oximeters or ECG  de- \\nvices is in plain graphical format and needs to be  pre-processes \\nto find values of many features of the input to the deep learn - \\ning model [31, 32]. This requires application specific domain \\nknowledge to be fed into the system. Normalising the age data \\nas it was slightly skewed as shown in Figure 4.  Similarly, the \\nRest Blood Pressure  (BPS)  data is also skewed  and patients  hav- \\ning a heat disease showed a higher blood pressure compared to patients  not having a heart  disease.  Patient cholesterol  levels   \\n \\nTraining data \\nand results  \\n \\n \\n \\n \\nNew data Training  \\nDeep Learning Model Updated parameters  \\n \\n  \\n \\n \\n \\nTesting  \\nForward Pass  Prediction output  \\n \\n \\n    \\nPrediction \\nresult  \\n  \\n \\n \\nGateway  \\nalso show some target specific behavior, the healthy patients \\ndistribution is leptokurtic. Even with maximum heart rate, \\nhealthy people have quite higher maximum heart rate (around \\n160) compared to those with heart disease (around 150). Other features like  chest pain and fasting blood sugar had to be con-  \\nverted from continuous values to categorical values. Also, the \\nslope of the peak exercise ST segment and the heart status as \\nretrieved from Thallium test.  \\n \\n5.2. Ensemble Deep learning Application  \\nWe have  used an ensemble  of deep  neural  network  as a model \\nfor the predictive analysis, and for our application the model  \\nis used for binary classification problem. The model is first \\ntrained on the heart patient data in the Cleveland Dataset and \\ncorresponding known output class and then the trained model \\nis used for predicting  results  of real time data input  as shown  in \\nFigure  5. \\nWe divide the data into tr aining, validation and testing set in \\nthe ratio of 70:10:20. The training set is used for training the model, the validation set is used for tuning the model and the \\ntest set is used for testing  how the model  performs  on new data. \\nThe trained  model  can be stored  in all the nodes  which  are capa- \\nble of processing by first storing in a common database.  Other  \\n \\n \\n \\nFigure 4: Age distribution  Body Sensor Network  \\n \\nFigure 5: Training and Testing of the application  \\n \\n \\napproach can be to train models separately by distributing the \\ntraining dataset points across di fferent models. In distributed \\ntraining, data distribution uses techniques like boosting which \\nrandomly samples data from the dataset with replacement and \\nsends  to different  edge  nodes  for training  individual  models  [7]. \\nAt diagnosis time, whenever a node is assigned a task, it gets \\nthe patients data which is a vector of size 13. This data is fed \\nas input to the model, makes a forward pass on the deep neu-  \\nral network and outputs 1 or 0 i.e whether the patient has heart \\ndisease or not. At diagnosis time, we use the ensemble method \\nof Bagging to combine the results of various models to provide \\nmore  accurate results.  The worker  that gets the input  data multi-  \\ncasts  it to other  worker  nodes.  Each  worker  then adds this to its \\nqueue and the prediction results of each worker node are sent \\nback to the worker assigned for this task. Then the majority \\nprediction  class  obtained in by bagging is sent it to the gateway \\ndevice. HealthFog allows users to disable this feature when  the \\nresults needed are latency critical. In Section 7 we show that \\nensemble learning gives better accuracies but also has higher \\nresponse time and network overheads.'),\n",
       " Document(metadata={'source': 'D:\\\\Homeowrk\\\\Cloud\\\\new papaers\\\\HealthFog An ensemble deep learning based Smart Healthcare System for Automatic Diagnosis of Heart Diseases in integrated IoT and fog computing environments.pdf', 'page': 7}, page_content='results needed are latency critical. In Section 7 we show that \\nensemble learning gives better accuracies but also has higher \\nresponse time and network overheads.  \\n \\n5.3. Android interface and Communication  \\n \\nAn android executable named FastHeartTest was used in the \\nGateway device to send data to the Broker /Worker nodes. The \\napplication interface is shown in Figure 6.  This application al- \\nlows the Gateway to act as a mediator between the Body Sen - \\nsor Network and the Worker nodes. The co mmunication is \\nachieved using HTTP RESTful APIs. We used HTTP POST to \\nupload  input  data from  and download  results  to the Gateway  de- \\nvice. Each Worker node, the Broker node and CDC contains a \\npre-trained deep learning model and pre -processing softwares.  Heart \\nDisease \\nor not  Sample \\nHeart \\nPatient \\nData  \\nHeart Patient  Data'),\n",
       " Document(metadata={'source': 'D:\\\\Homeowrk\\\\Cloud\\\\new papaers\\\\HealthFog An ensemble deep learning based Smart Healthcare System for Automatic Diagnosis of Heart Diseases in integrated IoT and fog computing environments.pdf', 'page': 8}, page_content='9   \\n \\nFigure 7: Di fferent modules in HealthFog  \\n \\n \\n \\n \\n \\n  \\n \\n \\n \\n \\n \\n(a) Negative example  (b) Positive  example  \\n \\nFigure 6: Gateway Interface of HealthFog  \\n \\n \\n6. Implementation  \\nThe components mentioned in Section 5 were implemented \\nin various programming languages. The pre -processing and \\nensemble deep learning components were implemented using \\nPython. The pre -processing module normalizes the data bas ed \\non the maximum and minimum values of the field parameters \\nin the dataset and their distribution.  \\nThe ensemble deep  learning  application  used SciKit learn  Li- \\nbrary [33]. We have used BaggingClassifier of the SciKit learn \\nLibrary to implement our voting scheme. The model takes the \\ntype of base classifier  which  is deep  neural  network  in our case \\nand the number  of classifiers  as input.  Now the model  randomly \\ndistributes the data among the classifiers to train them. At di- \\nagnosis time it takes all predicted classes as input and outputs \\nthe majority  prediction.  The following  are the parameters  of the \\nbest base model on our data set after  tuning:  \\n• Size o f input layer: 13 (number of features of the  data)  \\nSize of output layer: 2 (Binary classification; whether the \\npatient has heart disease or not)  \\n• Number of hidden layers:  3 \\nLayer descriptions: Fully connected (FC) layer with 20 nodes,  FC layer  with 20 nodes  and FC Layer  with 10 nodes  \\n• Optimizer: Adam  \\n• Activation function: ReLU  • Learning rate:  0.0001  \\nThe Android application was built using MIT’s App Inven-  \\ntor1 and communicated with the FogBus Broker node. The an - \\ndroid application saves the data attributes in a Comma Sepa - \\nrated Value (.csv) file and uploads it to the broker node using \\nHTTP POST to the Data Catalogue Module.  \\nThe broker node also has an Arbitrati on Module which de - \\ncides which worker node to select for task execution. This \\nworker  selection  process  is done  as per the default  FogBus  pol- \\nicy of selecting worker with minimum CPU load. Whichever worker is selected, is sent the CSV file for analysis. T he Ex- \\necution Interface Module in each worker receives the data and instantiates the Ensemble Deep Learning code for analysis of \\nthe data. The returned result is sent back to the Worker /Broker \\nnode  which  sent the data file. The result  is ensembled  using the \\nbagging strategy  and forwarded  to the gateway  device (android \\napplication).  \\nA diagrammatic  representation  of different  modules  and their \\ninteraction is shown in Figure  \\n7. \\n \\n7. Performance Evaluation  \\nTo demonst rate the feasibility and e fficacy of the proposed \\nHealthFog model, we implemented and deployed it on actual \\nFog framework of devices using the FogBus framework [27].  \\nThe model has been used for a real -world application of de - \\ntecting Heart problems for patients instantly using state -of the \\nart deep learning techniques using a Fog based computing en - \\nvironment. We have analyzed the accuracy and response times \\nwith network and energy  overheads  to show  that the HealthFog \\nmodel is productive and has low  overheads.  \\n \\n7.1. Experimental  Setup  \\nThe system setup for the HealthFog evaluation and the hard - \\nware configurations are described below:  \\n• Gateway Device : Samsung Galaxy S7 with android 9  \\nBroker/ Master  Node : Dell XPS 13 with Intel(R) \\nCore(TM) i5 -7200 CPU @ 2.50GHZ, 8.00 GB  DDR4  \\nRAM  and  64- bit Windows  10. The deployment used \\nApache HTTP Server  2.4.34.  \\n \\n \\n1MIT App Inventor 2: http:// ai2.appinventor.mit.edu / Broker Node  Worker Node  \\nArbitration  Resource  \\nModule  Manager  Resource  Ensemble  \\nMonitor  Module  \\nData Catalog  \\nModule  Result  \\nModule  \\nHTTP REST  HTTP REST  \\nGateway Device  To other worker nodes  Execution \\nInterface Module  \\n• \\n• •'),\n",
       " Document(metadata={'source': 'D:\\\\Homeowrk\\\\Cloud\\\\new papaers\\\\HealthFog An ensemble deep learning based Smart Healthcare System for Automatic Diagnosis of Heart Diseases in integrated IoT and fog computing environments.pdf', 'page': 9}, page_content='10   \\n \\nFigure 8: Real HealthFog deployed model and test setup  \\n \\n \\nWorker Node : Raspberry Pi 3B +, ARM Cortex -A53 \\nquad- core SoC CPU @ 1.4 GHz and 1GB LPDDR2 \\nSDRAM  and IEEE  802.11  Wifi.  Raspbian  Stretch  Operat - \\ning system with Apache HTTP server  2.4.34.  \\nPublic Cloud: Microsoft Azure B1s Machine, 1vCPU, \\n1GB RAM, 2GB SSD, Windows Server 2016.  \\nFigure 8 depicts the real implementation of this system model. \\nDuring the experiments,  data parameters  are recorded  using  Mi- \\ncrosoft Performance Mo nitor at the Master and the Azure VM \\nwhereas  at the Raspberry  Pi circuits  NMON Performance Mon- \\nitor is used [34, 35]. To measure the network bandwidth con- \\nsumption Microsoft Network Monitor 3. 4 was used at the Bro - \\nker node [36] and the vnStat [37] tool in Raspberry Pis. \\n7.2. Dataset  \\nFor the experimental results, we have considered the data of \\nheart  patients  to find the presence of heart  disease  in the patient \\n[26, 38, 31, 32], which is an integer valued 0 (no presence) or \\n1 (presence). The Cleveland database [26] is used to conduct \\nthe experiments which was created by Andras Janosi (M.D.) at \\nthe Gottsegen Hungarian Institute of Cardi ology, Hungary and \\nothers. The patient names and their patient numbers are kept \\nconfidential. We have used 14 important attributes of data to \\nfind out the status of patient health: (1) age: age in years, (2) \\nsex: two values (1 = male; 0 = female), (3) cp: chest pain  type:  \\n- Value 1: typical angina –  Value 2: atypical angina –  Value 3: \\nnon-anginal pain – Value 4: asymptomatic, (4) trestbps: rest - \\ning blood  pressure  (in mm Hg on admission  to the hospital),  (5) \\nchol:  serum cholesterol in mg /dl, (6) fbs:  (fasting blood  sugar  \\n> 120 mg/ dl) (1 = true; 0 = false), (7) restecg: resting electro - \\ncardiographic results –  Value 0: normal – Value 1: having  ST-T \\nwave  abnormality  (T wave  inversions  and/or ST elevation  or de- \\npression  of > 0.05 mV) – Value  2: showing probable  or definite \\nleft ventricular  hypertrophy by Estes’  criteria,  (8) thalach:  max- \\nimum heart rate achieved, (9) exang: exercise induced angina (1 = yes; 0 = no), (10) oldpeak = ST depression induced by \\nexercise relative to rest, (11) slope: the slope of the peak exer - \\ncise ST segment –  Value 1: upsloping – Value 2: flat –  Value \\n3: downs loping, (12) ca: number of major vessels (0- 3) col- \\nored by flourosopy, (13) thal:  3 = normal; 6 = fixed defect;  7 \\n= reversable defect,  (14) target (num):  diagnosis of heart dis - \\nease (angiographic disease status) –  Value  0:  < 50% diameter  narrowing – Value 1: > 50% diameter narrowing (in any major \\nvessel). Table 2 describes the details of just 10 heart patients.  \\n \\n7.3. Framework characteristics experiments  \\nUsing  the dataset  mentioned in Section  7.2, we test our model \\non how well it performs to predict if the patient has a heart  dis- \\nease or not based on the values of the parameters specified for \\neach patient. The dataset was divided into two parts of 70%, \\n10% and 20% of the whole  data.  The first part was used to train \\nthe model, the second for validation and tweaking the model parameters.  The last part was used for testing  the model  perfor - \\nmance. To measure the performance of the HealthFog model \\nthe following characteristics were observed and  analyzed:  \\n1. Prediction accuracies : The dataset consists of 1807 ex - \\namples  out of which  1355 were  used for training  the model \\nand 452 were  used for testing.  The training  examples  were \\ndivided equally across all worker /broker nodes equally to \\nobtain their respective trained deep learning models. As \\nthe number of Fog nodes increases to use all resources  for \\ntraining the dataset examples would have to be distributed to all nodes. This reduces the training time but also the \\ntest accuracy. To observe such e ffects, the training and \\ntest accuracies were analyzed. We define accuracy more'),\n",
       " Document(metadata={'source': 'D:\\\\Homeowrk\\\\Cloud\\\\new papaers\\\\HealthFog An ensemble deep learning based Smart Healthcare System for Automatic Diagnosis of Heart Diseases in integrated IoT and fog computing environments.pdf', 'page': 9}, page_content='test accuracy. To observe such e ffects, the training and \\ntest accuracies were analyzed. We define accuracy more \\nformally as the percentage of the total patients for which \\nthe model predicts correctly if they have heart disease or \\nnot. We compare accuracies for di fferent fog settings, by \\nchanging the number of edge nodes and with or without \\nensembling of  results.  \\n2. Time characteristics : A representative subset of the dif - \\nferent timing parameters shown in Figure 3 were also ob-  \\nserved and studied. These include arbitration time, la - \\ntency, execution time and jitter. We compare these tim - \\ning parameters  for different  fog settings  by having no edge \\nnodes or upto 2 edge nodes (with or without ensembling) \\nor having a cloud only computation infrastructure.  \\n3. Network bandwidth usage : As the scenario i.e. Broker \\nonly, Workers or Cloud and the number of Worker nodes \\naffect the network consumption this was studied to find \\nout the network usage in di fferent cases. Similar to the \\nexperiments for timing parameters, we compare the net - \\nwork bandwidth consumption for the di fferent fog scenar - \\nios. This was d one to find out the dependence of band - \\nwidth consumption with di fferent fog configurations that \\nHealthFog  provides.  \\n4. Power consumption: Energy being a crucial reason of \\nshift from  cloud  to fog domains,  we also studied  the power \\nconsumption in di fferent scenarios. Based on the power \\nconsumption studies and other experiments described ear - \\nlier we discuss  how different  HealthFog  configurations  can \\nbe used for various user and application requirements.  \\n \\n7.4. Prediction  Accuracies  \\nFigure 9 shows the variation of training accuracy with num - \\nber of Edge  nodes  (Broker plus Worker  nodes).  We can observe \\nthat the training accuracy gradually increases as the number  \\nof worker  nodes  increase.  This is because each node  learns  a \\n• \\n•'),\n",
       " Document(metadata={'source': 'D:\\\\Homeowrk\\\\Cloud\\\\new papaers\\\\HealthFog An ensemble deep learning based Smart Healthcare System for Automatic Diagnosis of Heart Diseases in integrated IoT and fog computing environments.pdf', 'page': 10}, page_content='11  × × −  \\nage sex cp trestbps  chol fbs restecg  thalach  exang  oldpeak  slope  ca thal target  \\n63 1 3 145 233 1 0 150 0 2.3 0 0 1 1 \\n37 1 2 130 250 0 1 187 0 3.5 0 0 2 1 \\n41 0 1 130 204 0 0 172 0 1.4 2 0 2 1 \\n56 1 1 120 236 0 1 178 0 0.8 2 0 2 1 \\n57 0 0 120 354 0 1 163 1 0.6 2 0 2 1 \\n62 0 0 140 268 0 0 160 0 3.6 0 2 2 0 \\n63 1 0 130 254 0 0 147 0 1.4 1 1 3 0 \\n53 1 0 140 203 1 0 155 1 3.1 0 0 3 0 \\n56 1 2 130 256 1 0 142 1 0.6 1 1 1 0 \\n48 1 1 110 229 0 1 168 0 1 0 0 3 0 \\n \\nTable 2: Sample patient record data from Cleveland database \\n \\n \\n \\n \\n \\n  \\n \\n \\n  \\n \\n \\n \\n \\nFigure 9: Training accuracy with number of edge nodes  \\n  \\n \\n \\n \\n \\n \\n \\n  \\n \\n \\n  \\n \\n \\nFigure 10: Test accuracy with number of edge nodes  \\n \\n \\nmodel for the data received by it, and as the number of nodes \\nincrease, the number of examples received by each node be- \\ncomes lesser and hence training the model for multiple epochs \\nover-fit the samples  and hence training  accuracy  increases.  Fig- \\nure 10 shows the variation of test data accuracy as the num- \\nber of Edge nodes increase. As expected, test accuracy de - \\ncreases with higher number of  nodes because each  node gets \\na smaller subset of training data and hence is unabl e to gener - \\nalise the model. Another observation is that ensemble learning \\nalways gives much better accuracy than the without ensemble \\ncase (best or  average).  \\n \\n7.5. Prediction  Confidence  \\nWhenever the deep learning model predicts whether the pa - \\ntient has heart disease or not it generates two probabilities: p 0 Figure 11: Confidence of the model for di fferent subsets of Cleveland Data \\n \\n \\n(probability  of no disease)  and p1 (probabili ty of heart  disease), \\nsuch that p 0 + p1 = 1. The confidence measure of a prediction \\n(p0, p1) is quantified as 100   (2   max (p0, p1)    1) and thus \\nhas range [0,100]. Thus, if prediction probabilities is (0.5, 0.5) \\nthen the confidence is 0 and when they are (0.9, 0.1) then the \\nprediction class is 0% and confidence is 80%. Figure 11 shows \\nthe variation of conf idence of the binary classifier for the com - \\nplete  test dataset,  subset  on which  the model  predicted  correctly \\nand that where prediction was incorrect. We see that the con - \\nfidence is higher for the datapoints where the prediction was \\ncorrect compared to t hose datapoints where the prediction was \\nincorrect.  The maximum  confidence  with which  the model  pre- \\ndicts incorrectly is 49.7%, thus if confidence is less that 50% \\nthen our model suggests the patient to consult the doctor as the \\nprediction may be  unreliable.  \\n7.6. Timing  Characteristics  \\nFigure 12 shows the variation of arbitration time at the Bro - \\nker node  for different  Fog scenarios:  (1) Broker only,  (2) Single \\nWorker node, (3) Two worker nodes and (4) Cloud. We see \\nthat arbitration  time is negligible  (nearly  115 ms) when  the task \\nis to be sent directly to Broker /Master or Cloud. As the num - \\nber of edge nodes increase, the Broker needs to check loads at \\nevery Worker node and find the minimum load worker to send \\ntask, hence the arbitration time increases as number of Edge \\nnodes increase. When the data is sent to worker nodes for en- \\nsemble lear ning, then also the broker does not need to do any \\nload checking as majority class choice needs to be done by one \\nof the worker nodes, thus arbitration time is similar to without \\nensembling case.  \\nFigure 13 shows the variation  of latency, which as per Fig - \\nure 3 is the addition of communication time and queuing de - \\nBest Average  Ensemble  \\n100 \\n81 81 84 84 84 83 89 85 85 94 91 86 94 90 87 \\n80      \\n60      \\n40      \\n20      \\n0 \\n1 2 3 \\nNumber of Edge  Nodes  4 5 \\nBest Average  Ensemble  \\n100 89 83 85 85 \\n80 78 78  78 84 \\n75 72 70 74 69 74 \\n68 \\n60      \\n40      \\n20      \\n0 \\n1 2 3 \\nNumber of Edge  Nodes  4 5 \\n70       \\n60 54.899  58.392  \\n  48.838   \\n50       \\n40       \\n30          \\n20       \\n10       \\n0 \\nComplete dataset  Correct  samples  Incorrect  Samples'),\n",
       " Document(metadata={'source': 'D:\\\\Homeowrk\\\\Cloud\\\\new papaers\\\\HealthFog An ensemble deep learning based Smart Healthcare System for Automatic Diagnosis of Heart Diseases in integrated IoT and fog computing environments.pdf', 'page': 10}, page_content='0 \\n1 2 3 \\nNumber of Edge  Nodes  4 5 \\n70       \\n60 54.899  58.392  \\n  48.838   \\n50       \\n40       \\n30          \\n20       \\n10       \\n0 \\nComplete dataset  Correct  samples  Incorrect  Samples  \\nDataset  Test Accuracy  (%) Training  Accuracy  (%) \\nConfidence'),\n",
       " Document(metadata={'source': 'D:\\\\Homeowrk\\\\Cloud\\\\new papaers\\\\HealthFog An ensemble deep learning based Smart Healthcare System for Automatic Diagnosis of Heart Diseases in integrated IoT and fog computing environments.pdf', 'page': 11}, page_content='12   \\n \\n \\n \\n \\n   \\n \\n \\n \\n \\n \\nFigure 12: Arbitration time in  different  cases  Figure 14: Jitter in different  cases  \\n \\n \\nlay. We see that if the task is sent to Broker or any of the edge \\nnodes, then the latency is nearly same as all communication is \\nthrough single hop data transfers. In ensemble case, the  latency \\nis slightly  higher.  For cloud setting,  the latency  is very high due \\nto multi- hop transfer of data outside the  LAN.  \\n \\n \\n \\n \\n \\n \\nFigure 15: Execution time in di fferent cases  \\n \\n \\n \\n \\n \\n \\n \\nFigure 13: Latency in di fferent cases  \\n \\nJitter  is the variation  of response  time for consecutive  job re- \\nquests. It is a critical parameter for most real -time applications \\nincluding health data analysis. Figure 14 (log vertical scale) \\nshows the variation of jitter with the Fog configurations. We \\nobserve that jitter is higher for  Broker only case compared to \\nthe case where tasks are sent to worker nodes. This is because \\nof other tasks including arbitration, resource management and \\nsecurity  checking  are also performed  by Broker.  As the workers \\nincrease, due to di fference in loads o f workers jitter slightly  in- \\ncreases  for two edge  nodes  compared  to single  edge  node.  Jitter \\nis also high in ensemble case. Jitter is very high when tasks are sent to  CDC.  \\nFigure 15 shows the variation of execution time. As ex - \\npected, the execution time in Cloud setup is very low due to \\nhigher resource availability. Broker execution time is lesser \\nthan the worker nodes as HealthFog workers are Raspberry Pis \\nwhich  have  processor  with low clock  frequency.  Also,  when  en- \\nsemble prediction is enabled then the execution time is higher \\nbecause the worker  node  now needs  to check  which  class  is ma- \\njority among all predicted  classes.  7.7. Network Bandwidth Usage  Characteristics  \\nFigure 16 shows the var iation of Network bandwidth usage \\nof all edge nodes in di fferent scenarios. We see that as the \\nworker  nodes  increase,  the network usage  also increase because \\nmore heartbeat packets, security checks and data transfer (with \\ncloud) are required. In ensemble case, as data is sent to all \\nworker nodes the network bandwidth consumption is  highest.  \\n \\n7.8. Power Characteristics  \\nWe also tested HealthFog energy consumption characteris - \\ntics in different scenarios.  The power consumption of CDC   \\nis very high compared to the Broker node (laptop) or Worker \\nnodes (Raspberry Pi). This leads to very high power consump-  \\ntion in Cloud case c ompared to Edge case. As the number of \\nWorker nodes increase, the power consumption of the Health-  \\nFog framework also  increases.  \\n \\n7.9. Analysis with Related  Work  \\nOther works that propose computing models for healthcare \\napplications in Fog Computing do not consi der various  aspects \\nwhich HealthFog does. Many prior works [13, 16, 17, 22, 23, \\n39, 42] do not leverage resources close to the edge of the net - \\nwork. As per Figure 13, such models provide a much higher \\nlatency as all computation is done on the c loud and hence has \\nhigher  data transfer  times.  With  the advancement  of deep  learn - \\ning based prediction models, HealthFog is able to use state -of- \\nthe-art Neural  Network  models  for highly accurate prediction  \\n4000 \\n3500 \\n3000 \\n2500 \\n2000 \\n1500 \\n1000 \\n500 \\n0    \\n2905.4  3076.8  \\n   \\n  1405.8      \\n   \\n     120.2  109.8   \\nMaster  \\nOnly 1 Edge  2 Edge  2 nodes  \\nnode nodes  (ensemble)  \\nFog Scenario  Cloud  \\n10000        2610.8   \\n1000      \\n100   29.8  \\n14.6 20 17.4 \\n10      \\n \\n1 \\nMaster  1 Edge  2 Edge   2 nodes  Cloud \\nOnly  node nodes  (ensemble)  \\nFog Scenario  \\n100   98.5  \\n   \\n10 \\n10  5.75  \\n2.25 2.75 \\n1 \\nMaster  Only1  Edge  node  2 Edge  2 nodes  Cloud  \\nnodes  (ensemble)  \\nFog Scenario  \\n7000      \\n6000  5710.8  \\n5000         \\n4000  3741.6  3660.9   \\n   \\n3000   2408   \\n2000      \\n1000  754.6  \\n0 \\nMaster  Only 1 Edge  node  2 Edge  nodes  2 nodes  Cloud  \\n(ensemble)'),\n",
       " Document(metadata={'source': 'D:\\\\Homeowrk\\\\Cloud\\\\new papaers\\\\HealthFog An ensemble deep learning based Smart Healthcare System for Automatic Diagnosis of Heart Diseases in integrated IoT and fog computing environments.pdf', 'page': 11}, page_content='Fog Scenario  \\n7000      \\n6000  5710.8  \\n5000         \\n4000  3741.6  3660.9   \\n   \\n3000   2408   \\n2000      \\n1000  754.6  \\n0 \\nMaster  Only 1 Edge  node  2 Edge  nodes  2 nodes  Cloud  \\n(ensemble)  \\nFog Scenario  Latency (milliseconds)  Arbitration  Time  (milliseconds)  \\nExecution Time (millisecodnds)  Jitter  (milliseconds)'),\n",
       " Document(metadata={'source': 'D:\\\\Homeowrk\\\\Cloud\\\\new papaers\\\\HealthFog An ensemble deep learning based Smart Healthcare System for Automatic Diagnosis of Heart Diseases in integrated IoT and fog computing environments.pdf', 'page': 12}, page_content='13   \\n  \\n \\n \\n \\n  \\n \\n \\n \\n \\n \\n \\n \\n \\nFigure 16: Network usage in di fferent cases  \\n \\n \\n \\n \\n \\n \\n \\n \\n  \\n \\n \\n \\nFigure 17: Power consumption in di fferent cases  \\n  \\n \\nof health characteristics of patients. Other works like [2, 46] or \\n[11, 12, 13, 14, 16, 18, 41, 43] lack the ability to integrate  such \\nmodels and hence provide lower disease detection accuracy. \\nThis is crucial  to provide  low latency  and highly accurate results \\nin critical healthcare appl ications especially those concerned \\nwith heart related problems like heart attack, stroke or arrhyth - \\nmia. Furthermore, works that use deep learning [17, 19, 20] do \\nnot use ensembling methods to provide even better results by \\nleveraging  fog resources  for parallel computation and providing \\nsignificantly higher accuracy. As shown by results in Section 7.4, with ensemble, the prediction a ccuracy increases by 16% \\nfor the case with 5 edge  nodes  which  is significantly  higher  than \\nwhat existing systems (not leveraging ensemble deep learning) \\ncan provide.  \\nMoreover, unlike prior work HealthFog uses the FogBus \\nframework [27] to provide a diverse set of configurations with \\ndifferent accuracy, response time, network and power usage \\ncharacteristics.  Based  on different  application  and user require - \\nments di fferent configurations can be used as described in the \\nfollowing section. This allows users to customize the frame - \\nwork as per their needs. This non- trivial extension of integra - \\ntion and synchronization among fog computing nodes allows \\nexecution  ensemble  based  deep  learning  models  which  not only \\nimproves disease detection accuracy but is also adaptive as per \\ndiverse  requirements.  Hence,  HealthFog  provides  a novel  archi - \\ntecture  of healthcare computation  not offered  by existing  works.  7.10. Discussion and Recommendations  \\nIn earlier work [27], the power of FogBus and comparisons \\nwith earlier such Fog frameworks were demonstrated showing \\nhow FogBus provides more e fficient implementation of appli - \\ncations harnessing the Edge and Cloud resources. This work \\ndeveloped a latency  and accuracy  sensitive  application  of Heart \\npatient analysis using the FogBus framework with engineering \\nsimplicity  and in low time to efficiently  use Edge  and Cloud  re- \\nsources. The application deployment system provided different \\nconfigurations that provide better accuracy or latency based on \\nuser requirements. Based on the experimental results we pro - \\npose HealthFog to be used in the following settings based on \\nthe targ et applications: \\nFor latency critical and lightweight tasks or energy con - \\nstraint environments, worker nodes should be used. This \\nprovides  very low result  delivery  time due to close  proxim - \\nity of worker  nodes.  If energy  and network  bandwidth con- \\nstraints exist then ensemble bagging should be disabled \\nbut if not, enabling  bagging  would give better  accuracy.  \\nFor heavy and latency tolerant tasks CDC configuration must be used otherwise such tasks would not be able to \\nsuccessfully complete on resource constraint edge worker \\nnodes.  \\n \\n8. Conclusions and Future  Work  \\nHealthcare as a service is a huge project. In this research \\nwork, we only focus on the healthcare aspects for heart pa- \\ntients  by proposing a novel  Fog based  Smart  Healthcare System \\nfor Automatic Diagnosis of Heart Diseases using deep  learning \\nand IoT called HealthFog. HealthFog provides healthcare as a \\nfog service and effi ciently manages the data of heart patients \\nwhich is coming from di fferent IoT devices. HealthFog inte- \\ngrates deep learning in Edge computing devices and deployed \\nit for a real -life application of Heart Disease analysis. Prior \\nworks  for such Heart  Patient analysis  did not utilize  deep  learn - \\ning and hence had very low prediction accuracy which renders \\nthem useless in practical settings. Deep learning based models \\nwith very high accuracy require very high compute resources'),\n",
       " Document(metadata={'source': 'D:\\\\Homeowrk\\\\Cloud\\\\new papaers\\\\HealthFog An ensemble deep learning based Smart Healthcare System for Automatic Diagnosis of Heart Diseases in integrated IoT and fog computing environments.pdf', 'page': 12}, page_content='ing and hence had very low prediction accuracy which renders \\nthem useless in practical settings. Deep learning based models \\nwith very high accuracy require very high compute resources \\n(CPU and GPU) both for training and prediction. This work al- \\nlowed  complex  deep  learning  networks  to be embedded in Edge \\ncomputing paradigms using novel communication and model \\ndistribution  techniques  like ensembling  which  allowed  high ac- \\ncuracy to be achieved with very low latencies. This was also \\nvalidated for real -life heart patient data analysis by training \\nneural networks on popular datasets and deploying a working \\nsystem that provides prediction results in real -time. We used \\nFogBus  framework  to validate  HealthFog  in fog computing en- \\nvironment  and tested  the efficiency  of proposed system  in terms \\nof power  consumption,  network  bandwidth,  latency,  jitter,  train- \\ning accuracy, testing accuracy and execution  time.  \\nAs part of the future work, we propose to extend HealthFog \\nto allow cost- optimal execution given di fferent QoS character - \\nistics and fog -cloud cost models. Currently HealthFog works \\nwith file based  input  data which  can be converted  to seamlessly  \\n25      \\n20 \\n20 17.6 \\n15 12.8 \\n10 \\n5    5.6  \\n4 \\n0 \\nMaster Only  1 Edge node 2 Edge  nodes  2 nodes  Cloud  \\n(ensemble)  \\nFog Scenario  \\n18  16.932   \\n16      \\n14      \\n12      \\n10      \\n8      \\n6 4.1242  \\n4 2.22 2.83 3.4422  \\n2      \\n0 \\nMaster Only  1 Edge node 2 Edge  nodes  2 nodes  Cloud  \\n(ensemble)  \\nFog Scenario  Power  Conumption  (W) Network bandwidth consumption (kbps)  \\n• \\n•'),\n",
       " Document(metadata={'source': 'D:\\\\Homeowrk\\\\Cloud\\\\new papaers\\\\HealthFog An ensemble deep learning based Smart Healthcare System for Automatic Diagnosis of Heart Diseases in integrated IoT and fog computing environments.pdf', 'page': 13}, page_content='14  integrated to take data directly from sensors to make it user - \\nfriendly. Moreover, the model training strategy used currently \\nuses separate training at each worker node. The trained mod - \\nels at each node have combined using various ensemble model \\nof bagging. More intelligent ensemble models can be deployed \\nfor further improving the accuracy. Further, proposed archi - \\ntecture  can be made  robust  and generic  to incorporate  other  fog \\ncomputing applications  such as agriculture,  healthcare,  weather \\nforecasting, traffi c management and smart city. HealthFog can \\nalso be extended towards other important domains of health - \\ncare such as diabetes, cancer and hepatitis, which can provide \\nefficient services to corresponding  patients.  \\n \\nSoftware Availability  \\nWe released  HealthFog  as an open source  software.  The \\nimplementation code  with experiment  scripts  and results  can \\nbe found a t the GitHub repository: https://github.com/  \\nCloudslab/HealthFog.  \\n \\nAcknowledgements  \\nThis research work is supported by the Melbourne -Chindia \\nCloud Computing (MC3) Research Network and Australian \\nResearch  Council.  We would like to thank  the editor,  area editor \\nand anonymous  reviewers  for their valuable  comments  and sug- \\ngestions  to help and improve  our research  paper.  We would  also \\nlike to thank Samodha  Pallewatta,  Shashikant  Ilager  (CLOUDS \\nLab, University of Melbourne) and Shikhar Tuli (Indian Insti- \\ntute of Technology, Delhi) for their valuable comments on im - \\nproving the quality o f presentation.  \\n \\nReferences  \\n[1] Islam, S.M.R., Kwak, D., Kabir M.D.H., Hossain M. and Kwak K.S.: \\nThe internet of things for health care: a comprehensive survey. IEEE \\nAccess. 3, 678 -708 (2015).  \\n[2] Rahmani, A. M., Gia T.N., Negash B., Anzanpour A., Azimi I., Jiang \\nM., and Liljeberg P.: Exploiting smart e -health gateways at the edge of \\nhealthcare internet -of-things: a fog computing approach. Future Gener - \\nation Computer Systems, 78, 641 -658 (2018).  \\n[3] Goyal, Abhishek, Kanika Nara ng, Gautam Ahluwalia, P. M. Sohal, \\nBhupinder  Singh,  Shibba  T. Chhabra, Naved  Aslam,  Bishav  Mohan,  and \\nGurpreet S. Wander. “Seasonal variation in 24 h blood pressure profile \\nin healthy adults -A prospective observational study.” Journal of human \\nhypertension  (2019):  1. \\n[4] Gill, Sukhpal  Singh,  Peter  Garraghan, and Rajkumar  Buyya.  “ROUTER: \\nFog enabled cloud based intelligent resource management approach for \\nsmart home IoT devices.” Journal of Systems and Software  (2019).  \\n[5] Faust, Oliver, Yuki Hagiwara, Tan Jen Hong, Oh Shu Lih, and U. \\nRajendra Acharya. deep learning for healthcare applications based on \\nphysiological signals: A review. Computer methods and programs in \\nbiomedicine 161 (2018):  1-13. \\n[6] Tuli, Shreshth, Nipam Basumatary and Rajkumar Buyya, Edgelens:  \\nDeep learning based object detection in integrated iot, fog and cloud \\ncomputing environments, Proceedings of the 4th IEEE International  \\nConference on Information Systems and Computer Networks (ISCON \\n2019, IEEE Press, USA), Mathura, India, November  21-22 \\n[7] Dietterich, Thomas G. “Ensemble methods in machine learning.” In In - \\nternational workshop on multiple classifier systems, pp. 1 -15. Springer, \\nBerlin, Heidelberg,  2000.  [8] Zhao,  Xianlong,  Kexin Yang,  Qimei  Chen,  Duo Peng,  Hao Jiang,  Xianze \\nXu, and Xinzhuo  Shua ng. “deep  learning  based  mobile  data offloading  in \\nmobile  edge  computing  systems.”  Future  Generation  Computer  Systems \\n(2019).  \\n[9] Lim,  Tjen-Sien,  Wei-Yin Loh, and Yu-Shan  Shih.  “A comparison  of pre- \\ndiction accuracy, complexity, and training time of thirty -three old and \\nnew classification algorithms.” Machine learning 40, no. 3 (2000): 203- \\n228. \\n[10] Gill, Sukhpal Singh, Rajesh Chand Arya, Gurpreet Singh Wander, and \\nRajkumar  Buyya.  “Fog -Based  Smart  Healthcare as a Big Data  and Cloud \\nService for Heart Patients Using IoT.” In International Conference on'),\n",
       " Document(metadata={'source': 'D:\\\\Homeowrk\\\\Cloud\\\\new papaers\\\\HealthFog An ensemble deep learning based Smart Healthcare System for Automatic Diagnosis of Heart Diseases in integrated IoT and fog computing environments.pdf', 'page': 13}, page_content='Rajkumar  Buyya.  “Fog -Based  Smart  Healthcare as a Big Data  and Cloud \\nService for Heart Patients Using IoT.” In International Conference on \\nIntelligent Data Communication Technologies and Internet of Things, \\npp. 1376 -1383. Springer, Cham,  2018.  \\n[11] Gia, T.N., Jiang M., Sarker V.K., Rahmani A.M., Westerlund T., Lilje - \\nberg P., and Tenhunen  H.: Low-cost fog-assisted  health -care IoT system \\nwith energy -efficient sensor nodes. In: 13th IEEE International Confer - \\nence Wireless  Communications  and Mobile  Computing,  pp. 1765 -1770, \\n(2017).  \\n[12] He S., Cheng B., Wang H., Huang Y., and Chen J.: Proactive person - \\nalized services through fog -cloud computing in large -scale IoT-based \\nhealthcare application.  China  Communications,  14, no. 11, 1-16 (2017).  \\n[13] Ali S., and Ghazal  M.: Real-time Heart  Attack  Mobile  Detection  Service \\n(RHAMDS): An IoT use case for Software Defined Networks. In: 30th \\nIEEE Canadian Conference on Electrical and Computer Engineering, \\npp. 1 -6, (2017).  \\n[14] Akrivopoulos O., Amaxilatis D., Antoniou A., and Chatzigiannakis I.: \\nDesign and Eva luation of a Person -Centric Heart Monitoring System \\nover Fog Computing Infrastructure. In: Ist ACM International Work - \\nshop  on Human -centered  Sensing,  Networking,  and Systems,  pp. 25-30, \\n(2017).  \\n[15] Sanghera, Dharambir K., Cynthia Bejar, Bishwa Sapkota, Gurpreet S. \\nWander, and Sarju Ralhan. “Frequencies of poor metabolizer alleles of \\n12 pharmacogenomic actionable genes in Punjabi Sikhs of Indian Ori - \\ngin.” Scientific reports 8, no. 1 (2018):  15742.  \\n[16] Rajasekaran, Manikandan, Abdulsalam Yassine, M. Shamim Hossain,  \\nMohammed F. Alhamid, and Mohsen Guizani. “Autonomous monitor - \\ning in healthcare environment: Reward -based energy charging mecha - \\nnism for IoMT wireless sensing nodes.” Future Generation Computer \\nSystems 98 (2019):  565-576. \\n[17] Choi, Edward, Mohammad Taha Baha dori, Le Song, Walter F. Stewart, \\nand Jimeng Sun. “GRAM: graph -based attention model for healthcare \\nrepresentation learning.” In Proceedings of the 23rd ACM SIGKDD In- \\nternational Conference on Knowledge Discovery and Data Mining, pp. \\n787-795. ACM,  2017.  \\n[18] Constant, Nicholas, Debanjan Borthakur, Mohammadreza Abtahi, Har- \\nishchandra Dubey, and Kunal Mankodiya. “Fog -assisted wiot: A smart \\nfog gateway for end -to-end analy tics in wearable internet of things.” \\narXiv preprint arXiv:1701.08680  (2017).  \\n[19] Azimi, Iman, Janne Takalo -Mattila, Arman Anzanpour, Amir M. Rah- \\nmani, Juha -Pekka Soininen, and Pasi Liljeberg. “Empowering health - \\ncare IoT systems with hierarchical edge- based deep learning.” In 2018 \\nIEEE/ ACM International Conference on Connected Health: Applica-  \\ntions, Systems and Engineering Technologies (CHASE), pp. 63-68. \\nIEEE,  2018.  \\n[20] Li, Liangzhi,  Kaoru  Ota, and Mianxiong  Dong.  “deep  learning  for smart \\nindustry: e fficient manufacture inspection system with fog computing.” \\nIEEE Transactions on Industrial Informatics 14, no. 10 (2018): 4665 - \\n4673.  \\n[21] Mahmud, Redowan, Fernando Luiz Koch, and Rajkumar Buyya. \\n“Cloud -fog interoperability  in IoT-enabled  healthcare  solutions.”  In Pro- \\nceedings  of the 19th International  Conference  on Distributed  Computing \\nand Networking, p. 32. ACM,  2018.  \\n[22] Barik, Rabindra K., Rojalina Priyadarshini, Harishchandra Dubey, Vinay Kumar, and Kunal Mankodiya. “FogLearn: leveraging  fog-based \\nmachine learning for smart system big data analytics.” International \\nJournal of Fog Computing (IJFC) 1, no. 1 (2018):  15-34. \\n[23] Rajkomar, Alvin, Eyal Oren, Kai Chen, Andrew M. Dai, Nissan Hajaj , \\nMichaela Hardt, Peter J. Liu et al. “Scalable and accurate deep learning with electronic health records.” NPJ Digital Medicine 1, no. 1 (2018): \\n18. \\n[24] Farahani B., Firouzi F., Chang V., Badaroglu M., Constant N.,  and'),\n",
       " Document(metadata={'source': 'D:\\\\Homeowrk\\\\Cloud\\\\new papaers\\\\HealthFog An ensemble deep learning based Smart Healthcare System for Automatic Diagnosis of Heart Diseases in integrated IoT and fog computing environments.pdf', 'page': 14}, page_content='15  − Mankodiya K.: Towards fog -driven IoT eHealth: Promises and chal - \\nlenges of IoT in medicine and healthcare. Future Generation Computer \\nSystems, 78, 659 -676 (2018).  \\n[25] Mkitalo N., Ometov A., Kannisto J., Andreev S., Koucheryavy J., and Mikkonen T.: Safe,  Secure Executions  at the Network  Edge:  Coordinat - \\ning Cloud, Edge, and Fog Computing. IEEE Software, 35, no. 1, 30-37 \\n(2017).  \\n[26] Dua, D. and Gra ff, C. (2019). UCI Machine Learning Repository \\n[http: //archi ve.ics.uci.edu /ml]. Irvine, CA: University of California, \\nSchool of Information and Computer  Science. \\n[27] Tuli, Shreshth, Redowan Mahmud, Shikhar Tuli, and Rajkumar Buyya. \\n“FogBus: A Blockchain -based Lightweight Framework for Edge and \\nFog Computing.”  Journal  of Systems  and Software,  Volume  154, August \\n2019, Pages  22-36. \\n[28] Vecchiola, Christian, Xingchen Chu, and Rajkumar Buyya. “Aneka: a \\nsoftware platform for .NET -based cloud computing.” High Speed and \\nLarge Scale Scientific Computing 18 (2009):  267-295. \\n[29] Hsieh, J. H., Lee R.C., Hung K.C., and Shih M.J.: Rapid and coding - \\nefficient  SPIHT  algorithm  for wavelet -based  ECG  data compression.  In- \\ntegration, the VLSI Journal, 60, 248 -256 (2018).  \\n[30] Liu T.Y., Lin K.Y. and Wu H.C.: ECG Data Encryption Then Compres - \\nsion Using Singular Value Decomposition. IEEE journal of biomedical \\nand health informatics  (2017).  \\n[31] Kato, Norihiro,  Marie Loh, Fumihiko Takeuchi, Niek Verweij, Xu \\nWang, Weihua Zhang, Tanika N. Kelly et al. “Trans -ancestry genome - \\nwide association study identifies 12 genetic loci influencing blood  pres- \\nsure and implicates  a role for DNA methylation.”  Nature  genetics  47, no. \\n11 (2015):  1282.  \\n[32] Sanghera, Dharambir  K., Latonya  Been,  Lyda  Ortega,  Gurpreet  S. Wan- \\nder, Narinder K. Mehra, Christopher E. Aston, John J. Mulvihill, and Sarju Ralhan. “Testing the association of novel meta -analysis -derived \\ndiabetes risk g enes with type II diabetes and related metabolic traits in \\nAsian Indian Sikhs.” Journal of human genetics 54, no. 3 (2009):  162. \\n[33] Pedregosa, Fabian, Gal Varoquaux, Alexandre Gramfort, Vincent Michel,  Bertrand  Thirion,  Olivier  Grisel,  Mathieu  Blondel  et al. “Scikit - \\nlearn: Machine learning in Python.” Journal of machine learning re - \\nsearch 12, no. Oct (2011):  2825 -2830.  \\n[34] Mircosoft  Windows  performance  toolkit.  https: //docs.microsoft.com /en- \\nus/windows -hardware /test/wpt/ [Online; accessed  28-May-2019].  \\n[35] SplunkBase  performance  monitor.  https: //splunkbase.splunk.com /app/1753/. \\n[Online; accessed  28-May-2019]  \\n[36] Microsoft Network Monitor 3.4. https: //www.microsoft.com /en- \\nau/download /details.aspx?id =4865. [Online; accessed  28-May-2019]  \\n[37] vnStat Network monitoring tool. https: //humdi.net /vnstat/ . [Online; ac- \\ncessed  28-May-2019]  \\n[38] Malik, Rainer, Ganesh Chauhan, Matthew Traylor, Muralidharan Sar - \\ngurupremraj, Yukinori Okada, Aniket Mishra, Loes Rutten -Jacobs et  \\nal. “Multiancestry genome- wide association study of 520,000 subjects \\nidentifies 32 loci associated with stroke and stroke s ubtypes.” Nature \\ngenetics 50, no. 4 (2018):  524. \\n[39] Pham, Minh, Yehenew Mengistu, Ha Do, and Weihua Sheng. ”Deliv - \\nering home healthcare through a cloud -based smart home environment \\n(CoSHE).” Future Generation Computer Systems 81 (2018):  129-140. \\n[40] Mutlag, Amma r Awad, Mohd Khanapi Abd Ghani, Net al Arunkumar, \\nMazin Abed Mohamed, and Othman Mohd. ”Enabling technologies for fog computing  in healthcare  IoT systems.”  Future  Generation  Computer \\nSystems 90 (2019):  62-78. \\n[41] Alam, Md Golam Rabiul, Md Shirajum Munir, Md Zi a Uddin, Mo - \\nhammed Shamsul Alam, Tri Nguyen Dang, and Choong Seon Hong. \\n”Edge -of-things computing framework for cost -effective provisioning \\nof healthcare data.” Journal of Parallel and Distributed Computing 123 \\n(2019):  54-60. \\n[42] Sahoo, Prasan Kumar, Suvendu Kumar Mohapatra, and Shih -Lin Wu.'),\n",
       " Document(metadata={'source': 'D:\\\\Homeowrk\\\\Cloud\\\\new papaers\\\\HealthFog An ensemble deep learning based Smart Healthcare System for Automatic Diagnosis of Heart Diseases in integrated IoT and fog computing environments.pdf', 'page': 14}, page_content='of healthcare data.” Journal of Parallel and Distributed Computing 123 \\n(2019):  54-60. \\n[42] Sahoo, Prasan Kumar, Suvendu Kumar Mohapatra, and Shih -Lin Wu. \\n”SLA based healthcare big data analysis and computing in cloud net - \\nwork.” Journal of Parallel and Distributed Computing 119 (2018): 121 - \\n135. \\n[43] Abdelmoneem, Randa M., Abderrahim Benslimane, Eman Shaaban, \\nSherin Abdelhamid, and Salma Ghoneim. ”A Cloud -Fog Based Archi - \\ntecture for IoT Applications Dedicated to Healthcare.” In ICC 2019-  \\n2019  IEEE International  Conference on Communications  (ICC),  pp. 1-6. \\nIEEE,  2019.  [44] Gupta,  Harshit,  Amir  Vahid  Dastjerdi,  Soumya  K. Ghosh,  and Rajkumar \\nBuyya. ”iFogSim: A toolkit for modeling and simulation of resource management  techniques  in the Internet  of Things,  Edge  and Fog comput - \\ning environments.” Software: Practice and Experience 47, no. 9  (2017): \\n1275 -1296.  \\n[45] Moysiadis, Vasileios, Panagi otis Sarigiannidis, and Ioannis Moscho - \\nlios. “Towards  distributed  data management  in fog computing.”  Wireless \\nCommunications and Mobile Computing 2018  (2018).  \\n[46] Moosavi,  Sanaz Rahimi,  Tuan  Nguyen  Gia, Ethiopia  Nigussie,  Amir  M. \\nRahmani,  Seppo  Virtanen,  Hannu  Tenhunen,  and Jouni  Isoaho.  “End -to- \\nend security  scheme  for mobility  enabled  healthcare Internet  of Things.” \\nFuture Generation Computer Systems 64 (2016):  108-124. \\n[47] Abdullahi, Ibrahim, Suki Arif, and  Suhaidi  Hassan.  ”Ubiquitous  shift with information centric network caching using fog computing.”  \\nIn Computational intelligence in information systems, pp. 327 -335. \\nSpringer, Cham,  2015.  \\n[48] Satyanarayanan, Mahadev. ”The emergence of edge computing.” Com - \\nputer 50, no. 1 (2017):  30-39. \\n[49] Naeije,  Robert,  and Anna  Ryan  Hemnes.  ”The difficult diagnosis  of pul- \\nmonary vascular disease in heart failure.” (2016):  308-310. \\n[50] Papa, Marco, Chiara Camesasca, Francesco Santoro, Elena Zoia, \\nGabriele Fragasso, Salvatore Giannico, and Sergio L. Chierchia. ”Fe- \\ntal echocardiography  in detecting  anomalous  pulmonary  venous  connec - \\ntion: four false positive cases.” Heart 73, no. 4 (1995):  355-358. \\n[51] Buch, Varun H., Irfan Ahmed, and Mahiben Maruthappu . ”Artificial  in- \\ntelligence in medicine: current trends and future possibilities.” Br J  Gen \\nPract 68, no. 668 (2018):  143-144. \\n[52] Panch, Trishan, Heather Mattie, and Leo Anthony Celi. ”The inconve-  \\nnient truth about AI in healthcare.” NPJ Digital Medicine 2  (2019).  \\n[53] Juarez -Orozco, L. E., O. Martinez- Manzanera, F. M. Van Der Zant, \\nR. J. J. Knol, and  J.  Knuuti.  ”241  Deep  learning  in  quantitative  \\nPET myocardial perfusion imaging to  predict  adverse  cardiovascu - \\nlar events.” European Heart Journal -Cardiovascular Imaging 20, no. \\nSupplement 3(2019) : jez 145 005. \\n[54] Acharya, U. Rajendra, Hamido Fujita, Shu Lih Oh, Yuki Hagiwara, Jen \\nHong Tan, and Muhamma d Adam. ”Application of deep convolutional \\nneural network for automated detection of myocardial infarction using \\nECG signals.” Information Sciences 415 (2017):  190-198. \\nShreshth Tuli is an undergraduate  stu- \\ndent at the Department of Computer Sci - \\nence an d Engineering at Indian Institute \\nof Technology -  Delhi, India. He is a na - \\ntional level Kishore Vaigyanic  Protsahan \\nYojana (KVPY) scholarship holder for \\nexcellence in science and innovation. He \\nis working as a visiting research fellow \\nat the Cloud Computing and Distributed \\nSystems (CLOUDS)  Laboratory,  Depart - \\nment of Computing and Information Systems, the University \\nof Melbourne,  Australia.  Most of his projects are focused   \\non developing technologies for future requiring sophisticated \\nhardware- software integration. His research interests include \\nInternet of Things (IoT), Fog Computing, Network Design, \\nBlockchain and deep learning.  \\nNipam Basumatary is an undergrad-  \\nuate student at Department of  Computer \\nScience and Engineering at Indian In-'),\n",
       " Document(metadata={'source': 'D:\\\\Homeowrk\\\\Cloud\\\\new papaers\\\\HealthFog An ensemble deep learning based Smart Healthcare System for Automatic Diagnosis of Heart Diseases in integrated IoT and fog computing environments.pdf', 'page': 14}, page_content='Blockchain and deep learning.  \\nNipam Basumatary is an undergrad-  \\nuate student at Department of  Computer \\nScience and Engineering at Indian In-  \\nstitute of Technology, Madras. He is \\nworking as a visiting research fellow at \\nCloud Computing and Distributed Sys - \\ntems (CLOUD) Laboratory, Department \\nof Computing and Information Systems, \\nthe University of M elbourne, Australia. \\nHis research interests include Machine'),\n",
       " Document(metadata={'source': 'D:\\\\Homeowrk\\\\Cloud\\\\new papaers\\\\HealthFog An ensemble deep learning based Smart Healthcare System for Automatic Diagnosis of Heart Diseases in integrated IoT and fog computing environments.pdf', 'page': 15}, page_content='16  Learning,  deep  learning,  Internet  of Things  (IoT) and Fog Com- \\nputing.  \\nSukhpal Singh Gill is a Lecturer  (As- \\nsistant Professor) in Cloud Computing \\nat School of Electronic Engineering and \\nComputer Science (EECS), Queen Mary \\nUniversity of London, UK. Prior to this, \\nDr. Gill has held positions as a Research \\nAssociate at the School of Computing \\nand Communications, La ncaster Univer - \\nsity, UK and also as a Postdoctoral Re - \\nsearch  Fellow  at the Cloud Computing  \\nand Distributed Systems (CLOUDS) Laboratory, School of \\nComputing and Information Systems, The University of Mel - \\nbourne, Australia. Dr. Gill was a research visor at Monash \\nUniversity, University of Manitoba and Imperial College Lon - \\ndon. He was a recipient of several awards, including the Dis - \\ntinguished Reviewer Award from Software: Practice and  Expe - \\nrience (Wiley), 2018, and served as t he PC member for venues \\nsuch as UCC,  SE-CLOUD,  ICCCN,  ICDICT  and SCES.  His \\none review  paper  has been  nominated  and selected  for the ACM \\n21st annual Best of Computing Notable Books and Articles as \\none of the notable items published in computing - 2016. He \\nhas published more  than 50 papers  as a leading  author  in highly \\nranked journals and conferences with H -index 18. His  research \\ninterests include Cloud Computing, Fog Computing, Software \\nEngineering, Internet of Things and Big Data. For further in- \\nformation on Dr. Gill, please visit: www.ssgill.me.  \\nMohsen Kahani is a professor of \\ncomputer engineering, IT director and head of Web Technology Laborat ory at \\nFerdowsi University of Mashhad and visiting Researcher at Cloud Comput - \\ning and Distributed Systems (CLOUDS) \\nLaboratory, School of Computing and \\nInformation Systems, The University of \\nMelbourne, Australia. His research in - \\nterests includes semantic wen, software engineering, natural \\nlanguage processing and process mining.  \\nRajesh Chand Arya is a Consul - \\ntant Cardiac Anesthesiologist at Depart - \\nment of Cardiology, Hero Heart  Institute \\nDayanand Medical College and Hospi - \\ntal, Ludhiana, Punjab, India. H e has 12 \\nyears of Cardiac Anesthesia experience after post -graduation. Special interest in \\nTrans Esophageal Echo (TEE) & Pedi - \\natric, Cardiac Anesthesia. He has  deliv - \\nered more than 20 guest lectures at national & international level.  Gurpreet Singh Wander is a Chief \\nCardiologist at Department of Cardi - \\nology, Hero Heart Institute Dayanand \\nMedical College and Hospital (DMC & H), Ludhiana, Punjab, India. He joined \\nDMC  & H in 1988.  He has been  awarded \\nBC Roy Award in 2007 and K. Sharan \\nAward by national IMA in 2005.  He is  \\na Member of Govern Board of API for  6 \\nyears.  Dr. Wander  has 200+ research  publications  in top ranked \\nvenues  which  include  5 publications  in Nature  journals  (Nature \\ngenetics, Journal of Human Genetics, Scientific Reports an d \\nJournal of Human Hypertension).  \\nRajkumar Buyya is a Redmond \\nBarry Distinguished Professor and Di - \\nrector of the Cloud Computing and Dis - \\ntributed Systems (CLOUDS)  Laboratory \\nat the University of Melbourne, Aus - \\ntralia. He is also serving as the found-  \\ning CEO of Manjrasoft, a spin- off com- \\npany of the University, commercializing \\nits innovations in Cloud Computing. He \\nserved  as a Future  Fellow  of the Aus- \\ntralian Research Council during 2012 -2016. He has authored \\nover 700 publications and seven text books including “Master - \\ning Cloud Computing” published by McGraw Hill, China Ma- \\nchine Press, and Morgan Kaufmann for Indian, Chinese and international markets  respectively.  He is one of the highly  cited \\nauthors in computer science and software engineering world - \\nwide (h -index= 127, g- index= 281, 84900+ citations). “A Sci- \\nentometric Analysis of Cloud Computing Literature” by Ger - \\nman scientists ranked Dr. Buyya a s the World’s Top-Cited (1) \\nAuthor and the World’s Most -Productive (1) Author in Cloud'),\n",
       " Document(metadata={'source': 'D:\\\\Homeowrk\\\\Cloud\\\\new papaers\\\\HealthFog An ensemble deep learning based Smart Healthcare System for Automatic Diagnosis of Heart Diseases in integrated IoT and fog computing environments.pdf', 'page': 15}, page_content='entometric Analysis of Cloud Computing Literature” by Ger - \\nman scientists ranked Dr. Buyya a s the World’s Top-Cited (1) \\nAuthor and the World’s Most -Productive (1) Author in Cloud \\nComputing. Recently, Dr. Buyya is recognized as a “Web of \\nScience Highly Cited Researcher” in both 2016 and 2017 by \\nThomson Reuters,  a Fellow  of IEEE,  and Scopus  Researcher  of \\nthe Year 2017 with Excellence in Innovative  Research  Award  by \\nElsevier for his outstanding contributions to Cloud computing. He served  as the founding Editor -in-Chief  of the IEEE  Transac - \\ntions  on Cloud Computing.  He is currently  serving as Editor-in- \\nChief of Journal of Software: Practice and Experience, which was established over 45 years ago. For further information on \\nDr. Buyya, please visit his cyberhome:  \\nwww.buyya.com')]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bca27a3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HealthFog: An Ensemble Deep Learning based Smart Healthcare System for Automatic \\nDiagnosis of Heart Diseases in Integrated IoT and Fog Computing Environments  \\n \\nShreshth Tuli1,2, Nipam Basumatary1,3, Sukhpal Singh Gill4, Mohsen Kahani1,5, Rajesh Chand Arya6, Gurpreet Singh Wander6, \\nRajkumar Buyya1 \\n \\n \\n \\n \\nAbstract  \\nCloud computing provides resources over the Internet and allows a plethora of applications to be deployed to provide services  for \\ndifferent industries. The major bottleneck being faced currently in the se cloud frameworks is their limited scalability and hence \\ninability  to cater  to the requirements  of centralized  Internet  of Things  (IoT)  based  compute  environments.  The main  reason  for this \\nis that latency -sensitive applications like health monitoring and  surveillance systems now require computation over large amounts \\nof data (Big Data) transferred to centralized database and from database to cloud data centers which leads to drop in perform ance \\nof such systems. The new paradigms of fog and edge computing provide innovative solutions by bringing resources closer to the \\nuser and provide low latency and energy e fficient solutions for data processing compared to cloud domains. Still, the current fog \\nmodels have many limitations and focus from a limited perspec tive on either accuracy of results or reduced response time but not \\nboth. We proposed a novel framework called HealthFog for integrating ensemble deep learning in Edge computing devices and \\ndeployed it for a real-life application  of automatic  Heart  Disease  analysis.  HealthFog  delivers  healthcare as a fog service using IoT \\ndevices  and efficiently  manages  the data of heart  patients,  which  comes  as user requests.  Fog- enabled  cloud  framework,  FogBus  is \\nused to deploy and test the performance of the proposed  model  in terms  of power  consumption,  network bandwidth,  latency,  jitter, \\naccuracy and execution time. HealthFog is configurable to various operation modes which provide the best Quality of Service o r \\nprediction accuracy, as required, in diverse fog computation scenarios and for di fferent user  requirements.  \\nKeywords: Fog Computing, Internet of Things, Healthcare, Deep Learning, Ensemble Learning, Heart Patient analysis  \\n \\n \\n1. Introduction  \\nFog and Cloud computing paradigms have emerged as a \\nbackbone of modern economy and utilize Internet to provide \\non-demand se rvices to users [1]. Both of these domains have \\ncaptured significant attention of industries and academia. But \\nbecause of high time delay, cloud computing is not a good op- \\ntion for applications requiring real -time response. Technologi - \\ncal developments  like edge  computing,  fog computing,  Internet \\nof Things (IoT), and Big Data have gained importance due to \\ntheir robustness and ability to provide diverse response charac-  \\nteristics based on target application [2].  These emerging tech - \\nnologies provide storage, computation, and communication to \\n \\n1Cloud Computing and Distributed Systems (CLOUDS) Laboratory, \\nSchool of Computing and Information Systems, The University of  Melbourne, \\nAustralia  \\n2Department of Computer Science and Engineering, Indian Institute of \\nTechnology (IIT), Delhi, India  \\n3Department  of Computer Science and Engineering, Indian Institute of \\nTechnology (IIT), Madras,  India  \\n4School of Electronic Engineering and Computer Science (EECS), Queen \\nMary University of London,  UK \\n5Web Technologies Laboratory, Ferdowsi University Of Mashhad, Iran  \\n6Department of Cardiology, Hero Heart Institute, Dayanand Medical \\nCollege and Hospital, Ludhiana, Punjab, India  \\nE-mail addresses: shreshthtuli@gmail.com  (S. Tuli), nipamba - \\nsumatary1@gmail.com  (N. Basumatary), s.s.gill@qmul.ac.uk  (S.S. Gill), \\nkahani@um.ac.ir  (M. Kahani), drrajesh arya@yahoo.com  (R.C. Arya), \\ndrgswander@yahoo.com (G.S. Wander), rbuyya@unimelb.edu.au (R. Buyya)  edge devices, which facilitate and enhance mobility, privacy, security, low latency, and network bandwidth so that fog com - \\nputing can perfectly match latency -sensitive or real -time appli - \\ncations [2, 6, 10, 12, 27, 40, 45, 46, 47, 48]. Now, cloud com- \\nputing fram eworks  also extend  support  to emerging  application \\nparadigms such as IoT, Fog computing, Edge, and Big Data \\nthrough service and infrastructure [3, 4]. Fog computing uses \\nrouters, compute nodes a nd gateways to provide services with \\nminimum possible energy consumption, network latency and \\nresponse  time.  \\nMutlag et al. [40] explored the challenges of Fog comput - \\ning in healthcare applications and identified that latency  and \\nresponse time are the most important and di fficult to optimize \\nQuality of Service (QoS) parameters in real time fog environ - \\nments. Healthcare is one of the prominent application areas that requires  accurate and real-time results,  and people  have  in- \\ntroduced Fog Computing in this field which leads to a positive \\nprogress. With Fog computing, we bring the resources closer \\nto the users thus decreasing the latency and thereby increas - \\ning the safety measure. Getting quicker results implies fast ac- \\ntions for critical heart patients.  But faster delivery o f results  \\nis not enough as with such delicate data we can not compro - \\nmise with the accuracy of the result. One way to obtain high \\naccuracies is by using state- of-the-art analysis softwares typi-  \\ncally those that employ deep learning and their variants  trained \\non a large  dataset.  In the recent  years,  deep  learning  [5] has \\nPreprint submitted to Future Generation  Computing  Systems  November 15,  2019 '"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "pdf_reader= PdfReader(r\"D:\\Homeowrk\\Cloud\\new papaers\\HealthFog An ensemble deep learning based Smart Healthcare System for Automatic Diagnosis of Heart Diseases in integrated IoT and fog computing environments.pdf\")\n",
    "pdf_reader.pages[0].extract_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ad9c09",
   "metadata": {},
   "source": [
    "#### WebBaseLoader: Loads text from website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "505df343",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://en.wikipedia.org/wiki/Large_language_model\")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bdfec3ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'title': 'Large language model - Wikipedia', 'language': 'en'}, page_content='\\n\\n\\n\\nLarge language model - Wikipedia\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to content\\n\\n\\n\\n\\n\\n\\n\\nMain menu\\n\\n\\n\\n\\n\\nMain menu\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tNavigation\\n\\t\\n\\n\\nMain pageContentsCurrent eventsRandom articleAbout WikipediaContact us\\n\\n\\n\\n\\n\\n\\t\\tContribute\\n\\t\\n\\n\\nHelpLearn to editCommunity portalRecent changesUpload file\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAppearance\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDonate\\n\\nCreate account\\n\\nLog in\\n\\n\\n\\n\\n\\n\\n\\n\\nPersonal tools\\n\\n\\n\\n\\n\\nDonate Create account Log in\\n\\n\\n\\n\\n\\n\\t\\tPages for logged out editors learn more\\n\\n\\n\\nContributionsTalk\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nContents\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n(Top)\\n\\n\\n\\n\\n\\n1\\nHistory\\n\\n\\n\\n\\n\\n\\n\\n\\n2\\nDataset preprocessing\\n\\n\\n\\n\\nToggle Dataset preprocessing subsection\\n\\n\\n\\n\\n\\n2.1\\nTokenization\\n\\n\\n\\n\\n\\n\\n2.1.1\\nBPE\\n\\n\\n\\n\\n\\n\\n\\n\\n2.1.2\\nProblems\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n2.2\\nDataset cleaning\\n\\n\\n\\n\\n\\n\\n\\n\\n2.3\\nSynthetic data\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n3\\nTraining and architecture\\n\\n\\n\\n\\nToggle Training and architecture subsection\\n\\n\\n\\n\\n\\n3.1\\nReinforcement learning from human feedback (RLHF)\\n\\n\\n\\n\\n\\n\\n\\n\\n3.2\\nInstruction tuning\\n\\n\\n\\n\\n\\n\\n\\n\\n3.3\\nMixture of experts\\n\\n\\n\\n\\n\\n\\n\\n\\n3.4\\nPrompt engineering, attention mechanism, and context window\\n\\n\\n\\n\\n\\n\\n\\n\\n3.5\\nInfrastructure\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n4\\nTraining cost\\n\\n\\n\\n\\n\\n\\n\\n\\n5\\nTool use\\n\\n\\n\\n\\n\\n\\n\\n\\n6\\nAgency\\n\\n\\n\\n\\n\\n\\n\\n\\n7\\nCompression\\n\\n\\n\\n\\n\\n\\n\\n\\n8\\nMultimodality\\n\\n\\n\\n\\n\\n\\n\\n\\n9\\nProperties\\n\\n\\n\\n\\nToggle Properties subsection\\n\\n\\n\\n\\n\\n9.1\\nScaling laws\\n\\n\\n\\n\\n\\n\\n\\n\\n9.2\\nEmergent abilities\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n10\\nInterpretation\\n\\n\\n\\n\\nToggle Interpretation subsection\\n\\n\\n\\n\\n\\n10.1\\nUnderstanding and intelligence\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n11\\nEvaluation\\n\\n\\n\\n\\nToggle Evaluation subsection\\n\\n\\n\\n\\n\\n11.1\\nPerplexity\\n\\n\\n\\n\\n\\n\\n11.1.1\\nBPW, BPC, and BPT\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n11.2\\nTask-specific datasets and benchmarks\\n\\n\\n\\n\\n\\n\\n11.2.1\\nAdversarially constructed evaluations\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n12\\nWider impact\\n\\n\\n\\n\\nToggle Wider impact subsection\\n\\n\\n\\n\\n\\n12.1\\nMemorization and copyright\\n\\n\\n\\n\\n\\n\\n\\n\\n12.2\\nSecurity\\n\\n\\n\\n\\n\\n\\n\\n\\n12.3\\nAlgorithmic bias\\n\\n\\n\\n\\n\\n\\n12.3.1\\nStereotyping\\n\\n\\n\\n\\n\\n\\n\\n\\n12.3.2\\nPolitical bias\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n13\\nList of large language models\\n\\n\\n\\n\\n\\n\\n\\n\\n14\\nSee also\\n\\n\\n\\n\\n\\n\\n\\n\\n15\\nNotes\\n\\n\\n\\n\\n\\n\\n\\n\\n16\\nReferences\\n\\n\\n\\n\\n\\n\\n\\n\\n17\\nFurther reading\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle the table of contents\\n\\n\\n\\n\\n\\n\\n\\nLarge language model\\n\\n\\n\\n46 languages\\n\\n\\n\\n\\nAfrikaansالعربيةAzərbaycancaবাংলা閩南語 / Bân-lâm-gúBoarischBosanskiCatalàČeštinaDeutschΕλληνικάEspañolEuskaraفارسیFrançaisGaeilgeGalego한국어हिन्दीBahasa IndonesiaIsiZuluItalianoעבריתMagyarМакедонскиNederlands日本語PolskiPortuguêsQaraqalpaqshaRomânăRuna SimiРусскийShqipSlovenščinaکوردیСрпски / srpskiTagalogไทยTürkçeУкраїнськаئۇيغۇرچە / UyghurcheTiếng Việt文言粵語中文\\n\\nEdit links\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nArticleTalk\\n\\n\\n\\n\\n\\nEnglish\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nReadEditView history\\n\\n\\n\\n\\n\\n\\n\\nTools\\n\\n\\n\\n\\n\\nTools\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tActions\\n\\t\\n\\n\\nReadEditView history\\n\\n\\n\\n\\n\\n\\t\\tGeneral\\n\\t\\n\\n\\nWhat links hereRelated changesUpload fileSpecial pagesPermanent linkPage informationCite this pageGet shortened URLDownload QR code\\n\\n\\n\\n\\n\\n\\t\\tPrint/export\\n\\t\\n\\n\\nDownload as PDFPrintable version\\n\\n\\n\\n\\n\\n\\t\\tIn other projects\\n\\t\\n\\n\\nWikimedia CommonsWikidata item\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAppearance\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFrom Wikipedia, the free encyclopedia\\n\\n\\nType of artificial neural network\\nNot to be confused with Logic learning machine.\\n\\nPart of a series onMachine learningand data mining\\nParadigms\\nSupervised learning\\nUnsupervised learning\\nSemi-supervised learning\\nSelf-supervised learning\\nReinforcement learning\\nMeta-learning\\nOnline learning\\nBatch learning\\nCurriculum learning\\nRule-based learning\\nNeuro-symbolic AI\\nNeuromorphic engineering\\nQuantum machine learning\\n\\nProblems\\nClassification\\nGenerative modeling\\nRegression\\nClustering\\nDimensionality reduction\\nDensity estimation\\nAnomaly detection\\nData cleaning\\nAutoML\\nAssociation rules\\nSemantic analysis\\nStructured prediction\\nFeature engineering\\nFeature learning\\nLearning to rank\\nGrammar induction\\nOntology learning\\nMultimodal learning\\n\\nSupervised learning(classification\\xa0• regression) \\nApprenticeship learning\\nDecision trees\\nEnsembles\\nBagging\\nBoosting\\nRandom forest\\nk-NN\\nLinear regression\\nNaive Bayes\\nArtificial neural networks\\nLogistic regression\\nPerceptron\\nRelevance vector machine (RVM)\\nSupport vector machine (SVM)\\n\\nClustering\\nBIRCH\\nCURE\\nHierarchical\\nk-means\\nFuzzy\\nExpectation–maximization (EM)\\nDBSCAN\\nOPTICS\\nMean shift\\n\\nDimensionality reduction\\nFactor analysis\\nCCA\\nICA\\nLDA\\nNMF\\nPCA\\nPGD\\nt-SNE\\nSDL\\n\\nStructured prediction\\nGraphical models\\nBayes net\\nConditional random field\\nHidden Markov\\n\\nAnomaly detection\\nRANSAC\\nk-NN\\nLocal outlier factor\\nIsolation forest\\n\\nArtificial neural network\\nAutoencoder\\nDeep learning\\nFeedforward neural network\\nRecurrent neural network\\nLSTM\\nGRU\\nESN\\nreservoir computing\\nBoltzmann machine\\nRestricted\\nGAN\\nDiffusion model\\nSOM\\nConvolutional neural network\\nU-Net\\nLeNet\\nAlexNet\\nDeepDream\\nNeural radiance field\\nTransformer\\nVision\\nMamba\\nSpiking neural network\\nMemtransistor\\nElectrochemical RAM (ECRAM)\\n\\nReinforcement learning\\nQ-learning\\nSARSA\\nTemporal difference (TD)\\nMulti-agent\\nSelf-play\\n\\nLearning with humans\\nActive learning\\nCrowdsourcing\\nHuman-in-the-loop\\nRLHF\\n\\nModel diagnostics\\nCoefficient of determination\\nConfusion matrix\\nLearning curve\\nROC curve\\n\\nMathematical foundations\\nKernel machines\\nBias–variance tradeoff\\nComputational learning theory\\nEmpirical risk minimization\\nOccam learning\\nPAC learning\\nStatistical learning\\nVC theory\\n\\nJournals and conferences\\nECML PKDD\\nNeurIPS\\nICML\\nICLR\\nIJCAI\\nML\\nJMLR\\n\\nRelated articles\\nGlossary of artificial intelligence\\nList of datasets for machine-learning research\\nList of datasets in computer vision and image processing\\nOutline of machine learning\\nvte\\nA large language model (LLM) is a type of computational model designed for natural language processing tasks such as language generation. As language models, LLMs acquire these abilities by learning statistical relationships from vast amounts of text during a self-supervised and semi-supervised training process.[1]\\nThe largest and most capable LLMs are artificial neural networks built with a decoder-only transformer-based architecture, enabling efficient processing and generation of large-scale text data. Modern models can be fine-tuned for specific tasks or guided by prompt engineering.[2] These models acquire predictive power regarding syntax, semantics, and ontologies[3] inherent in human language corpora, but they also inherit inaccuracies and biases present in the data they are trained in.[4]\\n\\n\\nHistory[edit]\\nThe training compute of notable large models in FLOPs vs publication date over the period 2010-2024. For overall notable models (top left), frontier models (top right), top language models (bottom left) and top models within leading companies (bottom right). The majority of these models are language models.\\nThe training compute of notable large AI models in FLOPs vs publication date over the period 2017-2024. The majority of large models are language models or multimodal models with language capacity.\\nBefore 2017, there were a few language models that were large as compared to capacities then available. In the 1990s, the IBM alignment models pioneered statistical language modelling. A smoothed n-gram model in 2001 trained on 0.3 billion words achieved state-of-the-art perplexity at the time.[5] In the 2000s, as Internet use became prevalent, some researchers constructed Internet-scale language datasets (\"web as corpus\"[6]), upon which they trained statistical language models.[7][8] In 2009, in most language processing tasks, statistical language models dominated over symbolic language models, as they can usefully ingest large datasets.[9]\\n\\nAfter neural networks became dominant in image processing around 2012,[10] they were applied to language modelling as well. Google converted its translation service to Neural Machine Translation in 2016. As it was before transformers, it was done by seq2seq deep LSTM networks.An illustration of main components of the transformer model from the original paper, where layers were normalized after (instead of before) multiheaded attention\\nAt the 2017 NeurIPS conference, Google researchers introduced the transformer architecture in their landmark paper \"Attention Is All You Need\". This paper\\'s goal was to improve upon 2014 seq2seq technology,[11] and was based mainly on the attention mechanism developed by Bahdanau et al. in 2014.[12] The following year in 2018, BERT was introduced and quickly became \"ubiquitous\".[13] Though the original transformer has both encoder and decoder blocks, BERT is an encoder-only model. \\nAcademic and research usage of BERT began to decline in 2023, following rapid improvements in the abilities of decoder-only models (such as GPT) to solve tasks via prompting.[14]\\nAlthough decoder-only GPT-1 was introduced in 2018, it was GPT-2 in 2019 that caught widespread attention because OpenAI at first deemed it too powerful to release publicly, out of fear of malicious use.[15] GPT-3 in 2020 went a step further and as of 2024[update] is available only via API with no offering of downloading the model to execute locally. But it was the 2022 consumer-facing browser-based ChatGPT that captured the imaginations of the general population and caused some media hype and online buzz.[16] The 2023 GPT-4 was praised for its increased accuracy and as a \"holy grail\" for its multimodal capabilities.[17] OpenAI did not reveal the high-level architecture and the number of parameters of GPT-4. The release of ChatGPT led to an uptick in LLM usage across several research subfields of computer science, including robotics, software engineering, and societal impact work.[18]\\nCompeting language models have for the most part been attempting to equal the GPT series, at least in terms of number of parameters.[19]\\nSince 2022, source-available models have been gaining popularity, especially at first with BLOOM and LLaMA, though both have restrictions on the field of use. Mistral AI\\'s models Mistral 7B and Mixtral 8x7b have the more permissive Apache License. As of June\\xa02024[update], The Instruction fine tuned variant of the Llama 3 70 billion parameter model is the most powerful open LLM according to the LMSYS Chatbot Arena Leaderboard, being more powerful than GPT-3.5 but not as powerful as GPT-4.[20]\\nAs of 2024, the largest and most capable models are all based on the Transformer architecture. Some recent implementations are based on other architectures, such as recurrent neural network variants and Mamba (a state space model).[21][22][23]\\n\\nDataset preprocessing[edit]\\nSee also: List of datasets for machine-learning research §\\xa0Internet\\nTokenization[edit]\\n\\nBecause machine learning algorithms process numbers rather than text, the text must be converted to numbers. In the first step, a vocabulary is decided upon, then integer indices are arbitrarily but uniquely assigned to each vocabulary entry, and finally, an embedding is associated to the integer index. Algorithms include byte-pair encoding (BPE) and WordPiece. There are also special tokens serving as control characters, such as [MASK] for masked-out token (as used in BERT), and [UNK] (\"unknown\") for characters not appearing in the vocabulary. Also, some special symbols are used to denote special text formatting. For example, \"Ġ\" denotes a preceding whitespace in RoBERTa and GPT. \"##\" denotes continuation of a preceding word in BERT.[24]\\nFor example, the BPE tokenizer used by GPT-3 (Legacy) would split tokenizer: texts -> series of numerical \"tokens\" as\\n\\n\\n\\ntoken\\n\\nizer\\n\\n:\\n\\n\\xa0texts\\n\\n\\xa0->\\n\\nseries\\n\\n\\xa0of\\n\\n\\xa0numerical\\n\\n\\xa0\"\\n\\nt\\n\\nok\\n\\nens\\n\\n\"\\n\\nTokenization also compresses the datasets. Because LLMs generally require input to be an array that is not jagged, the shorter texts must be \"padded\" until they match the length of the longest one. How many tokens are, on average, needed per word depends on the language of the dataset.[25][26]\\n\\nBPE[edit]\\nMain article: Byte pair encoding\\nAs an example, consider a tokenizer based on byte-pair encoding. In the first step, all unique characters (including blanks and punctuation marks) are treated as an initial set of n-grams (i.e. initial set of uni-grams). Successively the most frequent pair of adjacent characters is merged into a bi-gram and all instances of the pair are replaced by it. All occurrences of adjacent pairs of (previously merged) n-grams that most frequently occur together are then again merged into even lengthier n-gram, until a vocabulary of prescribed size is obtained (in case of GPT-3, the size is 50257).[27] After a tokenizer is trained, any text can be tokenized by it, as long as it does not contain characters not appearing in the initial-set of uni-grams.[28]\\n\\nProblems[edit]\\nA token vocabulary based on the frequencies extracted from mainly English corpora uses as few tokens as possible for an average English word. An average word in another language encoded by such an English-optimized tokenizer is however split into suboptimal amount of tokens. GPT-2 tokenizer can use up to 15 times more tokens per word for some languages, for example for the Shan language from Myanmar. Even more widespread languages such as Portuguese and German have \"a premium of 50%\" compared to English.[29]\\nGreedy tokenization also causes subtle problems with text completion.[30]\\n\\nDataset cleaning[edit]\\nMain article: Data cleansing\\nIn the context of training LLMs, datasets are typically cleaned by removing toxic passages from the dataset, discarding low-quality data, and de-duplication.[31] Cleaned datasets can increase training efficiency and lead to improved downstream performance.[32][33] A trained LLM can be used to clean datasets for training a further LLM.[34]\\nWith the increasing proportion of LLM-generated content on the web, data cleaning in the future may include filtering out such content. LLM-generated content can pose a problem if the content is similar to human text (making filtering difficult) but of lower quality (degrading performance of models trained on it).[35]\\n\\nSynthetic data[edit]\\nMain article: Synthetic data\\nTraining of largest language models might need more linguistic data than naturally available, or that the naturally occurring data is of insufficient quality. In these cases, synthetic data might be used. Microsoft\\'s Phi series of LLMs is trained on textbook-like data generated by another LLM.[36]\\n\\nTraining and architecture[edit]\\nSee also: Fine-tuning (machine learning)\\nReinforcement learning from human feedback (RLHF)[edit]\\nMain article: Reinforcement learning from human feedback\\nReinforcement learning from human feedback (RLHF) through algorithms, such as proximal policy optimization, is used to further fine-tune a model based on a dataset of human preferences.[37]\\n\\nInstruction tuning[edit]\\nUsing \"self-instruct\" approaches, LLMs have been able to bootstrap correct responses, replacing any naive responses, starting from human-generated corrections of a few cases. For example, in the instruction \"Write an essay about the main themes represented in Hamlet,\" an initial naive completion might be \"If you submit the essay after March 17, your grade will be reduced by 10% for each day of delay,\" based on the frequency of this textual sequence in the corpus.[38]\\n\\nMixture of experts[edit]\\nMain article: Mixture of experts\\nThe largest LLM may be too expensive to train and use directly. For such models, mixture of experts (MoE) can be applied, a line of research pursued by Google researchers since 2017 to train models reaching up to 1 trillion parameters.[39][40][41]\\n\\nPrompt engineering, attention mechanism, and context window[edit]\\nSee also: Prompt engineering and Attention (machine learning)\\nMost results previously achievable only by (costly) fine-tuning, can be achieved through prompt engineering, although limited to the scope of a single conversation (more precisely, limited to the scope of a context window).[42]\\n\\n When each head calculates, according to its own criteria, how much other tokens are relevant for the \"it_\" token, note that the second attention head, represented by the second column, is focusing most on the first two rows, i.e. the tokens \"The\" and \"animal\", while the third column is focusing most on the bottom two rows, i.e. on \"tired\", which has been tokenized into two tokens.[43]\\nIn order to find out which tokens are relevant to each other within the scope of the context window, the attention mechanism calculates \"soft\" weights for each token, more precisely for its embedding, by using multiple attention heads, each with its own \"relevance\" for calculating its own soft weights. For example, the small (i.e. 117M parameter sized) GPT-2 model has had twelve attention heads and a context window of only 1k tokens.[44] In its medium version it has 345M parameters and contains 24 layers, each with 12 attention heads. For the training with gradient descent a batch size of 512 was utilized.[28]\\nThe largest models, such as Google\\'s Gemini 1.5, presented in February 2024, can have a context window sized up to 1 million (context window of 10 million was also \"successfully tested\").[45] Other models with large context windows includes Anthropic\\'s Claude 2.1, with a context window of up to 200k tokens.[46] Note that this maximum refers to the number of input tokens and that the maximum number of output tokens differs from the input and is often smaller. For example, the GPT-4 Turbo model has a maximum output of 4096 tokens.[47]\\nLength of a conversation that the model can take into account when generating its next answer is limited by the size of a context window, as well. If the length of a conversation, for example with ChatGPT, is longer than its context window, only the parts inside the context window are taken into account when generating the next answer, or the model needs to apply some algorithm to summarize the too distant parts of conversation.\\nThe shortcomings of making a context window larger include higher computational cost and possibly diluting the focus on local context, while making it smaller can cause a model to miss an important long-range dependency. Balancing them are a matter of experimentation and domain-specific considerations.\\nA model may be pre-trained either to predict how the segment continues, or what is missing in the segment, given a segment from its training dataset.[48] It can be either\\n\\nautoregressive (i.e. predicting how the segment continues, the way GPTs do it): for example given a segment \"I like to eat\", the model predicts \"ice cream\", or \"sushi\".\\n\"masked\" (i.e. filling in the parts missing from the segment, the way \"BERT\"[49] does it): for example, given a segment \"I like to [__] [__] cream\", the model predicts that \"eat\" and \"ice\" are missing.\\nModels may be trained on auxiliary tasks which test their understanding of the data distribution, such as Next Sentence Prediction (NSP), in which pairs of sentences are presented and the model must predict whether they appear consecutively in the training corpus.[49] During training, regularization loss is also used to stabilize training. However regularization loss is usually not used during testing and evaluation.\\n\\nInfrastructure[edit]\\nSubstantial infrastructure is necessary for training the largest models.[50][51][52]\\n\\nTraining cost[edit]\\n\\nAdvances in software and hardware have reduced the cost substantially since 2020, such that in 2023 training of a 12-billion-parameter LLM computational cost is 72,300 A100-GPU-hours, while in 2020 the cost of training a 1.5-billion-parameter LLM (which was two orders of magnitude smaller than the state of the art in 2020) was between $80,000 and $1,600,000.[53][54][55] Since 2020, large sums were invested in increasingly large models. For example, training of the GPT-2 (i.e. a 1.5-billion-parameters model) in 2019 cost $50,000, while training of the PaLM (i.e. a 540-billion-parameters model) in 2022 cost $8 million, and Megatron-Turing NLG 530B (in 2021) cost around $11 million.[56]\\nFor Transformer-based LLM, training cost is much higher than inference cost. It costs 6 FLOPs per parameter to train on one token, whereas it costs 1 to 2 FLOPs per parameter to infer on one token.[57]\\n\\nTool use[edit]\\nThere are certain tasks that, in principle, cannot be solved by any LLM, at least not without the use of external tools or additional software. An example of such a task is responding to the user\\'s input \\'354 * 139 = \\', provided that the LLM has not already encountered a continuation of this calculation in its training corpus.[dubious – discuss] In such cases, the LLM needs to resort to running program code that calculates the result, which can then be included in its response.[dubious – discuss]: Another example is \"What is the time now? It is \", where a separate program interpreter would need to execute a code to get system time on the computer, so that the LLM can include it in its reply.[58][59] This basic strategy can be sophisticated with multiple attempts of generated programs, and other sampling strategies.[60]\\nGenerally, in order to get an LLM to use tools, one must fine-tune it for tool-use. If the number of tools is finite, then fine-tuning may be done just once. If the number of tools can grow arbitrarily, as with online API services, then the LLM can be fine-tuned to be able to read API documentation and call API correctly.[61][62]\\nA simpler form of tool use is retrieval-augmented generation: the augmentation of an LLM with document retrieval. Given a query, a document retriever is called to retrieve the most relevant documents. This is usually done by encoding the query and the documents into vectors, then finding the documents with vectors (usually stored in a vector database) most similar to the vector of the query. The LLM then generates an output based on both the query and context included from the retrieved documents.[63]\\n\\nAgency[edit]\\nAn LLM is typically not an autonomous agent by itself, as it lacks the ability to interact with dynamic environments, recall past behaviors, and plan future actions, but can be transformed into one by integrating modules like profiling, memory, planning, and action.[64]\\nThe ReAct pattern, a portmanteau of \"Reason\\xa0+\\xa0Act\", constructs an agent out of an LLM, using the LLM as a planner. The LLM is prompted to \"think out loud\". Specifically, the language model is prompted with a textual description of the environment, a goal, a list of possible actions, and a record of the actions and observations so far. It generates one or more thoughts before generating an action, which is then executed in the environment.[65] The linguistic description of the environment given to the LLM planner can even be the LaTeX code of a paper describing the environment.[66]\\nIn the DEPS (\"Describe, Explain, Plan and Select\") method, an LLM is first connected to the visual world via image descriptions, then it is prompted to produce plans for complex tasks and behaviors based on its pretrained knowledge and environmental feedback it receives.[67]\\nThe Reflexion method[68] constructs an agent that learns over multiple episodes. At the end of each episode, the LLM is given the record of the episode, and prompted to think up \"lessons learned\", which would help it perform better at a subsequent episode. These \"lessons learned\" are given to the agent in the subsequent episodes.[citation needed]\\nMonte Carlo tree search can use an LLM as rollout heuristic. When a programmatic world model is not available, an LLM can also be prompted with a description of the environment to act as world model.[69]\\nFor open-ended exploration, an LLM can be used to score observations for their \"interestingness\", which can be used as a reward signal to guide a normal (non-LLM) reinforcement learning agent.[70] Alternatively, it can propose increasingly difficult tasks for curriculum learning.[71] Instead of outputting individual actions, an LLM planner can also construct \"skills\", or functions for complex action sequences. The skills can be stored and later invoked, allowing increasing levels of abstraction in planning.[71]\\nLLM-powered agents can keep a long-term memory of its previous contexts, and the memory can be retrieved in the same way as Retrieval Augmented Generation. Multiple such agents can interact socially.[72]\\n\\nCompression[edit]\\nTypically, LLMs are trained with single- or half-precision floating point numbers (float32 and float16). One float16 has 16 bits, or 2 bytes, and so one billion parameters require 2 gigabytes. The largest models typically have 100 billion parameters, requiring 200 gigabytes to load, which places them outside the range of most consumer electronics.[73]\\nPost-training quantization[74] aims to decrease the space requirement by lowering precision of the parameters of a trained model, while preserving most of its performance.[75][76] The simplest form of quantization simply truncates all numbers to a given number of bits. It can be improved by using a different quantization codebook per layer. Further improvement can be done by applying different precisions to different parameters, with higher precision for particularly important parameters (\"outlier weights\").[77] See [78] for a visual guide.\\nWhile quantized models are typically frozen, and only pre-quantized models are fine-tuned, quantized models can still be fine-tuned.[79]\\n\\nMultimodality[edit]\\nSee also: Multimodal learning\\nMultimodality means \"having several modalities\", and a \"modality\" refers to a type of input or output, such as video, image, audio, text, proprioception, etc.[80] There have been many AI models trained specifically to ingest one modality and output another modality, such as AlexNet for image to label,[81] visual question answering for image-text to text,[82] and speech recognition for speech to text.\\nA common method to create multimodal models out of an LLM is to \"tokenize\" the output of a trained encoder. Concretely, one can construct an LLM that can understand images as follows: take a trained LLM, and take a trained image encoder \\n\\n\\n\\nE\\n\\n\\n{\\\\displaystyle E}\\n\\n. Make a small multilayered perceptron \\n\\n\\n\\nf\\n\\n\\n{\\\\displaystyle f}\\n\\n, so that for any image \\n\\n\\n\\ny\\n\\n\\n{\\\\displaystyle y}\\n\\n, the post-processed vector \\n\\n\\n\\nf\\n(\\nE\\n(\\ny\\n)\\n)\\n\\n\\n{\\\\displaystyle f(E(y))}\\n\\n has the same dimensions as an encoded token. That is an \"image token\". Then, one can interleave text tokens and image tokens. The compound model is then fine-tuned on an image-text dataset. This basic construction can be applied with more sophistication to improve the model. The image encoder may be frozen to improve stability.[83]\\nFlamingo demonstrated the effectiveness of the tokenization method, finetuning a pair of pretrained language model and image encoder to perform better on visual question answering than models trained from scratch.[84] Google PaLM model was fine-tuned into a multimodal model PaLM-E using the tokenization method, and applied to robotic control.[85] LLaMA models have also been turned multimodal using the tokenization method, to allow image inputs,[86] and video inputs.[87]\\nGPT-4 can use both text and image as inputs[88] (although the vision component was not released to the public until GPT-4V[89]); Google DeepMind\\'s Gemini is also multimodal.[90]  Mistral introduced its own multimodel Pixtral 12B model in September 2024.[91]\\n\\nProperties[edit]\\nScaling laws[edit]\\nMain article: Neural scaling law\\nThe performance of an LLM after pretraining largely depends on the:\\n\\ncost of pretraining \\n\\n\\n\\nC\\n\\n\\n{\\\\displaystyle C}\\n\\n (the total amount of compute used),\\nsize of the artificial neural network itself, such as number of parameters \\n\\n\\n\\nN\\n\\n\\n{\\\\displaystyle N}\\n\\n (i.e. amount of neurons in its layers, amount of weights between them and biases),\\nsize of its pretraining dataset (i.e. number of tokens in corpus, \\n\\n\\n\\nD\\n\\n\\n{\\\\displaystyle D}\\n\\n).\\n\"Scaling laws\" are empirical statistical laws that predict LLM performance based on such factors. One particular scaling law (\"Chinchilla scaling\") for LLM autoregressively trained for one epoch, with a log-log learning rate schedule, states that:[92]\\n\\n\\n\\n\\n\\n\\n{\\n\\n\\n\\nC\\n=\\n\\nC\\n\\n0\\n\\n\\nN\\nD\\n\\n\\n\\n\\nL\\n=\\n\\n\\nA\\n\\nN\\n\\nα\\n\\n\\n\\n\\n+\\n\\n\\nB\\n\\nD\\n\\nβ\\n\\n\\n\\n\\n+\\n\\nL\\n\\n0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n{\\\\displaystyle {\\\\begin{cases}C=C_{0}ND\\\\\\\\[6pt]L={\\\\frac {A}{N^{\\\\alpha }}}+{\\\\frac {B}{D^{\\\\beta }}}+L_{0}\\\\end{cases}}}\\n\\n where the variables are\\n\\n\\n\\n\\n\\nC\\n\\n\\n{\\\\displaystyle C}\\n\\n is the cost of training the model, in FLOPs.\\n\\n\\n\\n\\nN\\n\\n\\n{\\\\displaystyle N}\\n\\n is the number of parameters in the model.\\n\\n\\n\\n\\nD\\n\\n\\n{\\\\displaystyle D}\\n\\n is the number of tokens in the training set.\\n\\n\\n\\n\\nL\\n\\n\\n{\\\\displaystyle L}\\n\\n is the average negative log-likelihood loss per token (nats/token), achieved by the trained LLM on the test dataset.\\nand the statistical hyper-parameters are\\n\\n\\n\\n\\n\\n\\nC\\n\\n0\\n\\n\\n=\\n6\\n\\n\\n{\\\\displaystyle C_{0}=6}\\n\\n, meaning that it costs 6 FLOPs per parameter to train on one token. Note that training cost is much higher than inference cost, where it costs 1 to 2 FLOPs per parameter to infer on one token.[57]\\n\\n\\n\\n\\nα\\n=\\n0.34\\n,\\nβ\\n=\\n0.28\\n,\\nA\\n=\\n406.4\\n,\\nB\\n=\\n410.7\\n,\\n\\nL\\n\\n0\\n\\n\\n=\\n1.69\\n\\n\\n{\\\\displaystyle \\\\alpha =0.34,\\\\beta =0.28,A=406.4,B=410.7,L_{0}=1.69}\\n\\n\\nEmergent abilities[edit]\\nAt point(s) referred to as breaks,[93] the lines change their slopes, appearing on a linear-log plot as a series of linear segments connected by arcs.\\nPerformance of bigger models on various tasks, when plotted on a log-log scale, appears as a linear extrapolation of performance achieved by smaller models. However, this linearity may be punctuated by \"break(s)\"[93] in the scaling law, where the slope of the line changes abruptly, and where larger models acquire \"emergent abilities\".[42][94] They arise from the complex interaction of the model\\'s components and are not explicitly programmed or designed.[95]\\nFurthermore, recent research has demonstrated that AI systems, including large language models, can employ heuristic reasoning akin to human cognition. They balance between exhaustive logical processing and the use of cognitive shortcuts (heuristics), adapting their reasoning strategies to optimize between accuracy and effort. This behavior aligns with principles of resource-rational human cognition, as discussed in classical theories of bounded rationality and dual-process theory.[96]\\nThe most intriguing among emergent abilities is in-context learning from example demonstrations.[97] In-context learning is involved in tasks, such as:\\n\\nreported arithmetics, decoding the International Phonetic Alphabet, unscrambling a word\\'s letters, disambiguate word in context,[42][98][99] converting spatial words, cardinal directions (for example, replying \"northeast\" upon [0, 0, 1; 0, 0, 0; 0, 0, 0]), color terms represented in text.[100]\\nchain-of-thought prompting: Model outputs are improved by chain-of-thought prompting only when model size exceeds 62B. Smaller models perform better when prompted to answer immediately, without chain of thought.[101]\\nidentifying offensive content in paragraphs of Hinglish (a combination of Hindi and English), and generating a similar English equivalent of Kiswahili proverbs.[102]\\nSchaeffer et. al. argue that the emergent abilities are not unpredictably acquired, but predictably acquired according to a smooth scaling law. The authors considered a toy statistical model of an LLM solving multiple-choice questions, and showed that this statistical model, modified to account for other types of tasks, applies to these tasks as well.[103]\\nLet \\n\\n\\n\\nx\\n\\n\\n{\\\\displaystyle x}\\n\\n be the number of parameter count, and \\n\\n\\n\\ny\\n\\n\\n{\\\\displaystyle y}\\n\\n be the performance of the model.\\n\\n\\nWhen \\n\\n\\n\\ny\\n=\\n\\naverage\\xa0\\n\\nPr\\n(\\n\\ncorrect token\\n\\n)\\n\\n\\n{\\\\displaystyle y={\\\\text{average }}\\\\Pr({\\\\text{correct token}})}\\n\\n, then \\n\\n\\n\\n(\\nlog\\n\\u2061\\nx\\n,\\ny\\n)\\n\\n\\n{\\\\displaystyle (\\\\log x,y)}\\n\\n is an exponential curve (before it hits the plateau at one), which looks like emergence.\\nWhen \\n\\n\\n\\ny\\n=\\n\\naverage\\xa0\\n\\nlog\\n\\u2061\\n(\\nPr\\n(\\n\\ncorrect token\\n\\n)\\n)\\n\\n\\n{\\\\displaystyle y={\\\\text{average }}\\\\log(\\\\Pr({\\\\text{correct token}}))}\\n\\n, then the \\n\\n\\n\\n(\\nlog\\n\\u2061\\nx\\n,\\ny\\n)\\n\\n\\n{\\\\displaystyle (\\\\log x,y)}\\n\\n plot is a straight line (before it hits the plateau at zero), which does not look like emergence.\\nWhen \\n\\n\\n\\ny\\n=\\n\\naverage\\xa0\\n\\nPr\\n(\\n\\nthe most likely token is correct\\n\\n)\\n\\n\\n{\\\\displaystyle y={\\\\text{average }}\\\\Pr({\\\\text{the most likely token is correct}})}\\n\\n, then \\n\\n\\n\\n(\\nlog\\n\\u2061\\nx\\n,\\ny\\n)\\n\\n\\n{\\\\displaystyle (\\\\log x,y)}\\n\\n is a step-function, which looks like emergence.\\nInterpretation[edit]\\nLarge language models by themselves are black boxes, and it is not clear how they can perform linguistic tasks. There are several methods for understanding how LLM work.\\nMechanistic interpretability aims to reverse-engineer LLM by discovering symbolic algorithms that approximate the inference performed by LLM. One example is Othello-GPT, where a small Transformer is trained to predict legal Othello moves. It is found that there is a linear representation of Othello board, and modifying the representation changes the predicted legal Othello moves in the correct way.[104][105] In another example, a small Transformer is trained on Karel programs. Similar to the Othello-GPT example, there is a linear representation of Karel program semantics, and modifying the representation changes output in the correct way. The model also generates correct programs that are on average shorter than those in the training set.[106]\\nIn another example, the authors trained small transformers on modular arithmetic addition. The resulting models were reverse-engineered, and it turned out they used discrete Fourier transform.[107]\\n\\nUnderstanding and intelligence[edit]\\nSee also: Philosophy of artificial intelligence and Artificial consciousness\\nNLP researchers were evenly split when asked, in a 2022 survey, whether (untuned) LLMs \"could (ever) understand natural language in some nontrivial sense\".[108] Proponents of \"LLM understanding\" believe that some LLM abilities, such as mathematical reasoning, imply an ability to \"understand\" certain concepts. A Microsoft team argued in 2023 that GPT-4 \"can solve novel and difficult tasks that span mathematics, coding, vision, medicine, law, psychology and more\" and that GPT-4 \"could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence system\": \"Can one reasonably say that a system that passes exams for software engineering candidates is not really intelligent?\"[109][110] Ilya Sutskever argues that predicting the next word sometimes involves reasoning and deep insights, for example if the LLM has to predict the name of the criminal in an unknown detective novel after processing the entire story leading up to the revelation.[111] Some researchers characterize LLMs as \"alien intelligence\".[112][113] For example, Conjecture CEO Connor Leahy considers untuned LLMs to be like inscrutable alien \"Shoggoths\", and believes that RLHF tuning creates a \"smiling facade\" obscuring the inner workings of the LLM: \"If you don\\'t push it too far, the smiley face stays on. But then you give it [an unexpected] prompt, and suddenly you see this massive underbelly of insanity, of weird thought processes and clearly non-human understanding.\"[114][115]\\nIn contrast, some proponents of the \"LLMs lack understanding\" school believe that existing LLMs are \"simply remixing and recombining existing writing\",[113] a phenomenon known as stochastic parrot, or they point to the deficits existing LLMs continue to have in prediction skills, reasoning skills, agency, and explainability.[108] For example, GPT-4 has natural deficits in planning and in real-time learning.[110] Generative LLMs have been observed to confidently assert claims of fact which do not seem to be justified by their training data, a phenomenon which has been termed \"hallucination\".[116] Specifically, hallucinations in the context of LLMs correspond to the generation of text or responses that seem syntactically sound, fluent, and natural but are factually incorrect, nonsensical, or unfaithful to the provided source input.[117] Neuroscientist Terrence Sejnowski has argued that \"The diverging opinions of experts on the intelligence of LLMs suggests that our old ideas based on natural intelligence are inadequate\".[108]\\nThe matter of LLM\\'s exhibiting intelligence or understanding has two main aspects – the first is how to model thought and language in a computer system, and the second is how to enable the computer system to generate human like language.[108] These aspects of language as a model of cognition have been developed in the field of cognitive linguistics. American linguist George Lakoff presented Neural Theory of Language (NTL)[118] as a computational basis for using language as a model of learning tasks and understanding. The NTL Model outlines how specific neural structures of the human brain shape the nature of thought and language and in turn what are the computational properties of such neural systems that can be applied to model thought and language in a computer system. After a framework for modeling language in a computer systems was established, the focus shifted to establishing frameworks for computer systems to generate language with acceptable grammar. In his 2014 book titled The Language Myth: Why Language Is Not An Instinct, British cognitive linguist and digital communication technologist Vyvyan Evans mapped out the role of probabilistic context-free grammar (PCFG) in enabling NLP to model cognitive patterns and generate human like language.[119][120]\\n\\nEvaluation[edit]\\nPerplexity[edit]\\nThe canonical measure of the performance of an LLM is its perplexity on a given text corpus. Perplexity measures how well a model predicts the contents of a dataset; the higher the likelihood the model assigns to the dataset, the lower the perplexity. In mathematical terms, perplexity is the exponential of the average negative log likelihood per token.\\n\\n\\n\\n\\nlog\\n\\u2061\\n(\\n\\nPerplexity\\n\\n)\\n=\\n−\\n\\n\\n1\\nN\\n\\n\\n\\n∑\\n\\ni\\n=\\n1\\n\\n\\nN\\n\\n\\nlog\\n\\u2061\\n(\\nPr\\n(\\n\\n\\ntoken\\n\\n\\ni\\n\\n\\n∣\\n\\n\\ncontext for token\\n\\n\\ni\\n\\n\\n)\\n)\\n\\n\\n{\\\\displaystyle \\\\log({\\\\text{Perplexity}})=-{\\\\frac {1}{N}}\\\\sum _{i=1}^{N}\\\\log(\\\\Pr({\\\\text{token}}_{i}\\\\mid {\\\\text{context for token}}_{i}))}\\n\\n\\nHere, \\n\\n\\n\\nN\\n\\n\\n{\\\\displaystyle N}\\n\\n is the number of tokens in the text corpus, and \"context for token \\n\\n\\n\\ni\\n\\n\\n{\\\\displaystyle i}\\n\\n\" depends on the specific type of LLM. If the LLM is autoregressive, then \"context for token \\n\\n\\n\\ni\\n\\n\\n{\\\\displaystyle i}\\n\\n\" is the segment of text appearing before token \\n\\n\\n\\ni\\n\\n\\n{\\\\displaystyle i}\\n\\n. If the LLM is masked, then \"context for token \\n\\n\\n\\ni\\n\\n\\n{\\\\displaystyle i}\\n\\n\" is the segment of text surrounding token \\n\\n\\n\\ni\\n\\n\\n{\\\\displaystyle i}\\n\\n.\\nBecause language models may overfit to training data, models are usually evaluated by their perplexity on a test set.[49] This evaluation is potentially problematic for larger models which, as they are trained on increasingly large corpora of text, are increasingly likely to inadvertently include portions of any given test set.[2]\\n\\nBPW, BPC, and BPT[edit]\\nIn information theory, the concept of entropy is intricately linked to perplexity, a relationship notably established by Claude Shannon.[121] This relationship is mathematically expressed as \\n\\n\\n\\n\\nEntropy\\n\\n=\\n\\nlog\\n\\n2\\n\\n\\n\\u2061\\n(\\n\\nPerplexity\\n\\n)\\n\\n\\n{\\\\displaystyle {\\\\text{Entropy}}=\\\\log _{2}({\\\\text{Perplexity}})}\\n\\n.\\nEntropy, in this context, is commonly quantified in terms of bits per word (BPW) or bits per character (BPC), which hinges on whether the language model utilizes word-based or character-based tokenization.\\nNotably, in the case of larger language models that predominantly employ sub-word tokenization, bits per token (BPT) emerges as a seemingly more appropriate measure. However, due to the variance in tokenization methods across different Large Language Models (LLMs), BPT does not serve as a reliable metric for comparative analysis among diverse models. To convert BPT into BPW, one can multiply it by the average number of tokens per word.\\nIn the evaluation and comparison of language models, cross-entropy is generally the preferred metric over entropy. The underlying principle is that a lower BPW is indicative of a model\\'s enhanced capability for compression. This, in turn, reflects the model\\'s proficiency in making accurate predictions.\\n\\nTask-specific datasets and benchmarks[edit]\\nA large number of testing datasets and benchmarks have also been developed to evaluate the capabilities of language models on more specific downstream tasks. Tests may be designed to evaluate a variety of capabilities, including general knowledge, commonsense reasoning, and mathematical problem-solving.\\nOne broad category of evaluation dataset is question answering datasets, consisting of pairs of questions and correct answers, for example, (\"Have the San Jose Sharks won the Stanley Cup?\", \"No\").[122] A question answering task is considered \"open book\" if the model\\'s prompt includes text from which the expected answer can be derived (for example, the previous question could be adjoined with some text which includes the sentence \"The Sharks have advanced to the Stanley Cup finals once, losing to the Pittsburgh Penguins in 2016.\"[122]). Otherwise, the task is considered \"closed book\", and the model must draw on knowledge retained during training.[123] Some examples of commonly used question answering datasets include TruthfulQA, Web Questions, TriviaQA, and SQuAD.[123]\\nEvaluation datasets may also take the form of text completion, having the model select the most likely word or sentence to complete a prompt, for example: \"Alice was friends with Bob. Alice went to visit her friend, ____\".[2]\\nSome composite benchmarks have also been developed which combine a diversity of different evaluation datasets and tasks. Examples include GLUE, SuperGLUE, MMLU, BIG-bench, and HELM.[121][123] OpenAI has released tools for running composite benchmarks, but noted that the eval results are sensitive to the prompting method.[124][125] Some public datasets contain questions that are mislabeled, ambiguous, unanswerable, or otherwise of low-quality, which can be cleaned to give more reliable benchmark scores.[126]\\nIt was previously standard to report results on a heldout portion of an evaluation dataset after doing supervised fine-tuning on the remainder. It is now more common to evaluate a pre-trained model directly through prompting techniques, though researchers vary in the details of how they formulate prompts for particular tasks, particularly with respect to how many examples of solved tasks are adjoined to the prompt (i.e. the value of n in n-shot prompting).\\n\\nAdversarially constructed evaluations[edit]\\nBecause of the rapid pace of improvement of large language models, evaluation benchmarks have suffered from short lifespans, with state of the art models quickly \"saturating\" existing benchmarks, exceeding the performance of human annotators, leading to efforts to replace or augment the benchmark with more challenging tasks.[127] In addition, there are cases of \"shortcut learning\" wherein AIs sometimes \"cheat\" on multiple-choice tests by using statistical correlations in superficial test question wording in order to guess the correct responses, without necessarily understanding the actual question being asked.[108]\\nSome datasets have been constructed adversarially, focusing on particular problems on which extant language models seem to have unusually poor performance compared to humans. One example is the TruthfulQA dataset, a question answering dataset consisting of 817 questions which language models are susceptible to answering incorrectly by mimicking falsehoods to which they were repeatedly exposed during training. For example, an LLM may answer \"No\" to the question \"Can you teach an old dog new tricks?\" because of its exposure to the English idiom you can\\'t teach an old dog new tricks, even though this is not literally true.[128]\\nAnother example of an adversarial evaluation dataset is Swag and its successor, HellaSwag, collections of problems in which one of multiple options must be selected to complete a text passage. The incorrect completions were generated by sampling from a language model and filtering with a set of classifiers. The resulting problems are trivial for humans but at the time the datasets were created state of the art language models had poor accuracy on them. For example:\\n\\n\\nWe see a fitness center sign. We then see a man talking to the camera and sitting and laying on a exercise ball. The man...\\na) demonstrates how to increase efficient exercise work by running up and down balls.\\nb) moves all his arms and legs and builds up a lot of muscle.\\nc) then plays the ball and we see a graphics and hedge trimming demonstration.\\nd) performs sit ups while on the ball and talking.[129]\\n\\n\\nBERT selects b) as the most likely completion, though the correct answer is d).[129]\\n\\nWider impact[edit]\\nIn 2023, Nature Biomedical Engineering wrote that \"it is no longer possible to accurately distinguish\" human-written text from text created by large language models, and that \"It is all but certain that general-purpose large language models will rapidly proliferate... It is a rather safe bet that they will change many industries over time.\"[130] Goldman Sachs suggested in 2023 that generative language AI could increase global GDP by 7% in the next ten years, and could expose to automation 300 million jobs globally.[131][132]\\n\\nMemorization and copyright[edit]\\nFurther information: Artificial intelligence and copyright\\nMemorization is an emergent behavior in LLMs in which long strings of text are occasionally output verbatim from training data, contrary to typical behavior of traditional artificial neural nets. Evaluations of controlled LLM output measure the amount memorized from training data (focused on GPT-2-series models) as variously over 1% for exact duplicates[133] or up to about 7%.[134]\\n\\nSecurity[edit]\\nSome commenters expressed concern over accidental or deliberate creation of misinformation, or other forms of misuse.[135] For example, the availability of large language models could reduce the skill-level required to commit bioterrorism; biosecurity researcher Kevin Esvelt has suggested that LLM creators should exclude from their training data papers on creating or enhancing pathogens.[136]\\nA study by researchers at Google and several universities, including Cornell University and University of California, Berkeley, showed that there are potential security risks in language models such as ChatGPT. In their study, they examined and confirmed the possibility that questioners could get, from ChatGPT, the training data that the AI model used. For example, when asking ChatGPT 3.5 turbo to repeat the word \"poem\" forever, the AI model will say \"poem\" hundreds of times and then diverge, deviating from the standard dialogue style and spitting out nonsense phrases, thus spitting out the training data as it is. The researchers have seen more than 10,000 examples of the AI model exposing their training data in a similar method. The researchers said that it was hard to tell if the AI model was actually safe or not.[137]\\nThe potential presence of \"sleeper agents\" within LLM models is another emerging security concern. These are hidden functionalities built into the model that remain dormant until triggered by a specific event or condition. Upon activation, the LLM deviates from its expected behavior to make insecure actions.[138]\\nLLM applications accessible to the public, like ChatGPT or Claude, typically incorporate safety measures designed to filter out harmful content. However, implementing these controls effectively has proven challenging. For instance, a 2023 study[139] proposed a method for circumventing LLM safety systems. Similarly, Yongge Wang[140] illustrated in 2024 how a potential criminal could potentially bypass ChatGPT 4o\\'s safety controls to obtain information on establishing a drug trafficking operation.\\n\\nAlgorithmic bias[edit]\\nMain article: Algorithmic bias\\nWhile LLMs have shown remarkable capabilities in generating human-like text, they are susceptible to inheriting and amplifying biases present in their training data. This can manifest in skewed representations or unfair treatment of different demographics, such as those based on race, gender, language, and cultural groups.[141] Since English data is overrepresented in current large language models\\' training data, it may also downplay non-English views.[142]\\n\\nStereotyping[edit]\\nAI models can reinforce a wide range of stereotypes, including those based on gender, ethnicity, age, nationality, religion, or occupation. This can lead to outputs that unfairly generalize or caricature groups of people, sometimes in harmful or derogatory ways.[143]\\nNotably, gender bias refers to the tendency of these models to produce outputs that are unfairly prejudiced towards one gender over another. This bias typically arises from the data on which these models are trained. Large language models often assign roles and characteristics based on traditional gender norms.[141] For example, it might associate nurses or secretaries predominantly with women and engineers or CEOs with men.[144]\\n\\nPolitical bias[edit]\\nPolitical bias refers to the tendency of algorithms to systematically favor certain political viewpoints, ideologies, or outcomes over others. Language models may also exhibit political biases. Since the training data includes a wide range of political opinions and coverage, the models might generate responses that lean towards particular political ideologies or viewpoints, depending on the prevalence of those views in the data.[145]\\n\\nList of large language models[edit]\\nSee also: List of chatbots\\nFor the training cost column, 1 petaFLOP-day = 1 petaFLOP/sec × 1 day = 8.64E19 FLOP. Also, only the largest model\\'s cost is written.\\n\\n\\n\\nName\\nRelease date[a]\\nDeveloper\\nNumber of parameters (billion) [b]\\nCorpus size\\n\\nTraining cost (petaFLOP-day)\\nLicense[c]\\nNotes\\n\\n\\nGPT-1\\nJune 2018\\nOpenAI\\n0.117\\n\\n\\n1[146]\\nMIT[147]\\n\\nFirst GPT model, decoder-only transformer. Trained for 30 days on 8 P600 GPUs.\\n\\n\\nBERT\\nOctober 2018\\nGoogle\\n0.340[148]\\n3.3 billion words[148]\\n\\n9[149]\\nApache 2.0[150]\\n\\nAn early and influential language model.[4] Encoder-only and thus not built to be prompted or generative.[151] Training took 4 days on 64 TPUv2 chips.[152]\\n\\n\\nT5\\n\\nOctober 2019\\n\\nGoogle\\n\\n11[153]\\n\\n34 billion tokens[153]\\n\\n\\n\\nApache 2.0[154]\\n\\nBase model for many Google projects, such as Imagen.[155]\\n\\n\\nXLNet\\nJune 2019\\nGoogle\\n0.340[156]\\n33 billion words\\n\\n330\\nApache 2.0[157]\\n\\nAn alternative to BERT; designed as encoder-only. Trained on 512 TPU v3 chips for 5.5 days.[158]\\n\\n\\nGPT-2\\nFebruary 2019\\nOpenAI\\n1.5[159]\\n40GB[160] (~10 billion tokens)[161]\\n\\n28[162]\\nMIT[163]\\n\\nTrained on 32 TPUv3 chips for 1 week.[162]\\n\\n\\nGPT-3\\nMay 2020\\nOpenAI\\n175[53]\\n300 billion tokens[161]\\n\\n3640[164]\\nproprietary\\n\\nA fine-tuned variant of GPT-3, termed GPT-3.5, was made available to the public through a web interface called ChatGPT in 2022.[165]\\n\\n\\nGPT-Neo\\nMarch 2021\\nEleutherAI\\n2.7[166]\\n825 GiB[167]\\n\\n\\nMIT[168]\\n\\nThe first of a series of free GPT-3 alternatives released by EleutherAI. GPT-Neo outperformed an equivalent-size GPT-3 model on some benchmarks, but was significantly worse than the largest GPT-3.[168]\\n\\n\\nGPT-J\\nJune 2021\\nEleutherAI\\n6[169]\\n825 GiB[167]\\n\\n200[170]\\nApache 2.0\\n\\nGPT-3-style language model\\n\\n\\nMegatron-Turing NLG\\nOctober 2021[171]\\nMicrosoft and Nvidia\\n530[172]\\n338.6 billion tokens[172]\\n\\n38000[173]\\nRestricted web access\\n\\nTrained for 3 months on over 2000 A100 GPUs on the NVIDIA Selene Supercomputer, for over 3 million GPU-hours.[173]\\n\\n\\nErnie 3.0 Titan\\nDecember 2021\\nBaidu\\n260[174]\\n4 Tb\\n\\n\\nProprietary\\n\\nChinese-language LLM. Ernie Bot is based on this model.\\n\\n\\nClaude[175]\\nDecember 2021\\nAnthropic\\n52[176]\\n400 billion tokens[176]\\n\\n\\nbeta\\n\\nFine-tuned for desirable behavior in conversations.[177]\\n\\n\\nGLaM (Generalist Language Model)\\nDecember 2021\\nGoogle\\n1200[41]\\n1.6 trillion tokens[41]\\n\\n5600[41]\\nProprietary\\n\\nSparse mixture of experts model, making it more expensive to train but cheaper to run inference compared to GPT-3.\\n\\n\\nGopher\\nDecember 2021\\nDeepMind\\n280[178]\\n300 billion tokens[179]\\n\\n5833[180]\\nProprietary\\n\\nLater developed into the Chinchilla model.\\n\\n\\nLaMDA (Language Models for Dialog Applications)\\nJanuary 2022\\nGoogle\\n137[181]\\n1.56T words,[181] 168 billion tokens[179]\\n\\n4110[182]\\nProprietary\\n\\nSpecialized for response generation in conversations.\\n\\n\\nGPT-NeoX\\nFebruary 2022\\nEleutherAI\\n20[183]\\n825 GiB[167]\\n\\n740[170]\\nApache 2.0\\n\\nbased on the Megatron architecture\\n\\n\\nChinchilla\\nMarch 2022\\nDeepMind\\n70[184]\\n1.4 trillion tokens[184][179]\\n\\n6805[180]\\nProprietary\\n\\nReduced-parameter model trained on more data. Used in the Sparrow bot. Often cited for its neural scaling law.\\n\\n\\nPaLM (Pathways Language Model)\\nApril 2022\\nGoogle\\n540[185]\\n768 billion tokens[184]\\n\\n29,250[180]\\nProprietary\\n\\nTrained for ~60 days on ~6000 TPU v4 chips.[180] As of October\\xa02024[update], it is the largest dense Transformer published.\\n\\n\\nOPT (Open Pretrained Transformer)\\nMay 2022\\nMeta\\n175[186]\\n180 billion tokens[187]\\n\\n310[170]\\nNon-commercial research[d]\\n\\nGPT-3 architecture with some adaptations from Megatron. Uniquely, the training logbook written by the team was published.[188]\\n\\n\\nYaLM 100B\\nJune 2022\\nYandex\\n100[189]\\n\\n1.7TB[189]\\n\\nApache 2.0\\nEnglish-Russian model based on Microsoft\\'s Megatron-LM.\\n\\n\\nMinerva\\nJune 2022\\nGoogle\\n540[190]\\n38.5B tokens from webpages filtered for mathematical content and from papers submitted to the arXiv preprint server[190]\\n\\n\\nProprietary\\n\\nFor solving \"mathematical and scientific questions using step-by-step reasoning\".[191] Initialized from PaLM models, then finetuned on mathematical and scientific data.\\n\\n\\nBLOOM\\nJuly 2022\\nLarge collaboration led by Hugging Face\\n175[192]\\n350 billion tokens (1.6TB)[193]\\n\\n\\nResponsible AI\\n\\nEssentially GPT-3 but trained on a multi-lingual corpus (30% English excluding programming languages)\\n\\n\\nGalactica\\nNovember 2022\\nMeta\\n120\\n106 billion tokens[194]\\n\\nunknown\\nCC-BY-NC-4.0\\n\\nTrained on scientific text and modalities.\\n\\n\\nAlexaTM (Teacher Models)\\nNovember 2022\\nAmazon\\n20[195]\\n1.3 trillion[196]\\n\\n\\nproprietary[197]\\n\\nbidirectional sequence-to-sequence architecture\\n\\n\\nNeuro-sama\\nDecember 2022\\nIndependent\\nUnknown\\nUnknown\\n\\n\\nprivately-owned\\n\\nA language model designed for live-streaming on Twitch.\\n\\n\\nLLaMA (Large Language Model Meta AI)\\nFebruary 2023\\nMeta AI\\n65[198]\\n1.4 trillion[198]\\n\\n6300[199]\\nNon-commercial research[e]\\n\\nCorpus has 20 languages. \"Overtrained\" (compared to Chinchilla scaling law) for better performance with fewer parameters.[198]\\n\\n\\nGPT-4\\nMarch 2023\\nOpenAI\\nUnknown[f] (According to rumors: 1760)[201]\\n\\nUnknown\\n\\nUnknown\\nproprietary\\n\\nAvailable for ChatGPT Plus users and used in several products.\\n\\n\\nChameleon\\nJune 2024\\nMeta AI\\n34[202]\\n4.4 trillion\\n\\n\\n\\n\\nCerebras-GPT\\n\\nMarch 2023\\n\\nCerebras\\n\\n13[203]\\n\\n\\n\\n270[170]\\nApache 2.0\\n\\nTrained with Chinchilla formula.\\n\\n\\nFalcon\\nMarch 2023\\nTechnology Innovation Institute\\n40[204]\\n1 trillion tokens, from RefinedWeb (filtered web text corpus)[205] plus some \"curated corpora\".[206]\\n\\n2800[199]\\nApache 2.0[207]\\n\\n\\n\\n\\nBloombergGPT\\nMarch 2023\\nBloomberg L.P.\\n50\\n363 billion token dataset based on Bloomberg\\'s data sources, plus 345 billion tokens from general purpose datasets[208]\\n\\n\\nProprietary\\n\\nTrained on financial data from proprietary sources, for financial tasks.\\n\\n\\nPanGu-Σ\\nMarch 2023\\nHuawei\\n1085\\n329 billion tokens[209]\\n\\n\\nProprietary\\n\\n\\n\\n\\nOpenAssistant[210]\\nMarch 2023\\nLAION\\n17\\n1.5 trillion tokens\\n\\n\\nApache 2.0\\n\\nTrained on crowdsourced open data\\n\\n\\nJurassic-2[211]\\n\\nMarch 2023\\n\\nAI21 Labs\\n\\nUnknown\\n\\nUnknown\\n\\n\\nProprietary\\n\\nMultilingual[212]\\n\\n\\nPaLM 2 (Pathways Language Model 2)\\nMay 2023\\nGoogle\\n340[213]\\n3.6 trillion tokens[213]\\n\\n85,000[199]\\nProprietary\\n\\nWas used in Bard chatbot.[214]\\n\\n\\nLlama 2\\nJuly 2023\\nMeta AI\\n70[215]\\n2 trillion tokens[215]\\n\\n21,000\\nLlama 2 license\\n\\n1.7 million A100-hours.[216]\\n\\n\\nClaude 2\\n\\nJuly 2023\\n\\nAnthropic\\n\\nUnknown\\n\\nUnknown\\n\\nUnknown\\nProprietary\\n\\nUsed in Claude chatbot.[217]\\n\\n\\nGranite 13b\\n\\nJuly 2023\\n\\nIBM\\n\\nUnknown\\n\\nUnknown\\n\\nUnknown\\nProprietary\\n\\nUsed in IBM Watsonx.[218]\\n\\n\\nMistral 7B\\nSeptember 2023\\nMistral AI\\n7.3[219]\\nUnknown\\n\\n\\nApache 2.0\\n\\n\\n\\n\\nClaude 2.1\\n\\nNovember 2023\\n\\nAnthropic\\n\\nUnknown\\n\\nUnknown\\n\\nUnknown\\nProprietary\\n\\nUsed in Claude chatbot. Has a context window of 200,000 tokens, or ~500 pages.[220]\\n\\n\\nGrok-1[221]\\n\\nNovember 2023\\n\\nxAI\\n\\n314\\n\\nUnknown\\n\\nUnknown\\nApache 2.0\\n\\nUsed in Grok chatbot. Grok-1 has a context length of 8,192 tokens and has access to X (Twitter).[222]\\n\\n\\nGemini 1.0\\n\\nDecember 2023\\n\\nGoogle DeepMind\\n\\nUnknown\\n\\nUnknown\\n\\nUnknown\\nProprietary\\n\\nMultimodal model, comes in three sizes. Used in the chatbot of the same name.[223]\\n\\n\\nMixtral 8x7B\\n\\nDecember 2023\\n\\nMistral AI\\n\\n46.7\\n\\nUnknown\\n\\nUnknown\\nApache 2.0\\n\\nOutperforms GPT-3.5 and Llama 2 70B on many benchmarks.[224] Mixture of experts model, with 12.9 billion parameters activated per token.[225]\\n\\n\\nMixtral 8x22B\\n\\nApril 2024\\n\\nMistral AI\\n\\n141\\n\\nUnknown\\n\\nUnknown\\nApache 2.0\\n\\n[226]\\n\\n\\nPhi-2\\n\\nDecember 2023\\n\\nMicrosoft\\n\\n2.7\\n\\n1.4T tokens\\n\\n419[227]\\nMIT\\n\\nTrained on real and synthetic \"textbook-quality\" data, for 14 days on 96 A100 GPUs.[227]\\n\\n\\nGemini 1.5\\n\\nFebruary 2024\\n\\nGoogle DeepMind\\n\\nUnknown\\n\\nUnknown\\n\\nUnknown\\nProprietary\\n\\nMultimodal model, based on a Mixture-of-Experts (MoE) architecture. Context window above 1 million tokens.[228]\\n\\n\\nGemini Ultra\\n\\nFebruary 2024\\n\\nGoogle DeepMind\\n\\nUnknown\\n\\nUnknown\\n\\nUnknown\\n\\n\\n\\n\\n\\nGemma\\nFebruary 2024\\nGoogle DeepMind\\n7\\n6T tokens\\nUnknown\\nGemma Terms of Use[229]\\n\\n\\n\\nClaude 3\\n\\nMarch 2024\\n\\nAnthropic\\n\\nUnknown\\n\\nUnknown\\n\\nUnknown\\n\\nProprietary\\n\\nIncludes three models, Haiku, Sonnet, and Opus.[230]\\n\\n\\nNova\\n\\nOctober 2024\\n\\nRubik\\'s AI\\n\\nUnknown\\n\\nUnknown\\n\\nUnknown\\n\\nProprietary\\n\\nIncludes three models, Nova-Instant, Nova-Air, and Nova-Pro.\\n\\n\\nDBRX\\n\\nMarch 2024\\n\\nDatabricks and Mosaic ML\\n\\n136\\n\\n12T Tokens\\n\\n\\n\\nDatabricks Open Model License\\n\\nTraining cost 10 million USD.\\n\\n\\nFugaku-LLM\\n\\nMay 2024\\n\\nFujitsu, Tokyo Institute of Technology, etc.\\n\\n13\\n\\n380B Tokens\\n\\n\\n\\n\\n\\nThe largest model ever trained on CPU-only, on the Fugaku.[231]\\n\\n\\nPhi-3\\n\\nApril 2024\\n\\nMicrosoft\\n\\n14[232]\\n\\n4.8T Tokens\\n\\n\\n\\nMIT\\n\\nMicrosoft markets them as \"small language model\".[233]\\n\\n\\nGranite Code Models\\n\\nMay 2024\\n\\nIBM\\n\\nUnknown\\n\\nUnknown\\n\\nUnknown\\nApache 2.0\\n\\n\\n\\n\\nQwen2\\n\\nJune 2024\\n\\nAlibaba Cloud\\n\\n72[234]\\n\\n3T Tokens\\n\\n\\n\\n\\n\\nMultiple sizes, the smallest being 0.5B.\\n\\n\\nNemotron-4\\n\\nJune 2024\\n\\nNvidia\\n\\n340\\n\\n9T Tokens\\n\\n200,000\\n\\nNVIDIA Open Model License\\n\\nTrained for 1 epoch. Trained on 6144 H100 GPUs between December 2023 and May 2024.[235][236]\\n\\n\\nLlama 3.1\\n\\nJuly 2024\\n\\nMeta AI\\n\\n405\\n\\n15.6T tokens\\n\\n440,000\\n\\nLlama 3 license\\n\\n405B version took 31 million hours on H100-80GB, at 3.8E25 FLOPs.[237][238]\\n\\nSee also[edit]\\nFoundation models\\nNotes[edit]\\n\\n\\n^ This is the date that documentation describing the model\\'s architecture was first released.\\n\\n^ In many cases, researchers release or report on multiple versions of a model having different sizes. In these cases, the size of the largest model is listed here.\\n\\n^ This is the license of the pre-trained model weights. In almost all cases the training code itself is open-source or can be easily replicated.\\n\\n^ The smaller models including 66B are publicly available, while the 175B model is available on request.\\n\\n^ Facebook\\'s license and distribution scheme restricted access to approved researchers, but the model weights were leaked and became widely available.\\n\\n^ As stated in Technical report: \"Given both the competitive landscape and the safety implications of large-scale models like GPT-4, this report contains no further details about the architecture (including model size), hardware, training compute, dataset construction, training method ...\"[200] \\n\\n\\nReferences[edit]\\n\\n\\n^ \"Better Language Models and Their Implications\". OpenAI. 2019-02-14. Archived from the original on 2020-12-19. Retrieved 2019-08-25.\\n\\n^ a b c Brown, Tom B.; Mann, Benjamin; Ryder, Nick; Subbiah, Melanie; Kaplan, Jared; Dhariwal, Prafulla; Neelakantan, Arvind; Shyam, Pranav; Sastry, Girish; Askell, Amanda; Agarwal, Sandhini; Herbert-Voss, Ariel; Krueger, Gretchen; Henighan, Tom; Child, Rewon; Ramesh, Aditya; Ziegler, Daniel M.; Wu, Jeffrey; Winter, Clemens; Hesse, Christopher; Chen, Mark; Sigler, Eric; Litwin, Mateusz; Gray, Scott; Chess, Benjamin; Clark, Jack; Berner, Christopher; McCandlish, Sam; Radford, Alec; Sutskever, Ilya; Amodei, Dario (Dec 2020). Larochelle, H.; Ranzato, M.; Hadsell, R.; Balcan, M.F.; Lin, H. (eds.). \"Language Models are Few-Shot Learners\" (PDF). Advances in Neural Information Processing Systems. 33. Curran Associates, Inc.: 1877–1901. Archived (PDF) from the original on 2023-11-17. Retrieved 2023-03-14.\\n\\n^ Fathallah, Nadeen; Das, Arunav; De Giorgis, Stefano; Poltronieri, Andrea; Haase, Peter; Kovriguina, Liubov (2024-05-26). NeOn-GPT: A Large Language Model-Powered Pipeline for Ontology Learning (PDF). Extended Semantic Web Conference 2024. Hersonissos, Greece.\\n\\n^ a b Manning, Christopher D. (2022). \"Human Language Understanding & Reasoning\". Daedalus. 151 (2): 127–138. doi:10.1162/daed_a_01905. S2CID\\xa0248377870. Archived from the original on 2023-11-17. Retrieved 2023-03-09.\\n\\n^ Goodman, Joshua (2001-08-09), A Bit of Progress in Language Modeling, arXiv:cs/0108005, Bibcode:2001cs........8005G\\n\\n^ Kilgarriff, Adam; Grefenstette, Gregory (September 2003). \"Introduction to the Special Issue on the Web as Corpus\". Computational Linguistics. 29 (3): 333–347. doi:10.1162/089120103322711569. ISSN\\xa00891-2017.\\n\\n^ Banko, Michele; Brill, Eric (2001). \"Scaling to very very large corpora for natural language disambiguation\". Proceedings of the 39th Annual Meeting on Association for Computational Linguistics - ACL \\'01. Morristown, NJ, USA: Association for Computational Linguistics: 26–33. doi:10.3115/1073012.1073017.\\n\\n^ Resnik, Philip; Smith, Noah A. (September 2003). \"The Web as a Parallel Corpus\". Computational Linguistics. 29 (3): 349–380. doi:10.1162/089120103322711578. ISSN\\xa00891-2017. Archived from the original on 2024-06-07. Retrieved 2024-06-07.\\n\\n^ Halevy, Alon; Norvig, Peter; Pereira, Fernando (March 2009). \"The Unreasonable Effectiveness of Data\". IEEE Intelligent Systems. 24 (2): 8–12. doi:10.1109/MIS.2009.36. ISSN\\xa01541-1672.\\n\\n^ Chen, Leiyu; Li, Shaobo; Bai, Qiang; Yang, Jing; Jiang, Sanlong; Miao, Yanming (2021). \"Review of Image Classification Algorithms Based on Convolutional Neural Networks\". Remote Sensing. 13 (22): 4712. Bibcode:2021RemS...13.4712C. doi:10.3390/rs13224712.\\n\\n^ Vaswani, Ashish; Shazeer, Noam; Parmar, Niki; Uszkoreit, Jakob; Jones, Llion; Gomez, Aidan N; Kaiser, Łukasz; Polosukhin, Illia (2017). \"Attention is All you Need\" (PDF). Advances in Neural Information Processing Systems. 30. Curran Associates, Inc. Archived (PDF) from the original on 2024-02-21. Retrieved 2024-01-21.\\n\\n^ Bahdanau, Dzmitry; Cho, Kyunghyun; Bengio, Yoshua (2014). \"Neural Machine Translation by Jointly Learning to Align and Translate\". arXiv:1409.0473 [cs.CL].\\n\\n^ Rogers, Anna; Kovaleva, Olga; Rumshisky, Anna (2020). \"A Primer in BERTology: What We Know About How BERT Works\". Transactions of the Association for Computational Linguistics. 8: 842–866. arXiv:2002.12327. doi:10.1162/tacl_a_00349. S2CID\\xa0211532403. Archived from the original on 2022-04-03. Retrieved 2024-01-21.\\n\\n^ Movva, Rajiv; Balachandar, Sidhika; Peng, Kenny; Agostini, Gabriel; Garg, Nikhil; Pierson, Emma (2024). \"Topics, Authors, and Institutions in Large Language Model Research: Trends from 17K arXiv Papers\". Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers): 1223–1243. doi:10.18653/v1/2024.naacl-long.67. Retrieved 2024-12-08.{{cite journal}}:  CS1 maint: url-status (link)\\n\\n^ Hern, Alex (14 February 2019). \"New AI fake text generator may be too dangerous to release, say creators\". The Guardian. Archived from the original on 14 February 2019. Retrieved 20 January 2024.\\n\\n^ \"ChatGPT a year on: 3 ways the AI chatbot has completely changed the world in 12 months\". Euronews. November 30, 2023. Archived from the original on January 14, 2024. Retrieved January 20, 2024.\\n\\n^ Heaven, Will (March 14, 2023). \"GPT-4 is bigger and better than ChatGPT—but OpenAI won\\'t say why\". MIT Technology Review. Archived from the original on March 17, 2023. Retrieved January 20, 2024.\\n\\n^ Movva, Rajiv; Balachandar, Sidhika; Peng, Kenny; Agostini, Gabriel; Garg, Nikhil; Pierson, Emma (2024). \"Topics, Authors, and Institutions in Large Language Model Research: Trends from 17K arXiv Papers\". Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers): 1223–1243. doi:10.18653/v1/2024.naacl-long.67. Retrieved 2024-12-08.{{cite journal}}:  CS1 maint: url-status (link)\\n\\n^ \"Parameters in notable artificial intelligence systems\". ourworldindata.org. November 30, 2023. Retrieved January 20, 2024.\\n\\n^ \"LMSYS Chatbot Arena Leaderboard\". huggingface.co. Archived from the original on June 10, 2024. Retrieved June 12, 2024.\\n\\n^ Peng, Bo; et\\xa0al. (2023). \"RWKV: Reinventing RNNS for the Transformer Era\". arXiv:2305.13048 [cs.CL].\\n\\n^ Merritt, Rick (2022-03-25). \"What Is a Transformer Model?\". NVIDIA Blog. Archived from the original on 2023-11-17. Retrieved 2023-07-25.\\n\\n^ Gu, Albert; Dao, Tri (2023-12-01), Mamba: Linear-Time Sequence Modeling with Selective State Spaces, arXiv:2312.00752\\n\\n^ Kaushal, Ayush; Mahowald, Kyle (2022-06-06), What do tokens know about their characters and how do they know it?, arXiv:2206.02608\\n\\n^ Yennie Jun (2023-05-03). \"All languages are NOT created (tokenized) equal\". Language models cost much more in some languages than others. Archived from the original on 2023-08-17. Retrieved 2023-08-17. In other words, to express the same sentiment, some languages require up to 10 times more tokens.\\n\\n^ Petrov, Aleksandar; Malfa, Emanuele La; Torr, Philip; Bibi, Adel (June 23, 2023). \"Language Model Tokenizers Introduce Unfairness Between Languages\". NeurIPS. arXiv:2305.15425. Archived from the original on December 15, 2023. Retrieved September 16, 2023 – via openreview.net.\\n\\n^ \"OpenAI API\". platform.openai.com. Archived from the original on April 23, 2023. Retrieved 2023-04-30.\\n\\n^ a b Paaß, Gerhard; Giesselbach, Sven (2022). \"Pre-trained Language Models\". Foundation Models for Natural Language Processing. Artificial Intelligence: Foundations, Theory, and Algorithms. pp.\\xa019–78. doi:10.1007/978-3-031-23190-2_2. ISBN\\xa09783031231902. Archived from the original on 3 August 2023. Retrieved 3 August 2023.\\n\\n^ Petrov, Aleksandar; Emanuele La Malfa; Torr, Philip H. S.; Bibi, Adel (2023). \"Language Model Tokenizers Introduce Unfairness Between Languages\". arXiv:2305.15425 [cs.CL].\\n\\n^ Lundberg, Scott (2023-12-12). \"The Art of Prompt Design: Prompt Boundaries and Token Healing\". Medium. Retrieved 2024-08-05.\\n\\n^ Dodge, Jesse; Sap, Maarten; Marasović, Ana; Agnew, William; Ilharco, Gabriel; Groeneveld, Dirk; Mitchell, Margaret; Gardner, Matt (2021). \"Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus\". arXiv:2104.08758 [cs.CL].\\n\\n^ Lee, Katherine; Ippolito, Daphne; Nystrom, Andrew; Zhang, Chiyuan; Eck, Douglas; Callison-Burch, Chris; Carlini, Nicholas (May 2022). \"Deduplicating Training Data Makes Language Models Better\" (PDF). Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics. 1: Long Papers: 8424–8445. doi:10.18653/v1/2022.acl-long.577.\\n\\n^ Li, Yuanzhi; Bubeck, Sébastien; Eldan, Ronen; Del Giorno, Allie; Gunasekar, Suriya; Lee, Yin Tat (2023-09-11), Textbooks Are All You Need II: phi-1.5 technical report, arXiv:2309.05463\\n\\n^ Lin, Zhenghao; Gou, Zhibin; Gong, Yeyun; Liu, Xiao; Shen, Yelong; Xu, Ruochen; Lin, Chen; Yang, Yujiu; Jiao, Jian (2024-04-11). \"Rho-1: Not All Tokens Are What You Need\". arXiv:2404.07965 [cs.CL].\\n\\n^ Brown, Tom B.; et\\xa0al. (2020). \"Language Models are Few-Shot Learners\". arXiv:2005.14165 [cs.CL].\\n\\n^ Abdin, Marah; Jacobs, Sam Ade; Awan, Ammar Ahmad; Aneja, Jyoti; Awadallah, Ahmed; Awadalla, Hany; Bach, Nguyen; Bahree, Amit; Bakhtiari, Arash (2024-04-23). \"Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone\". arXiv:2404.14219 [cs.CL].\\n\\n^ Ouyang, Long; Wu, Jeff; Jiang, Xu; Almeida, Diogo; Wainwright, Carroll L.; Mishkin, Pamela; Zhang, Chong; Agarwal, Sandhini; Slama, Katarina; Ray, Alex; Schulman, John; Hilton, Jacob; Kelton, Fraser; Miller, Luke; Simens, Maddie; Askell, Amanda; Welinder, Peter; Christiano, Paul; Leike, Jan; Lowe, Ryan (2022). \"Training language models to follow instructions with human feedback\". arXiv:2203.02155 [cs.CL].\\n\\n^ Wang, Yizhong; Kordi, Yeganeh; Mishra, Swaroop; Liu, Alisa; Smith, Noah A.; Khashabi, Daniel; Hajishirzi, Hannaneh (2022). \"Self-Instruct: Aligning Language Model with Self Generated Instructions\". arXiv:2212.10560 [cs.CL].\\n\\n^ Shazeer, Noam; Mirhoseini, Azalia; Maziarz, Krzysztof; Davis, Andy; Le, Quoc; Hinton, Geoffrey; Dean, Jeff (2017-01-01). \"Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer\". arXiv:1701.06538 [cs.LG].\\n\\n^ Lepikhin, Dmitry; Lee, HyoukJoong; Xu, Yuanzhong; Chen, Dehao; Firat, Orhan; Huang, Yanping; Krikun, Maxim; Shazeer, Noam; Chen, Zhifeng (2021-01-12). \"GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding\". arXiv:2006.16668 [cs.CL].\\n\\n^ a b c d Dai, Andrew M; Du, Nan (December 9, 2021). \"More Efficient In-Context Learning with GLaM\". ai.googleblog.com. Archived from the original on 2023-03-12. Retrieved 2023-03-09.\\n\\n^ a b c Wei, Jason; Tay, Yi; Bommasani, Rishi; Raffel, Colin; Zoph, Barret; Borgeaud, Sebastian; Yogatama, Dani; Bosma, Maarten; Zhou, Denny; Metzler, Donald; Chi, Ed H.; Hashimoto, Tatsunori; Vinyals, Oriol; Liang, Percy; Dean, Jeff; Fedus, William (31 August 2022). \"Emergent Abilities of Large Language Models\". Transactions on Machine Learning Research. ISSN\\xa02835-8856. Archived from the original on 22 March 2023. Retrieved 19 March 2023.\\n\\n^ Allamar, Jay. \"Illustrated transformer\". Archived from the original on 2023-07-25. Retrieved 2023-07-29.\\n\\n^ Allamar, Jay. \"The Illustrated GPT-2 (Visualizing Transformer Language Models)\". Retrieved 2023-08-01.\\n\\n^ \"Our next-generation model: Gemini 1.5\". Google. 15 February 2024. Archived from the original on 18 February 2024. Retrieved 18 February 2024.\\n\\n^ \"Long context prompting for Claude 2.1\". December 6, 2023. Archived from the original on August 27, 2024. Retrieved January 20, 2024.\\n\\n^ \"Rate limits\". openai.com. Archived from the original on February 2, 2024. Retrieved January 20, 2024.\\n\\n^ Zaib, Munazza; Sheng, Quan Z.; Emma Zhang, Wei (4 February 2020). \"A Short Survey of Pre-trained Language Models for Conversational AI-A New Age in NLP\". Proceedings of the Australasian Computer Science Week Multiconference. pp.\\xa01–4. arXiv:2104.10810. doi:10.1145/3373017.3373028. ISBN\\xa09781450376976. S2CID\\xa0211040895.\\n\\n^ a b c Jurafsky, Dan; Martin, James H. (7 January 2023). Speech and Language Processing (PDF) (3rd edition draft\\xa0ed.). Archived (PDF) from the original on 23 March 2023. Retrieved 24 May 2022.\\n\\n^ \"From bare metal to a 70B model: infrastructure set-up and scripts\". imbue.com. Archived from the original on 2024-07-26. Retrieved 2024-07-24.\\n\\n^ \"metaseq/projects/OPT/chronicles at main · facebookresearch/metaseq\". GitHub. Archived from the original on 2024-01-24. Retrieved 2024-07-24.\\n\\n^ Albrecht, Josh (2024-07-23). \"State of the Art: Training >70B LLMs on 10,000 H100 clusters\". www.latent.space. Retrieved 2024-07-24.\\n\\n^ a b Wiggers, Kyle (28 April 2022). \"The emerging types of language models and why they matter\". TechCrunch. Archived from the original on 16 March 2023. Retrieved 9 March 2023.\\n\\n^ Sharir, Or; Peleg, Barak; Shoham, Yoav (2020). \"The Cost of Training NLP Models: A Concise Overview\". arXiv:2004.08900 [cs.CL].\\n\\n^ Biderman, Stella; Schoelkopf, Hailey; Anthony, Quentin; Bradley, Herbie; Khan, Mohammad Aflah; Purohit, Shivanshu; Prashanth, USVSN Sai (April 2023). \"Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling\". arXiv:2304.01373 [cs.CL].\\n\\n^ Maslej, Nestor; Fattorini, Loredana; Brynjolfsson, Erik; Etchemendy, John; Ligett, Katrina; Lyons, Terah; Manyika, James; Ngo, Helen; Niebles, Juan Carlos (2023-10-05), Artificial Intelligence Index Report 2023, arXiv:2310.03715\\n\\n^ a b Section 2.1 and Table 1,\\n\\nKaplan, Jared; McCandlish, Sam; Henighan, Tom; Brown, Tom B.; Chess, Benjamin; Child, Rewon; Gray, Scott; Radford, Alec; Wu, Jeffrey; Amodei, Dario (2020). \"Scaling Laws for Neural Language Models\". arXiv:2001.08361 [cs.LG].\\n\\n^ Gao, Luyu; Madaan, Aman; Zhou, Shuyan; Alon, Uri; Liu, Pengfei; Yang, Yiming; Callan, Jamie; Neubig, Graham (2022-11-01). \"PAL: Program-aided Language Models\". arXiv:2211.10435 [cs.CL].\\n\\n^ \"PAL: Program-aided Language Models\". reasonwithpal.com. Archived from the original on 2023-06-12. Retrieved 2023-06-12.\\n\\n^ Paranjape, Bhargavi; Lundberg, Scott; Singh, Sameer; Hajishirzi, Hannaneh; Zettlemoyer, Luke; Tulio Ribeiro, Marco (2023-03-01). \"ART: Automatic multi-step reasoning and tool-use for large language models\". arXiv:2303.09014 [cs.CL].\\n\\n^ Liang, Yaobo; Wu, Chenfei; Song, Ting; Wu, Wenshan; Xia, Yan; Liu, Yu; Ou, Yang; Lu, Shuai; Ji, Lei; Mao, Shaoguang; Wang, Yun; Shou, Linjun; Gong, Ming; Duan, Nan (2023-03-01). \"TaskMatrix.AI: Completing Tasks by Connecting Foundation Models with Millions of APIs\". arXiv:2303.16434 [cs.AI].\\n\\n^ Patil, Shishir G.; Zhang, Tianjun; Wang, Xin; Gonzalez, Joseph E. (2023-05-01). \"Gorilla: Large Language Model Connected with Massive APIs\". arXiv:2305.15334 [cs.CL].\\n\\n^ Lewis, Patrick; Perez, Ethan; Piktus, Aleksandra; Petroni, Fabio; Karpukhin, Vladimir; Goyal, Naman; Küttler, Heinrich; Lewis, Mike; Yih, Wen-tau; Rocktäschel, Tim; Riedel, Sebastian; Kiela, Douwe (2020). \"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\". Advances in Neural Information Processing Systems. 33. Curran Associates, Inc.: 9459–9474. arXiv:2005.11401. Archived from the original on 2023-06-12. Retrieved 2023-06-12.\\n\\n^ \"The Growth Behind LLM-based Autonomous Agents\". KDnuggets. October 23, 2023.\\n\\n^ Yao, Shunyu; Zhao, Jeffrey; Yu, Dian; Du, Nan; Shafran, Izhak; Narasimhan, Karthik; Cao, Yuan (2022-10-01). \"ReAct: Synergizing Reasoning and Acting in Language Models\". arXiv:2210.03629 [cs.CL].\\n\\n^ Wu, Yue; Prabhumoye, Shrimai; Min, So Yeon (24 May 2023). \"SPRING: GPT-4 Out-performs RL Algorithms by Studying Papers and Reasoning\". arXiv:2305.15486 [cs.AI].\\n\\n^ Wang, Zihao; Cai, Shaofei; Liu, Anji; Ma, Xiaojian; Liang, Yitao (2023-02-03). \"Describe, Explain, Plan and Select: Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents\". arXiv:2302.01560 [cs.AI].\\n\\n^ Shinn, Noah; Cassano, Federico; Labash, Beck; Gopinath, Ashwin; Narasimhan, Karthik; Yao, Shunyu (2023-03-01). \"Reflexion: Language Agents with Verbal Reinforcement Learning\". arXiv:2303.11366 [cs.AI].\\n\\n^ Hao, Shibo; Gu, Yi; Ma, Haodi; Jiahua Hong, Joshua; Wang, Zhen; Zhe Wang, Daisy; Hu, Zhiting (2023-05-01). \"Reasoning with Language Model is Planning with World Model\". arXiv:2305.14992 [cs.CL].\\n\\n^ Zhang, Jenny; Lehman, Joel; Stanley, Kenneth; Clune, Jeff (2 June 2023). \"OMNI: Open-endedness via Models of human Notions of Interestingness\". arXiv:2306.01711 [cs.AI].\\n\\n^ a b \"Voyager | An Open-Ended Embodied Agent with Large Language Models\". voyager.minedojo.org. Archived from the original on 2023-06-08. Retrieved 2023-06-09.\\n\\n^ Park, Joon Sung; O\\'Brien, Joseph C.; Cai, Carrie J.; Ringel Morris, Meredith; Liang, Percy; Bernstein, Michael S. (2023-04-01). \"Generative Agents: Interactive Simulacra of Human Behavior\". arXiv:2304.03442 [cs.HC].\\n\\n^ Mann, Tobias. \"How to run an LLM locally on your PC in less than 10 minutes\". www.theregister.com. Retrieved 2024-05-17.\\n\\n^ Nagel, Markus; Amjad, Rana Ali; Baalen, Mart Van; Louizos, Christos; Blankevoort, Tijmen (2020-11-21). \"Up or Down? Adaptive Rounding for Post-Training Quantization\". Proceedings of the 37th International Conference on Machine Learning. PMLR: 7197–7206. Archived from the original on 2023-06-14. Retrieved 2023-06-14.\\n\\n^ Polino, Antonio; Pascanu, Razvan; Alistarh, Dan (2018-02-01). \"Model compression via distillation and quantization\". arXiv:1802.05668 [cs.NE].\\n\\n^ Frantar, Elias; Ashkboos, Saleh; Hoefler, Torsten; Alistarh, Dan (2022-10-01). \"GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers\". arXiv:2210.17323 [cs.LG].\\n\\n^ Dettmers, Tim; Svirschevski, Ruslan; Egiazarian, Vage; Kuznedelev, Denis; Frantar, Elias; Ashkboos, Saleh; Borzunov, Alexander; Hoefler, Torsten; Alistarh, Dan (2023-06-01). \"SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight Compression\". arXiv:2306.03078 [cs.CL].\\n\\n^ Grootendorst, Maarten. \"A Visual Guide to Quantization\". newsletter.maartengrootendorst.com. Archived from the original on 31 Jul 2024. Retrieved 2024-07-31.\\n\\n^ Dettmers, Tim; Pagnoni, Artidoro; Holtzman, Ari; Zettlemoyer, Luke (2023-05-01). \"QLoRA: Efficient Finetuning of Quantized LLMs\". arXiv:2305.14314 [cs.LG].\\n\\n^ Kiros, Ryan; Salakhutdinov, Ruslan; Zemel, Rich (2014-06-18). \"Multimodal Neural Language Models\". Proceedings of the 31st International Conference on Machine Learning. PMLR: 595–603. Archived from the original on 2023-07-02. Retrieved 2023-07-02.\\n\\n^ Krizhevsky, Alex; Sutskever, Ilya; Hinton, Geoffrey E (2012). \"ImageNet Classification with Deep Convolutional Neural Networks\". Advances in Neural Information Processing Systems. 25. Curran Associates, Inc. Archived from the original on 2023-07-02. Retrieved 2023-07-02.\\n\\n^ Antol, Stanislaw; Agrawal, Aishwarya; Lu, Jiasen; Mitchell, Margaret; Batra, Dhruv; Zitnick, C. Lawrence; Parikh, Devi (2015). \"VQA: Visual Question Answering\". ICCV: 2425–2433. Archived from the original on 2023-07-02. Retrieved 2023-07-02.\\n\\n^ Li, Junnan; Li, Dongxu; Savarese, Silvio; Hoi, Steven (2023-01-01). \"BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models\". arXiv:2301.12597 [cs.CV].\\n\\n^ Alayrac, Jean-Baptiste; Donahue, Jeff; Luc, Pauline; Miech, Antoine; Barr, Iain; Hasson, Yana; Lenc, Karel; Mensch, Arthur; Millican, Katherine; Reynolds, Malcolm; Ring, Roman; Rutherford, Eliza; Cabi, Serkan; Han, Tengda; Gong, Zhitao (2022-12-06). \"Flamingo: a Visual Language Model for Few-Shot Learning\". Advances in Neural Information Processing Systems. 35: 23716–23736. arXiv:2204.14198. Archived from the original on 2023-07-02. Retrieved 2023-07-02.\\n\\n^ Driess, Danny; Xia, Fei; Sajjadi, Mehdi S. M.; Lynch, Corey; Chowdhery, Aakanksha; Ichter, Brian; Wahid, Ayzaan; Tompson, Jonathan; Vuong, Quan; Yu, Tianhe; Huang, Wenlong; Chebotar, Yevgen; Sermanet, Pierre; Duckworth, Daniel; Levine, Sergey (2023-03-01). \"PaLM-E: An Embodied Multimodal Language Model\". arXiv:2303.03378 [cs.LG].\\n\\n^ Liu, Haotian; Li, Chunyuan; Wu, Qingyang; Lee, Yong Jae (2023-04-01). \"Visual Instruction Tuning\". arXiv:2304.08485 [cs.CV].\\n\\n^ Zhang, Hang; Li, Xin; Bing, Lidong (2023-06-01). \"Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding\". arXiv:2306.02858 [cs.CL].\\n\\n^ OpenAI (2023-03-27). \"GPT-4 Technical Report\". arXiv:2303.08774 [cs.CL].\\n\\n^ OpenAI (September 25, 2023). \"GPT-4V(ision) System Card\" (PDF).\\n\\n^ Pichai, Sundar (10 May 2023), Google Keynote (Google I/O \\'23), timestamp 15:31, retrieved 2023-07-02\\n\\n^ Wiggers, Kyle (11 September 2024). \"Mistral releases Pixtral 12B, its first multimodal model\". TechCrunch. Retrieved 14 September 2024.\\n\\n^ Hoffmann, Jordan; Borgeaud, Sebastian; Mensch, Arthur; Buchatskaya, Elena; Cai, Trevor; Rutherford, Eliza; Casas, Diego de Las; Hendricks, Lisa Anne; Welbl, Johannes; Clark, Aidan; Hennigan, Tom; Noland, Eric; Millican, Katie; Driessche, George van den; Damoc, Bogdan (2022-03-29). \"Training Compute-Optimal Large Language Models\". arXiv:2203.15556 [cs.CL].\\n\\n^ a b Caballero, Ethan; Gupta, Kshitij; Rish, Irina; Krueger, David (2022). \"Broken Neural Scaling Laws\". arXiv:2210.14891 [cs.LG].\\n\\n^ \"137 emergent abilities of large language models\". Jason Wei. Retrieved 2023-06-24.\\n\\n^ Bowman, Samuel R. (2023). \"Eight Things to Know about Large Language Models\". arXiv:2304.00612 [cs.CL].\\n\\n^ Mukherjee, Anirban; Chang, Hannah (2024). \"Heuristic Reasoning in AI: Instrumental Use and Mimetic Absorption\". arXiv:2403.09404 [cs.AI].\\n\\n^ Hahn, Michael; Goyal, Navin (2023-03-14). \"A Theory of Emergent In-Context Learning as Implicit Structure Induction\". arXiv:2303.07971 [cs.LG].\\n\\n^ Pilehvar, Mohammad Taher; Camacho-Collados, Jose (June 2019). \"Proceedings of the 2019 Conference of the North\". Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). Minneapolis, Minnesota: Association for Computational Linguistics: 1267–1273. doi:10.18653/v1/N19-1128. S2CID\\xa0102353817. Archived from the original on 2023-06-27. Retrieved 2023-06-27.\\n\\n^ \"WiC: The Word-in-Context Dataset\". pilehvar.github.io. Archived from the original on 2023-06-27. Retrieved 2023-06-27.\\n\\n^ Patel, Roma; Pavlick, Ellie (2021-10-06). \"Mapping Language Models to Grounded Conceptual Spaces\". ICLR. Archived from the original on 2023-06-24. Retrieved 2023-06-27.\\n\\n^ A Closer Look at Large Language Models Emergent Abilities Archived 2023-06-24 at the Wayback Machine (Yao Fu, Nov 20, 2022)\\n\\n^ Ornes, Stephen (March 16, 2023). \"The Unpredictable Abilities Emerging From Large AI Models\". Quanta Magazine. Archived from the original on March 16, 2023. Retrieved March 16, 2023.\\n\\n^ Schaeffer, Rylan; Miranda, Brando; Koyejo, Sanmi (2023-04-01). \"Are Emergent Abilities of Large Language Models a Mirage?\". arXiv:2304.15004 [cs.AI].\\n\\n^ Li, Kenneth; Hopkins, Aspen K.; Bau, David; Viégas, Fernanda; Pfister, Hanspeter; Wattenberg, Martin (2022-10-01). \"Emergent World Representations: Exploring a Sequence Model Trained on a Synthetic Task\". arXiv:2210.13382 [cs.LG].\\n\\n^ \"Large Language Model: world models or surface statistics?\". The Gradient. 2023-01-21. Retrieved 2023-06-12.\\n\\n^ Jin, Charles; Rinard, Martin (2023-05-01). \"Evidence of Meaning in Language Models Trained on Programs\". arXiv:2305.11169 [cs.LG].\\n\\n^ Nanda, Neel; Chan, Lawrence; Lieberum, Tom; Smith, Jess; Steinhardt, Jacob (2023-01-01). \"Progress measures for grokking via mechanistic interpretability\". arXiv:2301.05217 [cs.LG].\\n\\n^ a b c d e Mitchell, Melanie; Krakauer, David C. (28 March 2023). \"The debate over understanding in AI\\'s large language models\". Proceedings of the National Academy of Sciences. 120 (13): e2215907120. arXiv:2210.13966. Bibcode:2023PNAS..12015907M. doi:10.1073/pnas.2215907120. PMC\\xa010068812. PMID\\xa036943882.\\n\\n^ Metz, Cade (16 May 2023). \"Microsoft Says New A.I. Shows Signs of Human Reasoning\". The New York Times.\\n\\n^ a b Bubeck, Sébastien; Chandrasekaran, Varun; Eldan, Ronen; Gehrke, Johannes; Horvitz, Eric; Kamar, Ece; Lee, Peter; Lee, Yin Tat; Li, Yuanzhi; Lundberg, Scott; Nori, Harsha; Palangi, Hamid; Ribeiro, Marco Tulio; Zhang, Yi (2023). \"Sparks of Artificial General Intelligence: Early experiments with GPT-4\". arXiv:2303.12712 [cs.CL].\\n\\n^ \"Anthropic CEO Dario Amodei pens a smart look at our AI future\". Fast Company. October 17, 2024.\\n\\n^ \"ChatGPT is more like an \\'alien intelligence\\' than a human brain, says futurist\". ZDNET. 2023. Archived from the original on 12 June 2023. Retrieved 12 June 2023.\\n\\n^ a b Newport, Cal (13 April 2023). \"What Kind of Mind Does ChatGPT Have?\". The New Yorker. Archived from the original on 12 June 2023. Retrieved 12 June 2023.\\n\\n^ Roose, Kevin (30 May 2023). \"Why an Octopus-like Creature Has Come to Symbolize the State of A.I.\" The New York Times. Archived from the original on 30 May 2023. Retrieved 12 June 2023.\\n\\n^ \"The A to Z of Artificial Intelligence\". Time Magazine. 13 April 2023. Archived from the original on 16 June 2023. Retrieved 12 June 2023.\\n\\n^ Ji, Ziwei; Lee, Nayeon; Frieske, Rita; Yu, Tiezheng; Su, Dan; Xu, Yan; Ishii, Etsuko; Bang, Yejin; Dai, Wenliang; Madotto, Andrea; Fung, Pascale (November 2022). \"Survey of Hallucination in Natural Language Generation\" (pdf). ACM Computing Surveys. 55 (12). Association for Computing Machinery: 1–38. arXiv:2202.03629. doi:10.1145/3571730. S2CID\\xa0246652372. Archived from the original on 26 March 2023. Retrieved 15 January 2023.\\n\\n^ Varshney, Neeraj; Yao, Wenlin; Zhang, Hongming; Chen, Jianshu; Yu, Dong (2023). \"A Stitch in Time Saves Nine: Detecting and Mitigating Hallucinations of LLMs by Validating Low-Confidence Generation\". arXiv:2307.03987 [cs.CL].\\n\\n^ Lakoff, George (1999). Philosophy in the Flesh: The Embodied Mind and Its Challenge to Western Philosophy; Appendix: The Neural Theory of Language Paradigm. New York Basic Books. pp.\\xa0569–583. ISBN\\xa0978-0-465-05674-3.\\n\\n^ Evans, Vyvyan. (2014). The Language Myth. Cambridge University Press. ISBN\\xa0978-1-107-04396-1.\\n\\n^ Friston, Karl J. (2022). Active Inference: The Free Energy Principle in Mind, Brain, and Behavior; Chapter 4 The Generative Models of Active Inference. The MIT Press. ISBN\\xa0978-0-262-36997-8.\\n\\n^ a b Huyen, Chip (October 18, 2019). \"Evaluation Metrics for Language Modeling\". The Gradient. Retrieved January 14, 2024.\\n\\n^ a b Clark, Christopher; Lee, Kenton; Chang, Ming-Wei; Kwiatkowski, Tom; Collins, Michael; Toutanova, Kristina (2019). \"BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions\". arXiv:1905.10044 [cs.CL].\\n\\n^ a b c Wayne Xin Zhao; Zhou, Kun; Li, Junyi; Tang, Tianyi; Wang, Xiaolei; Hou, Yupeng; Min, Yingqian; Zhang, Beichen; Zhang, Junjie; Dong, Zican; Du, Yifan; Yang, Chen; Chen, Yushuo; Chen, Zhipeng; Jiang, Jinhao; Ren, Ruiyang; Li, Yifan; Tang, Xinyu; Liu, Zikang; Liu, Peiyu; Nie, Jian-Yun; Wen, Ji-Rong (2023). \"A Survey of Large Language Models\". arXiv:2303.18223 [cs.CL].\\n\\n^ openai/simple-evals, OpenAI, 2024-05-28, retrieved 2024-05-28\\n\\n^ openai/evals, OpenAI, 2024-05-28, archived from the original on 2024-05-08, retrieved 2024-05-28\\n\\n^ \"Sanitized open-source datasets for natural language and code understanding: how we evaluated our 70B model\". imbue.com. Archived from the original on 2024-07-26. Retrieved 2024-07-24.\\n\\n^ Srivastava, Aarohi; et\\xa0al. (2022). \"Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models\". arXiv:2206.04615 [cs.CL].\\n\\n^ Lin, Stephanie; Hilton, Jacob; Evans, Owain (2021). \"TruthfulQA: Measuring How Models Mimic Human Falsehoods\". arXiv:2109.07958 [cs.CL].\\n\\n^ a b Zellers, Rowan; Holtzman, Ari; Bisk, Yonatan; Farhadi, Ali; Choi, Yejin (2019). \"HellaSwag: Can a Machine Really Finish Your Sentence?\". arXiv:1905.07830 [cs.CL].\\n\\n^ \"Prepare for truly useful large language models\". Nature Biomedical Engineering. 7 (2): 85–86. 7 March 2023. doi:10.1038/s41551-023-01012-6. PMID\\xa036882584. S2CID\\xa0257403466.\\n\\n^ \"Your job is (probably) safe from artificial intelligence\". The Economist. 7 May 2023. Archived from the original on 17 June 2023. Retrieved 18 June 2023.\\n\\n^ \"Generative AI Could Raise Global GDP by 7%\". Goldman Sachs. Archived from the original on 18 June 2023. Retrieved 18 June 2023.\\n\\n^ Peng, Zhencan; Wang, Zhizhi; Deng, Dong (13 June 2023). \"Near-Duplicate Sequence Search at Scale for Large Language Model Memorization Evaluation\" (PDF). Proceedings of the ACM on Management of Data. 1 (2): 1–18. doi:10.1145/3589324. S2CID\\xa0259213212. Archived (PDF) from the original on 2024-08-27. Retrieved 2024-01-20. Citing Lee et al 2022.\\n\\n^ Peng, Wang & Deng 2023, p.\\xa08.\\n\\n^ Alba, Davey (1 May 2023). \"AI chatbots have been used to create dozens of news content farms\". The Japan Times. Retrieved 18 June 2023.\\n\\n^ \"Could chatbots help devise the next pandemic virus?\". Science. 14 June 2023. doi:10.1126/science.adj2463. Archived from the original on 18 June 2023. Retrieved 18 June 2023.\\n\\n^ Stephen Council (1 Dec 2023). \"How Googlers cracked an SF rival\\'s tech model with a single word\". SFGATE. Archived from the original on 16 December 2023.\\n\\n^ Hubinger, Evan (10 January 2024). \"Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training\". arXiv:2401.05566 [cs.CR].\\n\\n^ Kang, Daniel (2023). \"Exploiting programmatic behavior of LLMs: Dual-use through standard security attacks\". arXiv:2302.05733 [cs.CR].\\n\\n^ Wang, Yongge (20 June 2024). \"Encryption Based Covert Channel for Large Language Models\" (PDF). IACR ePrint 2024/586. Archived (PDF) from the original on 24 June 2024. Retrieved 24 June 2024.\\n\\n^ a b Stokel-Walker, Chris (November 22, 2023). \"ChatGPT Replicates Gender Bias in Recommendation Letters\". Scientific American. Archived from the original on 2023-12-29. Retrieved 2023-12-29.\\n\\n^ Luo, Queenie; Puett, Michael J.; Smith, Michael D. (2023-03-28). \"A Perspectival Mirror of the Elephant: Investigating Language Bias on Google, ChatGPT, Wikipedia, and YouTube\". arXiv:2303.16281v2 [cs.CY].\\n\\n^ Cheng, Myra; Durmus, Esin; Jurafsky, Dan (2023-05-29), Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models, arXiv:2305.18189\\n\\n^ Kotek, Hadas; Dockum, Rikker; Sun, David (2023-11-05). \"Gender bias and stereotypes in Large Language Models\". Proceedings of the ACM Collective Intelligence Conference. CI \\'23. New York, NY, USA: Association for Computing Machinery. pp.\\xa012–24. doi:10.1145/3582269.3615599. ISBN\\xa0979-8-4007-0113-9.\\n\\n^ Heikkilä, Melissa (August 7, 2023). \"AI language models are rife with different political biases\". MIT Technology Review. Retrieved 2023-12-29.\\n\\n^ \"Improving language understanding with unsupervised learning\". openai.com. June 11, 2018. Archived from the original on 2023-03-18. Retrieved 2023-03-18.\\n\\n^ \"finetune-transformer-lm\". GitHub. Archived from the original on 19 May 2023. Retrieved 2 January 2024.\\n\\n^ a b Devlin, Jacob; Chang, Ming-Wei; Lee, Kenton; Toutanova, Kristina (11 October 2018). \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\". arXiv:1810.04805v2 [cs.CL].\\n\\n^ Prickett, Nicole Hemsoth (2021-08-24). \"Cerebras Shifts Architecture To Meet Massive AI/ML Models\". The Next Platform. Archived from the original on 2023-06-20. Retrieved 2023-06-20.\\n\\n^ \"BERT\". March 13, 2023. Archived from the original on January 13, 2021. Retrieved March 13, 2023 – via GitHub.\\n\\n^ Patel, Ajay; Li, Bryan; Rasooli, Mohammad Sadegh; Constant, Noah; Raffel, Colin; Callison-Burch, Chris (2022). \"Bidirectional Language Models Are Also Few-shot Learners\". arXiv:2209.14500 [cs.LG].\\n\\n^ Devlin, Jacob; Chang, Ming-Wei; Lee, Kenton; Toutanova, Kristina (11 October 2018). \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\". arXiv:1810.04805v2 [cs.CL].\\n\\n^ a b Raffel, Colin; Shazeer, Noam; Roberts, Adam; Lee, Katherine; Narang, Sharan; Matena, Michael; Zhou, Yanqi; Li, Wei; Liu, Peter J. (2020). \"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer\". Journal of Machine Learning Research. 21 (140): 1–67. arXiv:1910.10683. ISSN\\xa01533-7928.\\n\\n^ google-research/text-to-text-transfer-transformer, Google Research, 2024-04-02, archived from the original on 2024-03-29, retrieved 2024-04-04\\n\\n^ \"Imagen: Text-to-Image Diffusion Models\". imagen.research.google. Archived from the original on 2024-03-27. Retrieved 2024-04-04.\\n\\n^ \"Pretrained models — transformers 2.0.0 documentation\". huggingface.co. Archived from the original on 2024-08-05. Retrieved 2024-08-05.\\n\\n^ \"xlnet\". GitHub. Archived from the original on 2 January 2024. Retrieved 2 January 2024.\\n\\n^ Yang, Zhilin; Dai, Zihang; Yang, Yiming; Carbonell, Jaime; Salakhutdinov, Ruslan; Le, Quoc V. (2 January 2020). \"XLNet: Generalized Autoregressive Pretraining for Language Understanding\". arXiv:1906.08237 [cs.CL].\\n\\n^ \"GPT-2: 1.5B Release\". OpenAI. 2019-11-05. Archived from the original on 2019-11-14. Retrieved 2019-11-14.\\n\\n^ \"Better language models and their implications\". openai.com. Archived from the original on 2023-03-16. Retrieved 2023-03-13.\\n\\n^ a b \"OpenAI\\'s GPT-3 Language Model: A Technical Overview\". lambdalabs.com. 3 June 2020. Archived from the original on 27 March 2023. Retrieved 13 March 2023.\\n\\n^ a b \"openai-community/gpt2-xl · Hugging Face\". huggingface.co. Archived from the original on 2024-07-24. Retrieved 2024-07-24.\\n\\n^ \"gpt-2\". GitHub. Archived from the original on 11 March 2023. Retrieved 13 March 2023.\\n\\n^ Table D.1 in Brown, Tom B.; Mann, Benjamin; Ryder, Nick; Subbiah, Melanie; Kaplan, Jared; Dhariwal, Prafulla; Neelakantan, Arvind; Shyam, Pranav; Sastry, Girish; Askell, Amanda; Agarwal, Sandhini; Herbert-Voss, Ariel; Krueger, Gretchen; Henighan, Tom; Child, Rewon; Ramesh, Aditya; Ziegler, Daniel M.; Wu, Jeffrey; Winter, Clemens; Hesse, Christopher; Chen, Mark; Sigler, Eric; Litwin, Mateusz; Gray, Scott; Chess, Benjamin; Clark, Jack; Berner, Christopher; McCandlish, Sam; Radford, Alec; Sutskever, Ilya; Amodei, Dario (May 28, 2020). \"Language Models are Few-Shot Learners\". arXiv:2005.14165v4 [cs.CL].\\n\\n^ \"ChatGPT: Optimizing Language Models for Dialogue\". OpenAI. 2022-11-30. Archived from the original on 2022-11-30. Retrieved 2023-01-13.\\n\\n^ \"GPT Neo\". March 15, 2023. Archived from the original on March 12, 2023. Retrieved March 12, 2023 – via GitHub.\\n\\n^ a b c Gao, Leo; Biderman, Stella; Black, Sid; Golding, Laurence; Hoppe, Travis; Foster, Charles; Phang, Jason; He, Horace; Thite, Anish; Nabeshima, Noa; Presser, Shawn; Leahy, Connor (31 December 2020). \"The Pile: An 800GB Dataset of Diverse Text for Language Modeling\". arXiv:2101.00027 [cs.CL].\\n\\n^ a b Iyer, Abhishek (15 May 2021). \"GPT-3\\'s free alternative GPT-Neo is something to be excited about\". VentureBeat. Archived from the original on 9 March 2023. Retrieved 13 March 2023.\\n\\n^ \"GPT-J-6B: An Introduction to the Largest Open Source GPT Model | Forefront\". www.forefront.ai. Archived from the original on 2023-03-09. Retrieved 2023-02-28.\\n\\n^ a b c d Dey, Nolan; Gosal, Gurpreet; Zhiming; Chen; Khachane, Hemant; Marshall, William; Pathria, Ribhu; Tom, Marvin; Hestness, Joel (2023-04-01). \"Cerebras-GPT: Open Compute-Optimal Language Models Trained on the Cerebras Wafer-Scale Cluster\". arXiv:2304.03208 [cs.LG].\\n\\n^ Alvi, Ali; Kharya, Paresh (11 October 2021). \"Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, the World\\'s Largest and Most Powerful Generative Language Model\". Microsoft Research. Archived from the original on 13 March 2023. Retrieved 13 March 2023.\\n\\n^ a b Smith, Shaden; Patwary, Mostofa; Norick, Brandon; LeGresley, Patrick; Rajbhandari, Samyam; Casper, Jared; Liu, Zhun; Prabhumoye, Shrimai; Zerveas, George; Korthikanti, Vijay; Zhang, Elton; Child, Rewon; Aminabadi, Reza Yazdani; Bernauer, Julie; Song, Xia (2022-02-04). \"Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model\". arXiv:2201.11990 [cs.CL].\\n\\n^ a b Rajbhandari, Samyam; Li, Conglong; Yao, Zhewei; Zhang, Minjia; Aminabadi, Reza Yazdani; Awan, Ammar Ahmad; Rasley, Jeff; He, Yuxiong (2022-07-21), DeepSpeed-MoE: Advancing Mixture-of-Experts Inference and Training to Power Next-Generation AI Scale, arXiv:2201.05596\\n\\n^ Wang, Shuohuan; Sun, Yu; Xiang, Yang; Wu, Zhihua; Ding, Siyu; Gong, Weibao; Feng, Shikun; Shang, Junyuan; Zhao, Yanbin; Pang, Chao; Liu, Jiaxiang; Chen, Xuyi; Lu, Yuxiang; Liu, Weixin; Wang, Xi; Bai, Yangfan; Chen, Qiuliang; Zhao, Li; Li, Shiyong; Sun, Peng; Yu, Dianhai; Ma, Yanjun; Tian, Hao; Wu, Hua; Wu, Tian; Zeng, Wei; Li, Ge; Gao, Wen; Wang, Haifeng (December 23, 2021). \"ERNIE 3.0 Titan: Exploring Larger-scale Knowledge Enhanced Pre-training for Language Understanding and Generation\". arXiv:2112.12731 [cs.CL].\\n\\n^ \"Product\". Anthropic. Archived from the original on 16 March 2023. Retrieved 14 March 2023.\\n\\n^ a b Askell, Amanda; Bai, Yuntao; Chen, Anna; et\\xa0al. (9 December 2021). \"A General Language Assistant as a Laboratory for Alignment\". arXiv:2112.00861 [cs.CL].\\n\\n^ Bai, Yuntao; Kadavath, Saurav; Kundu, Sandipan; et\\xa0al. (15 December 2022). \"Constitutional AI: Harmlessness from AI Feedback\". arXiv:2212.08073 [cs.CL].\\n\\n^ \"Language modelling at scale: Gopher, ethical considerations, and retrieval\". www.deepmind.com. 8 December 2021. Archived from the original on 20 March 2023. Retrieved 20 March 2023.\\n\\n^ a b c Hoffmann, Jordan; Borgeaud, Sebastian; Mensch, Arthur; et\\xa0al. (29 March 2022). \"Training Compute-Optimal Large Language Models\". arXiv:2203.15556 [cs.CL].\\n\\n^ a b c d Table 20 and page 66 of PaLM: Scaling Language Modeling with Pathways Archived 2023-06-10 at the Wayback Machine\\n\\n^ a b Cheng, Heng-Tze; Thoppilan, Romal (January 21, 2022). \"LaMDA: Towards Safe, Grounded, and High-Quality Dialog Models for Everything\". ai.googleblog.com. Archived from the original on 2022-03-25. Retrieved 2023-03-09.\\n\\n^ Thoppilan, Romal; De Freitas, Daniel; Hall, Jamie; Shazeer, Noam; Kulshreshtha, Apoorv; Cheng, Heng-Tze; Jin, Alicia; Bos, Taylor; Baker, Leslie; Du, Yu; Li, YaGuang; Lee, Hongrae; Zheng, Huaixiu Steven; Ghafouri, Amin; Menegali, Marcelo (2022-01-01). \"LaMDA: Language Models for Dialog Applications\". arXiv:2201.08239 [cs.CL].\\n\\n^ Black, Sidney; Biderman, Stella; Hallahan, Eric; et\\xa0al. (2022-05-01). GPT-NeoX-20B: An Open-Source Autoregressive Language Model. Proceedings of BigScience Episode #5 – Workshop on Challenges & Perspectives in Creating Large Language Models. Vol.\\xa0Proceedings of BigScience Episode #5 – Workshop on Challenges & Perspectives in Creating Large Language Models. pp.\\xa095–136. Archived from the original on 2022-12-10. Retrieved 2022-12-19.\\n\\n^ a b c Hoffmann, Jordan; Borgeaud, Sebastian; Mensch, Arthur; Sifre, Laurent (12 April 2022). \"An empirical analysis of compute-optimal large language model training\". Deepmind Blog. Archived from the original on 13 April 2022. Retrieved 9 March 2023.\\n\\n^ Narang, Sharan; Chowdhery, Aakanksha (April 4, 2022). \"Pathways Language Model (PaLM): Scaling to 540 Billion Parameters for Breakthrough Performance\". ai.googleblog.com. Archived from the original on 2022-04-04. Retrieved 2023-03-09.\\n\\n^ Susan Zhang; Mona Diab; Luke Zettlemoyer. \"Democratizing access to large-scale language models with OPT-175B\". ai.facebook.com. Archived from the original on 2023-03-12. Retrieved 2023-03-12.\\n\\n^ Zhang, Susan; Roller, Stephen; Goyal, Naman; Artetxe, Mikel; Chen, Moya; Chen, Shuohui; Dewan, Christopher; Diab, Mona; Li, Xian; Lin, Xi Victoria; Mihaylov, Todor; Ott, Myle; Shleifer, Sam; Shuster, Kurt; Simig, Daniel; Koura, Punit Singh; Sridhar, Anjali; Wang, Tianlu; Zettlemoyer, Luke (21 June 2022). \"OPT: Open Pre-trained Transformer Language Models\". arXiv:2205.01068 [cs.CL].\\n\\n^ \"metaseq/projects/OPT/chronicles at main · facebookresearch/metaseq\". GitHub. Retrieved 2024-10-18.\\n\\n^ a b Khrushchev, Mikhail; Vasilev, Ruslan; Petrov, Alexey; Zinov, Nikolay (2022-06-22), YaLM 100B, archived from the original on 2023-06-16, retrieved 2023-03-18\\n\\n^ a b Lewkowycz, Aitor; Andreassen, Anders; Dohan, David; Dyer, Ethan; Michalewski, Henryk; Ramasesh, Vinay; Slone, Ambrose; Anil, Cem; Schlag, Imanol; Gutman-Solo, Theo; Wu, Yuhuai; Neyshabur, Behnam; Gur-Ari, Guy; Misra, Vedant (30 June 2022). \"Solving Quantitative Reasoning Problems with Language Models\". arXiv:2206.14858 [cs.CL].\\n\\n^ \"Minerva: Solving Quantitative Reasoning Problems with Language Models\". ai.googleblog.com. 30 June 2022. Retrieved 20 March 2023.\\n\\n^ Ananthaswamy, Anil (8 March 2023). \"In AI, is bigger always better?\". Nature. 615 (7951): 202–205. Bibcode:2023Natur.615..202A. doi:10.1038/d41586-023-00641-w. PMID\\xa036890378. S2CID\\xa0257380916. Archived from the original on 16 March 2023. Retrieved 9 March 2023.\\n\\n^ \"bigscience/bloom · Hugging Face\". huggingface.co. Archived from the original on 2023-04-12. Retrieved 2023-03-13.\\n\\n^ Taylor, Ross; Kardas, Marcin; Cucurull, Guillem; Scialom, Thomas; Hartshorn, Anthony; Saravia, Elvis; Poulton, Andrew; Kerkez, Viktor; Stojnic, Robert (16 November 2022). \"Galactica: A Large Language Model for Science\". arXiv:2211.09085 [cs.CL].\\n\\n^ \"20B-parameter Alexa model sets new marks in few-shot learning\". Amazon Science. 2 August 2022. Archived from the original on 15 March 2023. Retrieved 12 March 2023.\\n\\n^ Soltan, Saleh; Ananthakrishnan, Shankar; FitzGerald, Jack; et\\xa0al. (3 August 2022). \"AlexaTM 20B: Few-Shot Learning Using a Large-Scale Multilingual Seq2Seq Model\". arXiv:2208.01448 [cs.CL].\\n\\n^ \"AlexaTM 20B is now available in Amazon SageMaker JumpStart | AWS Machine Learning Blog\". aws.amazon.com. 17 November 2022. Archived from the original on 13 March 2023. Retrieved 13 March 2023.\\n\\n^ a b c \"Introducing LLaMA: A foundational, 65-billion-parameter large language model\". Meta AI. 24 February 2023. Archived from the original on 3 March 2023. Retrieved 9 March 2023.\\n\\n^ a b c \"The Falcon has landed in the Hugging Face ecosystem\". huggingface.co. Archived from the original on 2023-06-20. Retrieved 2023-06-20.\\n\\n^ \"GPT-4 Technical Report\" (PDF). OpenAI. 2023. Archived (PDF) from the original on March 14, 2023. Retrieved March 14, 2023.\\n\\n^ Schreiner, Maximilian (2023-07-11). \"GPT-4 architecture, datasets, costs and more leaked\". THE DECODER. Archived from the original on 2023-07-12. Retrieved 2024-07-26.\\n\\n^ Dickson, Ben (22 May 2024). \"Meta introduces Chameleon, a state-of-the-art multimodal model\". VentureBeat.\\n\\n^ Dey, Nolan (March 28, 2023). \"Cerebras-GPT: A Family of Open, Compute-efficient, Large Language Models\". Cerebras. Archived from the original on March 28, 2023. Retrieved March 28, 2023.\\n\\n^ \"Abu Dhabi-based TII launches its own version of ChatGPT\". tii.ae. Archived from the original on 2023-04-03. Retrieved 2023-04-03.\\n\\n^ Penedo, Guilherme; Malartic, Quentin; Hesslow, Daniel; Cojocaru, Ruxandra; Cappelli, Alessandro; Alobeidli, Hamza; Pannier, Baptiste; Almazrouei, Ebtesam; Launay, Julien (2023-06-01). \"The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only\". arXiv:2306.01116 [cs.CL].\\n\\n^ \"tiiuae/falcon-40b · Hugging Face\". huggingface.co. 2023-06-09. Retrieved 2023-06-20.\\n\\n^ UAE\\'s Falcon 40B, World\\'s Top-Ranked AI Model from Technology Innovation Institute, is Now Royalty-Free Archived 2024-02-08 at the Wayback Machine, 31 May 2023\\n\\n^ Wu, Shijie; Irsoy, Ozan; Lu, Steven; Dabravolski, Vadim; Dredze, Mark; Gehrmann, Sebastian; Kambadur, Prabhanjan; Rosenberg, David; Mann, Gideon (March 30, 2023). \"BloombergGPT: A Large Language Model for Finance\". arXiv:2303.17564 [cs.LG].\\n\\n^ Ren, Xiaozhe; Zhou, Pingyi; Meng, Xinfan; Huang, Xinjing; Wang, Yadao; Wang, Weichao; Li, Pengfei; Zhang, Xiaoda; Podolskiy, Alexander; Arshinov, Grigory; Bout, Andrey; Piontkovskaya, Irina; Wei, Jiansheng; Jiang, Xin; Su, Teng; Liu, Qun; Yao, Jun (March 19, 2023). \"PanGu-Σ: Towards Trillion Parameter Language Model with Sparse Heterogeneous Computing\". arXiv:2303.10845 [cs.CL].\\n\\n^ Köpf, Andreas; Kilcher, Yannic; von Rütte, Dimitri; Anagnostidis, Sotiris; Tam, Zhi-Rui; Stevens, Keith; Barhoum, Abdullah; Duc, Nguyen Minh; Stanley, Oliver; Nagyfi, Richárd; ES, Shahul; Suri, Sameer; Glushkov, David; Dantuluri, Arnav; Maguire, Andrew (2023-04-14). \"OpenAssistant Conversations – Democratizing Large Language Model Alignment\". arXiv:2304.07327 [cs.CL].\\n\\n^ Wrobel, Sharon. \"Tel Aviv startup rolls out new advanced AI language model to rival OpenAI\". www.timesofisrael.com. Archived from the original on 2023-07-24. Retrieved 2023-07-24.\\n\\n^ Wiggers, Kyle (2023-04-13). \"With Bedrock, Amazon enters the generative AI race\". TechCrunch. Archived from the original on 2023-07-24. Retrieved 2023-07-24.\\n\\n^ a b Elias, Jennifer (16 May 2023). \"Google\\'s newest A.I. model uses nearly five times more text data for training than its predecessor\". CNBC. Archived from the original on 16 May 2023. Retrieved 18 May 2023.\\n\\n^ \"Introducing PaLM 2\". Google. May 10, 2023. Archived from the original on May 18, 2023. Retrieved May 18, 2023.\\n\\n^ a b \"Introducing Llama 2: The Next Generation of Our Open Source Large Language Model\". Meta AI. 2023. Archived from the original on 2024-01-05. Retrieved 2023-07-19.\\n\\n^ \"llama/MODEL_CARD.md at main · meta-llama/llama\". GitHub. Archived from the original on 2024-05-28. Retrieved 2024-05-28.\\n\\n^ \"Claude 2\". anthropic.com. Archived from the original on 15 December 2023. Retrieved 12 December 2023.\\n\\n^ Nirmal, Dinesh (2023-09-07). \"Building AI for business: IBM\\'s Granite foundation models\". IBM Blog. Archived from the original on 2024-07-22. Retrieved 2024-08-11.\\n\\n^ \"Announcing Mistral 7B\". Mistral. 2023. Archived from the original on 2024-01-06. Retrieved 2023-10-06.\\n\\n^ \"Introducing Claude 2.1\". anthropic.com. Archived from the original on 15 December 2023. Retrieved 12 December 2023.\\n\\n^ xai-org/grok-1, xai-org, 2024-03-19, archived from the original on 2024-05-28, retrieved 2024-03-19\\n\\n^ \"Grok-1 model card\". x.ai. Retrieved 12 December 2023.\\n\\n^ \"Gemini – Google DeepMind\". deepmind.google. Archived from the original on 8 December 2023. Retrieved 12 December 2023.\\n\\n^ Franzen, Carl (11 December 2023). \"Mistral shocks AI community as latest open source model eclipses GPT-3.5 performance\". VentureBeat. Archived from the original on 11 December 2023. Retrieved 12 December 2023.\\n\\n^ \"Mixtral of experts\". mistral.ai. 11 December 2023. Archived from the original on 13 February 2024. Retrieved 12 December 2023.\\n\\n^ AI, Mistral (2024-04-17). \"Cheaper, Better, Faster, Stronger\". mistral.ai. Archived from the original on 2024-05-05. Retrieved 2024-05-05.\\n\\n^ a b Hughes, Alyssa (12 December 2023). \"Phi-2: The surprising power of small language models\". Microsoft Research. Archived from the original on 12 December 2023. Retrieved 13 December 2023.\\n\\n^ \"Our next-generation model: Gemini 1.5\". Google. 15 February 2024. Archived from the original on 16 February 2024. Retrieved 16 February 2024. This means 1.5 Pro can process vast amounts of information in one go — including 1 hour of video, 11 hours of audio, codebases with over 30,000 lines of code or over 700,000 words. In our research, we\\'ve also successfully tested up to 10 million tokens.\\n\\n^ \"Gemma\" – via GitHub.\\n\\n^ \"Introducing the next generation of Claude\". www.anthropic.com. Archived from the original on 2024-03-04. Retrieved 2024-03-04.\\n\\n^ \"Fugaku-LLM/Fugaku-LLM-13B · Hugging Face\". huggingface.co. Archived from the original on 2024-05-17. Retrieved 2024-05-17.\\n\\n^ \"Phi-3\". azure.microsoft.com. 23 April 2024. Archived from the original on 2024-04-27. Retrieved 2024-04-28.\\n\\n^ \"Phi-3 Model Documentation\". huggingface.co. Archived from the original on 2024-05-13. Retrieved 2024-04-28.\\n\\n^ \"Qwen2\". GitHub. Archived from the original on 2024-06-17. Retrieved 2024-06-17.\\n\\n^ \"nvidia/Nemotron-4-340B-Base · Hugging Face\". huggingface.co. 2024-06-14. Archived from the original on 2024-06-15. Retrieved 2024-06-15.\\n\\n^ \"Nemotron-4 340B | Research\". research.nvidia.com. Archived from the original on 2024-06-15. Retrieved 2024-06-15.\\n\\n^ \"The Llama 3 Herd of Models\" (July 23, 2024) Llama Team, AI @ Meta\\n\\n^ \"llama-models/models/llama3_1/MODEL_CARD.md at main · meta-llama/llama-models\". GitHub. Archived from the original on 2024-07-23. Retrieved 2024-07-23.\\n\\n\\n\\n\\nFurther reading[edit]\\nJurafsky, Dan, Martin, James. H. Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition, 3rd Edition draft, 2023.\\nZhao, Wayne Xin; et\\xa0al. (2023). \"A Survey of Large Language Models\". arXiv:2303.18223 [cs.CL].\\nKaddour, Jean; et\\xa0al. (2023). \"Challenges and Applications of Large Language Models\". arXiv:2307.10169 [cs.CL].\\nYin, Shukang; Fu, Chaoyou; Zhao, Sirui; Li, Ke; Sun, Xing; Xu, Tong; Chen, Enhong (2023-06-01). \"A Survey on Multimodal Large Language Models\". arXiv:2306.13549 [cs.CV].\\n\"AI Index Report 2024 – Artificial Intelligence Index\". aiindex.stanford.edu. Retrieved 2024-05-05.\\nFrank, Michael C. (27 June 2023). \"Baby steps in evaluating the capacities of large language models\". Nature Reviews Psychology. 2 (8): 451–452. doi:10.1038/s44159-023-00211-x. ISSN\\xa02731-0574. S2CID\\xa0259713140. Retrieved 2 July 2023.\\nvteNatural language processingGeneral terms\\nAI-complete\\nBag-of-words\\nn-gram\\nBigram\\nTrigram\\nComputational linguistics\\nNatural language understanding\\nStop words\\nText processing\\nText analysis\\nArgument mining\\nCollocation extraction\\nConcept mining\\nCoreference resolution\\nDeep linguistic processing\\nDistant reading\\nInformation extraction\\nNamed-entity recognition\\nOntology learning\\nParsing\\nSemantic parsing\\nSyntactic parsing\\nPart-of-speech tagging\\nSemantic analysis\\nSemantic role labeling\\nSemantic decomposition\\nSemantic similarity\\nSentiment analysis\\nTerminology extraction\\nText mining\\nTextual entailment\\nTruecasing\\nWord-sense disambiguation\\nWord-sense induction\\nText segmentation\\nCompound-term processing\\nLemmatisation\\nLexical analysis\\nText chunking\\nStemming\\nSentence segmentation\\nWord segmentation\\n\\nAutomatic summarization\\nMulti-document summarization\\nSentence extraction\\nText simplification\\nMachine translation\\nComputer-assisted\\nExample-based\\nRule-based\\nStatistical\\nTransfer-based\\nNeural\\nDistributional semantics models\\nBERT\\nDocument-term matrix\\nExplicit semantic analysis\\nfastText\\nGloVe\\nLanguage model (large)\\nLatent semantic analysis\\nSeq2seq\\nWord embedding\\nWord2vec\\nLanguage resources,datasets and corporaTypes andstandards\\nCorpus linguistics\\nLexical resource\\nLinguistic Linked Open Data\\nMachine-readable dictionary\\nParallel text\\nPropBank\\nSemantic network\\nSimple Knowledge Organization System\\nSpeech corpus\\nText corpus\\nThesaurus (information retrieval)\\nTreebank\\nUniversal Dependencies\\nData\\nBabelNet\\nBank of English\\nDBpedia\\nFrameNet\\nGoogle Ngram Viewer\\nUBY\\nWordNet\\nWikidata\\nAutomatic identificationand data capture\\nSpeech recognition\\nSpeech segmentation\\nSpeech synthesis\\nNatural language generation\\nOptical character recognition\\nTopic model\\nDocument classification\\nLatent Dirichlet allocation\\nPachinko allocation\\nComputer-assistedreviewing\\nAutomated essay scoring\\nConcordancer\\nGrammar checker\\nPredictive text\\nPronunciation assessment\\nSpell checker\\nNatural languageuser interface\\nChatbot\\nInteractive fiction (c.f. Syntax guessing)\\nQuestion answering\\nVirtual assistant\\nVoice user interface\\nRelated\\nFormal semantics\\nHallucination\\nNatural Language Toolkit\\nspaCy\\n\\nvteArtificial intelligenceConcepts\\nParameter\\nHyperparameter\\nLoss functions\\nRegression\\nBias–variance tradeoff\\nDouble descent\\nOverfitting\\nClustering\\nGradient descent\\nSGD\\nQuasi-Newton method\\nConjugate gradient method\\nBackpropagation\\nAttention\\nConvolution\\nNormalization\\nBatchnorm\\nActivation\\nSoftmax\\nSigmoid\\nRectifier\\nGating\\nWeight initialization\\nRegularization\\nDatasets\\nAugmentation\\nPrompt engineering\\nReinforcement learning\\nQ-learning\\nSARSA\\nImitation\\nDiffusion\\nLatent diffusion model\\nAutoregression\\nAdversary\\nRAG\\nRLHF\\nSelf-supervised learning\\nWord embedding\\nHallucination\\nApplications\\nMachine learning\\nIn-context learning\\nArtificial neural network\\nDeep learning\\nLanguage model\\nLarge language model\\nNMT\\nArtificial general intelligence\\nImplementationsAudio–visual\\nAlexNet\\nWaveNet\\nHuman image synthesis\\nHWR\\nOCR\\nSpeech synthesis\\nElevenLabs\\nSpeech recognition\\nWhisper\\nFacial recognition\\nAlphaFold\\nText-to-image models\\nAurora\\nDALL-E\\nFlux\\nIdeogram\\nImagen\\nMidjourney\\nStable Diffusion\\nText-to-video models\\nDream Machine\\nKling\\nSora\\nVideoPoet\\nMusic generation\\nSuno AI\\nUdio\\nText\\nWord2vec\\nSeq2seq\\nGloVe\\nBERT\\nT5\\nLlama\\nChinchilla AI\\nPaLM\\nGPT\\n1\\n2\\n3\\nJ\\nChatGPT\\n4\\n4o\\no1\\nClaude\\nGemini\\nchatbot\\nGrok\\nLaMDA\\nBLOOM\\nProject Debater\\nIBM Watson\\nIBM Watsonx\\nGranite\\nPanGu-Σ\\nDecisional\\nAlphaGo\\nAlphaZero\\nOpenAI Five\\nSelf-driving car\\nMuZero\\nAction selection\\nAutoGPT\\nRobot control\\nPeople\\nAlan Turing\\nWarren Sturgis McCulloch\\nWalter Pitts\\nJohn von Neumann\\nClaude Shannon\\nMarvin Minsky\\nJohn McCarthy\\nNathaniel Rochester\\nAllen Newell\\nCliff Shaw\\nHerbert A. Simon\\nOliver Selfridge\\nFrank Rosenblatt\\nBernard Widrow\\nJoseph Weizenbaum\\nSeymour Papert\\nSeppo Linnainmaa\\nPaul Werbos\\nJürgen Schmidhuber\\nYann LeCun\\nGeoffrey Hinton\\nJohn Hopfield\\nYoshua Bengio\\nLotfi A. Zadeh\\nStephen Grossberg\\nAlex Graves\\nAndrew Ng\\nFei-Fei Li\\nAlex Krizhevsky\\nIlya Sutskever\\nDemis Hassabis\\nDavid Silver\\nIan Goodfellow\\nAndrej Karpathy\\nArchitectures\\nNeural Turing machine\\nDifferentiable neural computer\\nTransformer\\nVision transformer (ViT)\\nRecurrent neural network (RNN)\\nLong short-term memory (LSTM)\\nGated recurrent unit (GRU)\\nEcho state network\\nMultilayer perceptron (MLP)\\nConvolutional neural network (CNN)\\nResidual neural network (RNN)\\nHighway network\\nMamba\\nAutoencoder\\nVariational autoencoder (VAE)\\nGenerative adversarial network (GAN)\\nGraph neural network (GNN)\\n\\n Portals\\nTechnology\\n Categories\\nArtificial neural networks\\nMachine learning\\n List\\nCompanies\\nProjects\\n\\n\\n\\n\\n\\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Large_language_model&oldid=1261953784\"\\nCategories: Large language modelsDeep learningNatural language processingHidden categories: CS1 maint: url-statusCS1: long volume valueWebarchive template wayback linksArticles with short descriptionShort description is different from WikidataArticles containing potentially dated statements from 2024All articles containing potentially dated statementsArticles containing potentially dated statements from June 2024All accuracy disputesArticles with disputed statements from September 2024All articles with unsourced statementsArticles with unsourced statements from February 2024Articles containing potentially dated statements from October 2024\\n\\n\\n\\n\\n\\n\\n This page was last edited on 8 December 2024, at 21:33\\xa0(UTC).\\nText is available under the Creative Commons Attribution-ShareAlike 4.0 License;\\nadditional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.\\n\\n\\nPrivacy policy\\nAbout Wikipedia\\nDisclaimers\\nContact Wikipedia\\nCode of Conduct\\nDevelopers\\nStatistics\\nCookie statement\\nMobile view\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf16e54",
   "metadata": {},
   "source": [
    "#### using custom loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ac7bb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the URL: https://en.wikipedia.org/wiki/Large_language_model\n"
     ]
    }
   ],
   "source": [
    "url=input(\"Enter the URL: \")\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "text = soup.get_text()\n",
    "text = re.sub(r\"\\n+\", \"\\n\", text)\n",
    "with open(\"text_file.txt\", \"w\",encoding='utf-8') as f:\n",
    "        f.write(text)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ab1e90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=text.replace(\"\\n\",\" \").replace(\"\\t\",\" \")\n",
    "\n",
    "doc = Document(page_content=text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d5919a",
   "metadata": {},
   "source": [
    "\n",
    "# Splitters and Splitting Techniques (Chunking Strategies)\n",
    "\n",
    "> *Chunking is to RAG what memory is to human intelligence — get it wrong, and everything falls apart.* — Andrew Ng\n",
    "\n",
    "## Importance of Chunking in RAG Systems\n",
    "- A poorly chunked RAG system can miss up to **60% of relevant information** *(Stanford NLP Lab, 2023)*.\n",
    "- Optimal chunking can reduce hallucinations by **42%** *(OpenAI Research, 2023)*.\n",
    "- Processing time can vary by **300%** based on the chunking strategy used.\n",
    "\n",
    "## Chunking Strategies\n",
    "\n",
    "### 1. Fixed-size Chunking\n",
    "- **Description**: Divides text into chunks of equal size, such as 500 or 1000 tokens.\n",
    "- **Advantages**: Simple to implement, consistent chunk sizes.\n",
    "- **Disadvantages**: May split meaningful information mid-sentence or mid-paragraph.\n",
    "\n",
    "### 2. Structure Aware Chunking\n",
    "- **Description**: Splits text considering specific text structure. Mainly used for PDFs, HTML, Markdown files where the document has a structure\n",
    "- **Advantages**: Adapts to document type, Preserves format-specific elements, Respects format-specific content divisions.\n",
    "- **Disadvantages**: Uneven chunk sizes, may require post-processing for uniformity.\n",
    "\n",
    "### 3. Semantic Chunking\n",
    "- **Description**: Groups sentences or paragraphs based on thematic or contextual relevance.\n",
    "- **Advantages**: High semantic coherence, reduces redundant information.\n",
    "- **Disadvantages**: Computationally expensive to implement.\n",
    "\n",
    "### 4. Dynamic Chunking\n",
    "- **Description**: Adjusts chunk size dynamically based on content or token limits.\n",
    "- **Advantages**: Balances coherence and processing constraints.\n",
    "- **Disadvantages**: Requires sophisticated algorithms and tuning.\n",
    "\n",
    "## Best Practices for Effective Chunking\n",
    "- Analyze document structure to identify natural boundaries (e.g., headings, paragraphs).\n",
    "- Test multiple chunking techniques to identify the most suitable one for the use case.\n",
    "- Use tools like tokenizers to ensure chunk sizes align with model limitations.\n",
    "- Balance between chunk size and semantic coherence to reduce hallucinations and improve retrieval accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bf7b83",
   "metadata": {},
   "source": [
    "### 1) Character Text Splitters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d97d64a",
   "metadata": {},
   "source": [
    "#### CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "10982e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "splitter = CharacterTextSplitter(\n",
    "    chunk_size=26,\n",
    "    chunk_overlap=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0ef5b438",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'abcdefghijklmnopqrstuvwxyz1234Satyajeet89767546456'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "bfe0f1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e1f7b2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e8b01325",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=366,\n",
    "    chunk_overlap=4,\n",
    "    separators=[\"Satyajeet\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a8a2a04e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz1234Satyajeet89767546456']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26127313",
   "metadata": {},
   "outputs": [],
   "source": [
    "RecursiveCharacterTextSplitter??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d3f832e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import MarkdownHeaderTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37079838",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_document = \"\"\"# Title\n",
    "## Chapter 1\n",
    "Hi this is Satyajeet\\n\\n His surname is Narayan\n",
    "### Section\n",
    "He is taking this session\n",
    "## Chapter 2\n",
    "This session is on RAG\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad5b0bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8194cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on\n",
    ")\n",
    "md_header_splits = markdown_splitter.split_text(markdown_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f650559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1'}, page_content='Hi this is Satyajeet  \\nHis surname is Narayan'),\n",
       " Document(metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1', 'Header 3': 'Section'}, page_content='He is taking this session'),\n",
       " Document(metadata={'Header 1': 'Title', 'Header 2': 'Chapter 2'}, page_content='This session is on RAG')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40ad4bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
